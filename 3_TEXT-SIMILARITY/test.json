{
  "id": "1802.00209v1"
}
//  "author": "[{'name': 'Ahmed Osman'}, {'name': 'Wojciech Samek'}]",
//  "day": 1,
//  "id": "1802.00209v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.00209v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.00209v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We propose an architecture for VQA which utilizes recurrent layers to\ngenerate visual and textual attention. The memory characteristic of the\nproposed recurrent attention units offers a rich joint embedding of visual and\ntextual features and enables the model to reason relations between several\nparts of the image and question. Our single model outperforms the first place\nwinner on the VQA 1.0 dataset, performs within margin to the current\nstate-of-the-art ensemble model. We also experiment with replacing attention\nmechanisms in other state-of-the-art models with our implementation and show\nincreased accuracy. In both cases, our recurrent attention mechanism improves\nperformance in tasks requiring sequential or relational reasoning on the VQA\ndataset.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Dual Recurrent Attention Units for Visual Question Answering",
//  "year": 2018
//}
//{
//  "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}]",
//  "day": 12,
//  "id": "1603.03827v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.03827v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.03827v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for short-text classification. However, many short texts\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\nand most existing ANN-based systems do not leverage the preceding short texts\nwhen classifying a subsequent one. In this work, we present a model based on\nrecurrent neural networks and convolutional neural networks that incorporates\nthe preceding short texts. Our model achieves state-of-the-art results on three\ndifferent datasets for dialog act prediction.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sequential Short-Text Classification with Recurrent and Convolutional\n  Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Iulian Vlad Serban'}, {'name': 'Tim Klinger'}, {'name': 'Gerald Tesauro'}, {'name': 'Kartik Talamadupula'}, {'name': 'Bowen Zhou'}, {'name': 'Yoshua Bengio'}, {'name': 'Aaron Courville'}]",
//  "day": 2,
//  "id": "1606.00776v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.00776v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.00776v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Sebastian Ruder'}, {'name': 'Joachim Bingel'}, {'name': 'Isabelle Augenstein'}, {'name': 'Anders S\u00f8gaard'}]",
//  "day": 23,
//  "id": "1705.08142v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08142v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08142v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Multi-task learning is motivated by the observation that humans bring to bear\nwhat they know about related problems when solving new ones. Similarly, deep\nneural networks can profit from related tasks by sharing parameters with other\nnetworks. However, humans do not consciously decide to transfer knowledge\nbetween tasks. In Natural Language Processing (NLP), it is hard to predict if\nsharing will lead to improvements, particularly if tasks are only loosely\nrelated. To overcome this, we introduce Sluice Networks, a general framework\nfor multi-task learning where trainable parameters control the amount of\nsharing. Our framework generalizes previous proposals in enabling sharing of\nall combinations of subspaces, layers, and skip connections. We perform\nexperiments on three task pairs, and across seven different domains, using data\nfrom OntoNotes 5.0, and achieve up to 15% average error reductions over common\napproaches to multi-task learning. We show that a) label entropy is predictive\nof gains in sluice networks, confirming findings for hard parameter sharing and\nb) while sluice networks easily fit noise, they are robust across domains in\npractice.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning what to share between loosely related tasks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Chinnadhurai Sankar'}, {'name': 'Mathieu Germain'}, {'name': 'Saizheng Zhang'}, {'name': 'Zhouhan Lin'}, {'name': 'Sandeep Subramanian'}, {'name': 'Taesup Kim'}, {'name': 'Michael Pieper'}, {'name': 'Sarath Chandar'}, {'name': 'Nan Rosemary Ke'}, {'name': 'Sai Rajeshwar'}, {'name': 'Alexandre de Brebisson'}, {'name': 'Jose M. R. Sotelo'}, {'name': 'Dendi Suhubdy'}, {'name': 'Vincent Michalski'}, {'name': 'Alexandre Nguyen'}, {'name': 'Joelle Pineau'}, {'name': 'Yoshua Bengio'}]",
//  "day": 7,
//  "id": "1709.02349v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.02349v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.02349v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Deep Reinforcement Learning Chatbot",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kelvin Guu'}, {'name': 'Tatsunori B. Hashimoto'}, {'name': 'Yonatan Oren'}, {'name': 'Percy Liang'}]",
//  "day": 26,
//  "id": "1709.08878v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.08878v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.08878v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generating Sentences by Editing Prototypes",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Chinnadhurai Sankar'}, {'name': 'Mathieu Germain'}, {'name': 'Saizheng Zhang'}, {'name': 'Zhouhan Lin'}, {'name': 'Sandeep Subramanian'}, {'name': 'Taesup Kim'}, {'name': 'Michael Pieper'}, {'name': 'Sarath Chandar'}, {'name': 'Nan Rosemary Ke'}, {'name': 'Sai Rajeswar'}, {'name': 'Alexandre de Brebisson'}, {'name': 'Jose M. R. Sotelo'}, {'name': 'Dendi Suhubdy'}, {'name': 'Vincent Michalski'}, {'name': 'Alexandre Nguyen'}, {'name': 'Joelle Pineau'}, {'name': 'Yoshua Bengio'}]",
//  "day": 20,
//  "id": "1801.06700v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.06700v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.06700v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Deep Reinforcement Learning Chatbot (Short Version)",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Darko Brodic'}, {'name': 'Alessia Amelio'}, {'name': 'Zoran N. Milivojevic'}, {'name': 'Milena Jevtic'}]",
//  "day": 21,
//  "id": "1609.06492v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.06492v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.06492v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '97R40, 62H35, 68U15, 68T50,', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Document Image Coding and Clustering for Script Discrimination",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mateusz Malinowski'}, {'name': 'Mario Fritz'}]",
//  "day": 4,
//  "id": "1610.01076v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.01076v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.01076v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Together with the development of more accurate methods in Computer Vision and\nNatural Language Understanding, holistic architectures that answer on questions\nabout the content of real-world images have emerged. In this tutorial, we build\na neural-based approach to answer questions about images. We base our tutorial\non two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the\nmodels that we present here can achieve a competitive performance on both\ndatasets, in fact, they are among the best methods that use a combination of\nLSTM with a global, full frame CNN representation of an image. We hope that\nafter reading this tutorial, the reader will be able to use Deep Learning\nframeworks, such as Keras and introduced Kraino, to build various architectures\nthat will lead to a further performance improvement on this challenging task.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Tutorial on Answering Questions about Images with Deep Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tony Beltramelli'}]",
//  "day": 22,
//  "id": "1705.07962v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.07962v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.07962v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Transforming a graphical user interface screenshot created by a designer into\ncomputer code is a typical task conducted by a developer in order to build\ncustomized software, websites, and mobile applications. In this paper, we show\nthat deep learning methods can be leveraged to train a model end-to-end to\nautomatically generate code from a single input image with over 77% of accuracy\nfor three different platforms (i.e. iOS, Android and web-based technologies).",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.1; I.2.10; I.2.2; I.2.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "pix2code: Generating Code from a Graphical User Interface Screenshot",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Fred Richardson'}, {'name': 'Douglas Reynolds'}, {'name': 'Najim Dehak'}]",
//  "day": 3,
//  "id": "1504.00923v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.00923v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.00923v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Learned feature representations and sub-phoneme posteriors from Deep Neural\nNetworks (DNNs) have been used separately to produce significant performance\ngains for speaker and language recognition tasks. In this work we show how\nthese gains are possible using a single DNN for both speaker and language\nrecognition. The unified DNN approach is shown to yield substantial performance\nimprovements on the the 2013 Domain Adaptation Challenge speaker recognition\ntask (55% reduction in EER for the out-of-domain condition) and on the NIST\n2011 Language Recognition Evaluation (48% reduction in EER for the 30s test\ncondition).",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Unified Deep Neural Network for Speaker and Language Recognition",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Hieu Pham'}, {'name': 'Melody Y. Guan'}, {'name': 'Barret Zoph'}, {'name': 'Quoc V. Le'}, {'name': 'Jeff Dean'}]",
//  "day": 9,
//  "id": "1802.03268v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.03268v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.03268v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Efficient Neural Architecture Search via Parameter Sharing",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Brenden M. Lake'}, {'name': 'Tomer D. Ullman'}, {'name': 'Joshua B. Tenenbaum'}, {'name': 'Samuel J. Gershman'}]",
//  "day": 1,
//  "id": "1604.00289v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.00289v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.00289v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Building Machines That Learn and Think Like People",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Hao Wang'}, {'name': 'Dit-Yan Yeung'}]",
//  "day": 6,
//  "id": "1604.01662v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.01662v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.01662v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "While perception tasks such as visual object recognition and text\nunderstanding play an important role in human intelligence, the subsequent\ntasks that involve inference, reasoning and planning require an even higher\nlevel of intelligence. The past few years have seen major advances in many\nperception tasks using deep learning models. For higher-level inference,\nhowever, probabilistic graphical models with their Bayesian nature are still\nmore powerful and flexible. To achieve integrated intelligence that involves\nboth perception and inference, it is naturally desirable to tightly integrate\ndeep learning and Bayesian models within a principled probabilistic framework,\nwhich we call Bayesian deep learning. In this unified framework, the perception\nof text or images using deep learning can boost the performance of higher-level\ninference and in return, the feedback from the inference process is able to\nenhance the perception of text or images. This survey provides a general\nintroduction to Bayesian deep learning and reviews its recent applications on\nrecommender systems, topic models, and control. In this survey, we also discuss\nthe relationship and differences between Bayesian deep learning and other\nrelated topics like Bayesian treatment of neural networks.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards Bayesian Deep Learning: A Survey",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tejas D. Kulkarni'}, {'name': 'Karthik R. Narasimhan'}, {'name': 'Ardavan Saeedi'}, {'name': 'Joshua B. Tenenbaum'}]",
//  "day": 20,
//  "id": "1604.06057v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.06057v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.06057v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Learning goal-directed behavior in environments with sparse feedback is a\nmajor challenge for reinforcement learning algorithms. The primary difficulty\narises due to insufficient exploration, resulting in an agent being unable to\nlearn robust value functions. Intrinsically motivated agents can explore new\nbehavior for its own sake rather than to directly solve problems. Such\nintrinsic behaviors could eventually help the agent solve tasks posed by the\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\nhierarchical value functions, operating at different temporal scales, with\nintrinsically motivated deep reinforcement learning. A top-level value function\nlearns a policy over intrinsic goals, and a lower-level function learns a\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\nflexible goal specifications, such as functions over entities and relations.\nThis provides an efficient space for exploration in complicated environments.\nWe demonstrate the strength of our approach on two problems with very sparse,\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\nthe classic ATARI game `Montezuma's Revenge'.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal\n  Abstraction and Intrinsic Motivation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Deepak Pathak'}, {'name': 'Ross Girshick'}, {'name': 'Piotr Doll\u00e1r'}, {'name': 'Trevor Darrell'}, {'name': 'Bharath Hariharan'}]",
//  "day": 19,
//  "id": "1612.06370v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.06370v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.06370v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "This paper presents a novel yet intuitive approach to unsupervised feature\nlearning. Inspired by the human visual system, we explore whether low-level\nmotion-based grouping cues can be used to learn an effective visual\nrepresentation. Specifically, we use unsupervised motion-based segmentation on\nvideos to obtain segments, which we use as 'pseudo ground truth' to train a\nconvolutional network to segment objects from a single frame. Given the\nextensive evidence that motion plays a key role in the development of the human\nvisual system, we hope that this straightforward approach to unsupervised\nlearning will be more effective than cleverly designed 'pretext' tasks studied\nin the literature. Indeed, our extensive experiments show that this is the\ncase. When used for transfer learning on object detection, our representation\nsignificantly outperforms previous unsupervised approaches across multiple\nsettings, especially when training data for the target task is scarce.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Features by Watching Objects Move",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Muhammad Ghifary'}, {'name': 'W. Bastiaan Kleijn'}, {'name': 'Mengjie Zhang'}]",
//  "day": 21,
//  "id": "1409.6041v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.6041v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.6041v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose a simple neural network model to deal with the domain adaptation\nproblem in object recognition. Our model incorporates the Maximum Mean\nDiscrepancy (MMD) measure as a regularization in the supervised learning to\nreduce the distribution mismatch between the source and target domains in the\nlatent space. From experiments, we demonstrate that the MMD regularization is\nan effective tool to provide good domain adaptation models on both SURF\nfeatures and raw image pixels of a particular image data set. We also show that\nour proposed model, preceded by the denoising auto-encoder pretraining,\nachieves better performance than recent benchmark models on the same data sets.\nThis work represents the first study of MMD measure in the context of neural\nnetworks.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Domain Adaptive Neural Networks for Object Recognition",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Lionel Pigou'}, {'name': 'A\u00e4ron van den Oord'}, {'name': 'Sander Dieleman'}, {'name': 'Mieke Van Herreweghe'}, {'name': 'Joni Dambre'}]",
//  "day": 5,
//  "id": "1506.01911v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.01911v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.01911v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Recent studies have demonstrated the power of recurrent neural networks for\nmachine translation, image captioning and speech recognition. For the task of\ncapturing temporal structure in video, however, there still remain numerous\nopen research questions. Current research suggests using a simple temporal\nfeature pooling strategy to take into account the temporal aspect of video. We\ndemonstrate that this method is not sufficient for gesture recognition, where\ntemporal information is more discriminative compared to general video\nclassification tasks. We explore deep architectures for gesture recognition in\nvideo and propose a new end-to-end trainable neural network architecture\nincorporating temporal convolutions and bidirectional recurrence. Our main\ncontributions are twofold; first, we show that recurrence is crucial for this\ntask; second, we show that adding temporal convolutions leads to significant\nimprovements. We evaluate the different approaches on the Montalbano gesture\nrecognition dataset, where we achieve state-of-the-art results.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Beyond Temporal Pooling: Recurrence and Temporal Convolutions for\n  Gesture Recognition in Video",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Rakesh Achanta'}, {'name': 'Trevor Hastie'}]",
//  "day": 20,
//  "id": "1509.05962v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.05962v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.05962v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "In this paper, we address the task of Optical Character Recognition(OCR) for\nthe Telugu script. We present an end-to-end framework that segments the text\nimage, classifies the characters and extracts lines using a language model. The\nsegmentation is based on mathematical morphology. The classification module,\nwhich is the most challenging task of the three, is a deep convolutional neural\nnetwork. The language is modelled as a third degree markov chain at the glyph\nlevel. Telugu script is a complex alphasyllabary and the language is\nagglutinative, making the problem hard. In this paper we apply the latest\nadvances in neural networks to achieve state-of-the-art error rates. We also\nreview convolutional neural networks in great detail and expound the\nstatistical justification behind the many tricks needed to make Deep Learning\nwork.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Telugu OCR Framework using Deep Learning",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Jeff Donahue'}, {'name': 'Philipp Kr\u00e4henb\u00fchl'}, {'name': 'Trevor Darrell'}]",
//  "day": 31,
//  "id": "1605.09782v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.09782v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.09782v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Adversarial Feature Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Zachary C. Lipton'}]",
//  "day": 10,
//  "id": "1606.03490v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.03490v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.03490v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "The Mythos of Model Interpretability",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Sahil Garg'}, {'name': 'Irina Rish'}, {'name': 'Guillermo Cecchi'}, {'name': 'Aurelie Lozano'}]",
//  "day": 22,
//  "id": "1701.06106v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.06106v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.06106v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "In this paper, we focus on online representation learning in non-stationary\nenvironments which may require continuous adaptation of model architecture. We\npropose a novel online dictionary-learning (sparse-coding) framework which\nincorporates the addition and deletion of hidden units (dictionary elements),\nand is inspired by the adult neurogenesis phenomenon in the dentate gyrus of\nthe hippocampus, known to be associated with improved cognitive function and\nadaptation to new environments. In the online learning setting, where new input\ninstances arrive sequentially in batches, the neuronal-birth is implemented by\nadding new units with random initial weights (random dictionary elements); the\nnumber of new units is determined by the current performance (representation\nerror) of the dictionary, higher error causing an increase in the birth rate.\nNeuronal-death is implemented by imposing l1/l2-regularization (group sparsity)\non the dictionary within the block-coordinate descent optimization at each\niteration of our online alternating minimization scheme, which iterates between\nthe code and dictionary updates. Finally, hidden unit connectivity adaptation\nis facilitated by introducing sparsity in dictionary elements. Our empirical\nevaluation on several real-life datasets (images and language) as well as on\nsynthetic data demonstrates that the proposed approach can considerably\noutperform the state-of-art fixed-size (nonadaptive) online sparse coding of\nMairal et al. (2009) in the presence of nonstationary data. Moreover, we\nidentify certain properties of the data (e.g., sparse inputs with nearly\nnon-overlapping supports) and of the model (e.g., dictionary sparsity)\nassociated with such improvements.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a\n  Changing World",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Weifeng Ge'}, {'name': 'Yizhou Yu'}]",
//  "day": 28,
//  "id": "1702.08690v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.08690v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.08690v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Deep neural networks require a large amount of labeled training data during\nsupervised learning. However, collecting and labeling so much data might be\ninfeasible in many cases. In this paper, we introduce a source-target selective\njoint fine-tuning scheme for improving the performance of deep learning tasks\nwith insufficient training data. In this scheme, a target learning task with\ninsufficient training data is carried out simultaneously with another source\nlearning task with abundant training data. However, the source learning task\ndoes not use all existing training data. Our core idea is to identify and use a\nsubset of training images from the original source learning task whose\nlow-level characteristics are similar to those from the target learning task,\nand jointly fine-tune shared convolutional layers for both tasks. Specifically,\nwe compute descriptors from linear or nonlinear filter bank responses on\ntraining images from both tasks, and use such descriptors to search for a\ndesired subset of training samples for the source learning task.\n  Experiments demonstrate that our selective joint fine-tuning scheme achieves\nstate-of-the-art performance on multiple visual classification tasks with\ninsufficient training data for deep learning. Such tasks include Caltech 256,\nMIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to\nfine-tuning without a source domain, the proposed method can improve the\nclassification accuracy by 2% - 10% using a single model.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Borrowing Treasures from the Wealthy: Deep Transfer Learning through\n  Selective Joint Fine-tuning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Tanmay Gupta'}, {'name': 'Kevin Shih'}, {'name': 'Saurabh Singh'}, {'name': 'Derek Hoiem'}]",
//  "day": 2,
//  "id": "1704.00260v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.00260v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.00260v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "An important goal of computer vision is to build systems that learn visual\nrepresentations over time that can be applied to many tasks. In this paper, we\ninvestigate a vision-language embedding as a core representation and show that\nit leads to better cross-task transfer than standard multi-task learning. In\nparticular, the task of visual recognition is aligned to the task of visual\nquestion answering by forcing each to use the same word-region embeddings. We\nshow this leads to greater inductive transfer from recognition to VQA than\nstandard multitask learning. Visual recognition also improves, especially for\ncategories that have relatively few recognition training labels but appear\noften in the VQA setting. Thus, our paper takes a small step towards creating\nmore general vision systems by showing the benefit of interpretable, flexible,\nand trainable core representations.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Aligned Image-Word Representations Improve Inductive Transfer Across\n  Vision-Language Tasks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jan Hendrik Metzen'}, {'name': 'Mummadi Chaithanya Kumar'}, {'name': 'Thomas Brox'}, {'name': 'Volker Fischer'}]",
//  "day": 19,
//  "id": "1704.05712v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.05712v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.05712v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "While deep learning is remarkably successful on perceptual tasks, it was also\nshown to be vulnerable to adversarial perturbations of the input. These\nperturbations denote noise added to the input that was generated specifically\nto fool the system while being quasi-imperceptible for humans. More severely,\nthere even exist universal perturbations that are input-agnostic but fool the\nnetwork on the majority of inputs. While recent work has focused on image\nclassification, this work proposes attacks against semantic image segmentation:\nwe present an approach for generating (universal) adversarial perturbations\nthat make the network yield a desired target segmentation as output. We show\nempirically that there exist barely perceptible universal noise patterns which\nresult in nearly the same predicted segmentation for arbitrary inputs.\nFurthermore, we also show the existence of universal noise which removes a\ntarget class (e.g., all pedestrians) from the segmentation while leaving the\nsegmentation mostly unchanged otherwise.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Universal Adversarial Perturbations Against Semantic Image Segmentation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Quynh Nguyen'}, {'name': 'Matthias Hein'}]",
//  "day": 26,
//  "id": "1704.08045v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08045v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08045v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "While the optimization problem behind deep neural networks is highly\nnon-convex, it is frequently observed in practice that training deep networks\nseems possible without getting stuck in suboptimal points. It has been argued\nthat this is the case as all local minima are close to being globally optimal.\nWe show that this is (almost) true, in fact almost all local minima are\nglobally optimal, for a fully connected network with squared loss and analytic\nactivation function given that the number of hidden units of one layer of the\nnetwork is larger than the number of training points and the network structure\nfrom this layer on is pyramidal.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "The loss surface of deep and wide neural networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chris Donahue'}, {'name': 'Zachary C. Lipton'}, {'name': 'Akshay Balsubramani'}, {'name': 'Julian McAuley'}]",
//  "day": 22,
//  "id": "1705.07904v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.07904v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.07904v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "We propose a new algorithm for training generative adversarial networks that\njointly learns latent codes for both identities (e.g. individual humans) and\nobservations (e.g. specific photographs). By fixing the identity portion of the\nlatent codes, we can generate diverse images of the same subject, and by fixing\nthe observation portion, we can traverse the manifold of subjects while\nmaintaining contingent aspects such as lighting and pose. Our algorithm\nfeatures a pairwise training scheme in which each sample from the generator\nconsists of two images with a common identity code. Corresponding samples from\nthe real dataset consist of two distinct photographs of the same subject. In\norder to fool the discriminator, the generator must produce pairs that are\nphotorealistic, distinct, and appear to depict the same individual. We augment\nboth the DCGAN and BEGAN approaches with Siamese discriminators to facilitate\npairwise training. Experiments with human judges and an off-the-shelf face\nverification system demonstrate our algorithm's ability to generate convincing,\nidentity-matched photographs.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Semantically Decomposing the Latent Spaces of Generative Adversarial\n  Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mahesh Chandra Mukkamala'}, {'name': 'Matthias Hein'}]",
//  "day": 17,
//  "id": "1706.05507v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.05507v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.05507v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chunyuan Li'}, {'name': 'Hao Liu'}, {'name': 'Changyou Chen'}, {'name': 'Yunchen Pu'}, {'name': 'Liqun Chen'}, {'name': 'Ricardo Henao'}, {'name': 'Lawrence Carin'}]",
//  "day": 5,
//  "id": "1709.01215v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.01215v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.01215v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mateusz Buda'}, {'name': 'Atsuto Maki'}, {'name': 'Maciej A. Mazurowski'}]",
//  "day": 15,
//  "id": "1710.05381v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.05381v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.05381v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "In this study, we systematically investigate the impact of class imbalance on\nclassification performance of convolutional neural networks (CNNs) and compare\nfrequently used methods to address the issue. Class imbalance is a common\nproblem that has been comprehensively studied in classical machine learning,\nyet very limited systematic research is available in the context of deep\nlearning. In our study, we use three benchmark datasets of increasing\ncomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of\nimbalance on classification and perform an extensive comparison of several\nmethods to address the issue: oversampling, undersampling, two-phase training,\nand thresholding that compensates for prior class probabilities. Our main\nevaluation metric is area under the receiver operating characteristic curve\n(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is\nassociated with notable difficulties in the context of imbalanced data. Based\non results from our experiments we conclude that (i) the effect of class\nimbalance on classification performance is detrimental; (ii) the method of\naddressing class imbalance that emerged as dominant in almost all analyzed\nscenarios was oversampling; (iii) oversampling should be applied to the level\nthat totally eliminates the imbalance, whereas undersampling can perform better\nwhen the imbalance is only removed to some extent; (iv) as opposed to some\nclassical machine learning models, oversampling does not necessarily cause\noverfitting of CNNs; (v) thresholding should be applied to compensate for prior\nclass probabilities when overall number of properly classified cases is of\ninterest.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A systematic study of the class imbalance problem in convolutional\n  neural networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jan Kuka\u010dka'}, {'name': 'Vladimir Golkov'}, {'name': 'Daniel Cremers'}]",
//  "day": 29,
//  "id": "1710.10686v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.10686v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.10686v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62M45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Regularization for Deep Learning: A Taxonomy",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Elie Aljalbout'}, {'name': 'Vladimir Golkov'}, {'name': 'Yawar Siddiqui'}, {'name': 'Daniel Cremers'}]",
//  "day": 23,
//  "id": "1801.07648v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.07648v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.07648v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Clustering is a fundamental machine learning method. The quality of its\nresults is dependent on the data distribution. For this reason, deep neural\nnetworks can be used for learning better representations of the data. In this\npaper, we propose a systematic taxonomy for clustering with deep learning, in\naddition to a review of methods from the field. Based on our taxonomy, creating\nnew methods is more straightforward. We also propose a new approach which is\nbuilt on the taxonomy and surpasses some of the limitations of some previous\nwork. Our experimental evaluation on image datasets shows that the method\napproaches state-of-the-art clustering quality, and performs better in some\ncases.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62H30, 62M45, 91C20', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.3; I.2.6; I.5; I.5.3; I.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Clustering with Deep Learning: Taxonomy and New Methods",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Armand Zampieri'}, {'name': 'Guillaume Charpiat'}, {'name': 'Yuliya Tarabalka'}]",
//  "day": 27,
//  "id": "1802.09816v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.09816v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.09816v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Li Yao'}, {'name': 'Atousa Torabi'}, {'name': 'Kyunghyun Cho'}, {'name': 'Nicolas Ballas'}, {'name': 'Christopher Pal'}, {'name': 'Hugo Larochelle'}, {'name': 'Aaron Courville'}]",
//  "day": 27,
//  "id": "1502.08029v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1502.08029v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1502.08029v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Recent progress in using recurrent neural networks (RNNs) for image\ndescription has motivated the exploration of their application for video\ndescription. However, while images are static, working with videos requires\nmodeling their dynamic temporal structure and then properly integrating that\ninformation into a natural language description. In this context, we propose an\napproach that successfully takes into account both the local and global\ntemporal structure of videos to produce descriptions. First, our approach\nincorporates a spatial temporal 3-D convolutional neural network (3-D CNN)\nrepresentation of the short temporal dynamics. The 3-D CNN representation is\ntrained on video action recognition tasks, so as to produce a representation\nthat is tuned to human motion and behavior. Second we propose a temporal\nattention mechanism that allows to go beyond local temporal modeling and learns\nto automatically select the most relevant temporal segments given the\ntext-generating RNN. Our approach exceeds the current state-of-art for both\nBLEU and METEOR metrics on the Youtube2Text dataset. We also present results on\na new, larger and more challenging dataset of paired video and natural language\ndescriptions.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Describing Videos by Exploiting Temporal Structure",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Hao Wang'}, {'name': 'Xingjian Shi'}, {'name': 'Dit-Yan Yeung'}]",
//  "day": 2,
//  "id": "1611.00454v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.00454v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.00454v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Hybrid methods that utilize both content and rating information are commonly\nused in many recommender systems. However, most of them use either handcrafted\nfeatures or the bag-of-words representation as a surrogate for the content\ninformation but they are neither effective nor natural enough. To address this\nproblem, we develop a collaborative recurrent autoencoder (CRAE) which is a\ndenoising recurrent autoencoder (DRAE) that models the generation of content\nsequences in the collaborative filtering (CF) setting. The model generalizes\nrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n(CF-based) input and provides a new denoising scheme along with a novel\nlearnable pooling scheme for the recurrent autoencoder. To do this, we first\ndevelop a hierarchical Bayesian model for the DRAE and then generalize it to\nthe CF setting. The synergy between denoising and CF enables CRAE to make\naccurate recommendations while learning to fill in the blanks in sequences.\nExperiments on real-world datasets from different domains (CiteULike and\nNetflix) show that, by jointly modeling the order-aware generation of sequences\nfor the content information and performing CF for the ratings, CRAE is able to\nsignificantly outperform the state of the art on both the recommendation task\nbased on ratings and the sequence generation task based on content information.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n  the Blanks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Laura Graesser'}, {'name': 'Abhinav Gupta'}, {'name': 'Lakshay Sharma'}, {'name': 'Evelina Bakhturina'}]",
//  "day": 3,
//  "id": "1712.00725v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.00725v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.00725v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sentiment Classification using Images and Label Embeddings",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Hao Wang'}, {'name': 'Xingjian Shi'}, {'name': 'Dit-Yan Yeung'}]",
//  "day": 2,
//  "id": "1611.00448v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.00448v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.00448v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Neural networks (NN) have achieved state-of-the-art performance in various\napplications. Unfortunately in applications where training data is\ninsufficient, they are often prone to overfitting. One effective way to\nalleviate this problem is to exploit the Bayesian approach by using Bayesian\nneural networks (BNN). Another shortcoming of NN is the lack of flexibility to\ncustomize different distributions for the weights and neurons according to the\ndata, as is often done in probabilistic graphical models. To address these\nproblems, we propose a class of probabilistic neural networks, dubbed\nnatural-parameter networks (NPN), as a novel and lightweight Bayesian treatment\nof NN. NPN allows the usage of arbitrary exponential-family distributions to\nmodel the weights and neurons. Different from traditional NN and BNN, NPN takes\ndistributions as input and goes through layers of transformation before\nproducing distributions to match the target output distributions. As a Bayesian\ntreatment, efficient backpropagation (BP) is performed to learn the natural\nparameters for the distributions over both the weights and neurons. The output\ndistributions of each layer, as byproducts, may be used as second-order\nrepresentations for the associated tasks such as link prediction. Experiments\non real-world datasets show that NPN can achieve state-of-the-art performance.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Misha Denil'}, {'name': 'Pulkit Agrawal'}, {'name': 'Tejas D Kulkarni'}, {'name': 'Tom Erez'}, {'name': 'Peter Battaglia'}, {'name': 'Nando de Freitas'}]",
//  "day": 6,
//  "id": "1611.01843v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.01843v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.01843v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "When encountering novel objects, humans are able to infer a wide range of\nphysical properties such as mass, friction and deformability by interacting\nwith them in a goal driven way. This process of active interaction is in the\nsame spirit as a scientist performing experiments to discover hidden facts.\nRecent advances in artificial intelligence have yielded machines that can\nachieve superhuman performance in Go, Atari, natural language processing, and\ncomplex control problems; however, it is not clear that these systems can rival\nthe scientific intuition of even a young child. In this work we introduce a\nbasic set of tasks that require agents to estimate properties such as mass and\ncohesion of objects in an interactive simulated environment where they can\nmanipulate the objects and observe the consequences. We found that state of art\ndeep reinforcement learning methods can learn to perform the experiments\nnecessary to discover such hidden properties. By systematically manipulating\nthe problem difficulty and the cost incurred by the agent for performing\nexperiments, we found that agents learn different strategies that balance the\ncost of gathering information against the cost of making mistakes in different\nsituations.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tsung-Hsien Wen'}, {'name': 'David Vandyke'}, {'name': 'Nikola Mrksic'}, {'name': 'Milica Gasic'}, {'name': 'Lina M. Rojas-Barahona'}, {'name': 'Pei-Hao Su'}, {'name': 'Stefan Ultes'}, {'name': 'Steve Young'}]",
//  "day": 15,
//  "id": "1604.04562v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.04562v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.04562v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Teaching machines to accomplish tasks by conversing naturally with humans is\nchallenging. Currently, developing task-oriented dialogue systems requires\ncreating multiple components and typically this involves either a large amount\nof handcrafting, or acquiring costly labelled datasets to solve a statistical\nlearning problem for each component. In this work we introduce a neural\nnetwork-based text-in, text-out end-to-end trainable goal-oriented dialogue\nsystem along with a new way of collecting dialogue data based on a novel\npipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue\nsystems easily and without making too many assumptions about the task at hand.\nThe results show that the model can converse with human subjects naturally\nwhilst helping them to accomplish tasks in a restaurant search domain.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Johannes Welbl'}, {'name': 'Guillaume Bouchard'}, {'name': 'Sebastian Riedel'}]",
//  "day": 20,
//  "id": "1604.05878v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.05878v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.05878v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Embedding-based Knowledge Base Completion models have so far mostly combined\ndistributed representations of individual entities or relations to compute\ntruth scores of missing links. Facts can however also be represented using\npairwise embeddings, i.e. embeddings for pairs of entities and relations. In\nthis paper we explore such bigram embeddings with a flexible Factorization\nMachine model and several ablations from it. We investigate the relevance of\nvarious bigram types on the fb15k237 dataset and find relative improvements\ncompared to a compositional model.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Factorization Machine Framework for Testing Bigram Embeddings in\n  Knowledgebase Completion",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Franck Dernoncourt'}, {'name': 'Ji Young Lee'}, {'name': 'Peter Szolovits'}]",
//  "day": 15,
//  "id": "1612.05251v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.05251v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.05251v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Existing models based on artificial neural networks (ANNs) for sentence\nclassification often do not incorporate the context in which sentences appear,\nand classify sentences individually. However, traditional sentence\nclassification approaches have been shown to greatly benefit from jointly\nclassifying subsequent sentences, such as with conditional random fields. In\nthis work, we present an ANN architecture that combines the effectiveness of\ntypical ANN models to classify sentences in isolation, with the strength of\nstructured prediction. Our model achieves state-of-the-art results on two\ndifferent datasets for sequential sentence classification in medical abstracts.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Networks for Joint Sentence Classification in Medical Paper\n  Abstracts",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Franck Dernoncourt'}, {'name': 'Ji Young Lee'}, {'name': 'Ozlem Uzuner'}, {'name': 'Peter Szolovits'}]",
//  "day": 10,
//  "id": "1606.03475v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.03475v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.03475v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "De-identification of Patient Notes with Recurrent Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tsendsuren Munkhdalai'}, {'name': 'Hong Yu'}]",
//  "day": 20,
//  "id": "1610.06454v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.06454v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.06454v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Hypothesis testing is an important cognitive process that supports human\nreasoning. In this paper, we introduce a computational hypothesis testing\napproach based on memory augmented neural networks. Our approach involves a\nhypothesis testing loop that reconsiders and progressively refines a previously\nformed hypothesis in order to generate new hypotheses to test. We apply the\nproposed approach to language comprehension task by using Neural Semantic\nEncoders (NSE). Our NSE models achieve the state-of-the-art results showing an\nabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\nsingle and ensemble systems on standard machine comprehension benchmarks such\nas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Reasoning with Memory Augmented Neural Networks for Language\n  Comprehension",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'W. James Murdoch'}, {'name': 'Arthur Szlam'}]",
//  "day": 8,
//  "id": "1702.02540v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.02540v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.02540v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Although deep learning models have proven effective at solving problems in\nnatural language processing, the mechanism by which they come to their\nconclusions is often unclear. As a result, these models are generally treated\nas black boxes, yielding no insight of the underlying learned patterns. In this\npaper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new\napproach for tracking the importance of a given input to the LSTM for a given\noutput. By identifying consistently important patterns of words, we are able to\ndistill state of the art LSTMs on sentiment analysis and question answering\ninto a set of representative phrases. This representation is then\nquantitatively validated by using the extracted phrases to construct a simple,\nrule-based classifier which approximates the output of the LSTM.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Automatic Rule Extraction from Long Short Term Memory Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Sebastian Gehrmann'}, {'name': 'Franck Dernoncourt'}, {'name': 'Yeran Li'}, {'name': 'Eric T. Carlson'}, {'name': 'Joy T. Wu'}, {'name': 'Jonathan Welt'}, {'name': 'John Foote Jr.'}, {'name': 'Edward T. Moseley'}, {'name': 'David W. Grant'}, {'name': 'Patrick D. Tyler'}, {'name': 'Leo Anthony Celi'}]",
//  "day": 25,
//  "id": "1703.08705v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.08705v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.08705v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}, {'name': 'Peter Szolovits'}]",
//  "day": 5,
//  "id": "1704.01523v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.01523v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.01523v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Over 50 million scholarly articles have been published: they constitute a\nunique repository of knowledge. In particular, one may infer from them\nrelations between scientific concepts, such as synonyms and hyponyms.\nArtificial neural networks have been recently explored for relation extraction.\nIn this work, we continue this line of work and present a system based on a\nconvolutional neural network to extract relations. Our model ranked first in\nthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific\narticles (subtask C).",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional\n  Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ji Young Lee'}, {'name': 'Franck Dernoncourt'}, {'name': 'Peter Szolovits'}]",
//  "day": 17,
//  "id": "1705.06273v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.06273v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.06273v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for named-entity recognition (NER). In order to achieve high\nperformances, ANNs need to be trained on a large labeled dataset. However,\nlabels might be difficult to obtain for the dataset on which the user wants to\nperform NER: label scarcity is particularly pronounced for patient note\nde-identification, which is an instance of NER. In this work, we analyze to\nwhat extent transfer learning may address this issue. In particular, we\ndemonstrate that transferring an ANN model trained on a large labeled dataset\nto another dataset with a limited number of labels improves upon the\nstate-of-the-art results on two different datasets for patient note\nde-identification.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Transfer Learning for Named-Entity Recognition with Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Sai Rajeswar'}, {'name': 'Sandeep Subramanian'}, {'name': 'Francis Dutil'}, {'name': 'Christopher Pal'}, {'name': 'Aaron Courville'}]",
//  "day": 31,
//  "id": "1705.10929v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10929v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10929v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Generative Adversarial Networks (GANs) have gathered a lot of attention from\nthe computer vision community, yielding impressive results for image\ngeneration. Advances in the adversarial generation of natural language from\nnoise however are not commensurate with the progress made in generating images,\nand still lag far behind likelihood based methods. In this paper, we take a\nstep towards generating natural language with a GAN objective alone. We\nintroduce a simple baseline that addresses the discrete output space problem\nwithout relying on gradient estimators and show that it is able to achieve\nstate-of-the-art results on a Chinese poem generation dataset. We present\nquantitative results on generating sentences from context-free and\nprobabilistic context-free grammars, and qualitative language modeling results.\nA conditional version is also described that can generate sequences conditioned\non sentence characteristics.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Adversarial Generation of Natural Language",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Leila Arras'}, {'name': 'Gr\u00e9goire Montavon'}, {'name': 'Klaus-Robert M\u00fcller'}, {'name': 'Wojciech Samek'}]",
//  "day": 22,
//  "id": "1706.07206v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.07206v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.07206v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Emmanuel Dufourq'}, {'name': 'Bruce A. Bassett'}]",
//  "day": 20,
//  "id": "1709.06990v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.06990v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.06990v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Can textual data be compressed intelligently without losing accuracy in\nevaluating sentiment? In this study, we propose a novel evolutionary\ncompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),\nwhich makes use of Parts-of-Speech tags to compress text in a way that\nsacrifices minimal classification accuracy when used in conjunction with\nsentiment analysis algorithms. An analysis of PARSEC with eight commercial and\nnon-commercial sentiment analysis algorithms on twelve English sentiment data\nsets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss\nin sentiment classification accuracy for (20%, 50%, 75%) data compression with\nPARSEC using LingPipe, the most accurate of the sentiment algorithms. Other\nsentiment analysis algorithms are more severely affected by compression. We\nconclude that significant compression of text data is possible for sentiment\nanalysis depending on the accuracy demands of the specific application and the\nspecific sentiment analysis algorithm used.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kartik Audhkhasi'}, {'name': 'Brian Kingsbury'}, {'name': 'Bhuvana Ramabhadran'}, {'name': 'George Saon'}, {'name': 'Michael Picheny'}]",
//  "day": 8,
//  "id": "1712.03133v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.03133v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.03133v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Huijuan Xu'}, {'name': 'Kate Saenko'}]",
//  "day": 17,
//  "id": "1511.05234v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.05234v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.05234v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We address the problem of Visual Question Answering (VQA), which requires\njoint image and language understanding to answer a question about a given\nphotograph. Recent approaches have applied deep image captioning methods based\non convolutional-recurrent networks to this problem, but have failed to model\nspatial inference. To remedy this, we propose a model we call the Spatial\nMemory Network and apply it to the VQA task. Memory networks are recurrent\nneural networks with an explicit attention mechanism that selects certain parts\nof the information stored in memory. Our Spatial Memory Network stores neuron\nactivations from different spatial regions of the image in its memory, and uses\nthe question to choose relevant regions for computing the answer, a process of\nwhich constitutes a single \"hop\" in the network. We propose a novel spatial\nattention architecture that aligns words with image patches in the first hop,\nand obtain improved results by adding a second attention hop which considers\nthe whole question to choose visual evidence based on the results of the first\nhop. To better understand the inference process learned by the network, we\ndesign synthetic questions that specifically require spatial inference and\nvisualize the attention weights. We evaluate our model on two published visual\nquestion answering datasets, DAQUAR [1] and VQA [2], and obtain improved\nresults compared to a strong deep baseline model (iBOWIMG) which concatenates\nimage and question features to predict the answer [3].",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for\n  Visual Question Answering",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Yuetan Lin'}, {'name': 'Zhangyang Pang'}, {'name': 'Donghui Wang'}, {'name': 'Yueting Zhuang'}]",
//  "day": 22,
//  "id": "1702.06700v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.06700v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.06700v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Visual question answering (VQA) has witnessed great progress since May, 2015\nas a classic problem unifying visual and textual data into a system. Many\nenlightening VQA works explore deep into the image and question encodings and\nfusing methods, of which attention is the most effective and infusive\nmechanism. Current attention based methods focus on adequate fusion of visual\nand textual features, but lack the attention to where people focus to ask\nquestions about the image. Traditional attention based methods attach a single\nvalue to the feature at each spatial location, which losses many useful\ninformation. To remedy these problems, we propose a general method to perform\nsaliency-like pre-selection on overlapped region features by the interrelation\nof bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication\nbased attention method to capture more competent correlation information\nbetween visual and textual features. We conduct experiments on the large-scale\nCOCO-VQA dataset and analyze the effectiveness of our model demonstrated by\nstrong empirical results.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Task-driven Visual Saliency and Attention-based Visual Question\n  Answering",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Akash Kumar Dhaka'}, {'name': 'Giampiero Salvi'}]",
//  "day": 29,
//  "id": "1606.09163v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.09163v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.09163v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We present a systematic analysis on the performance of a phonetic recogniser\nwhen the window of input features is not symmetric with respect to the current\nframe. The recogniser is based on Context Dependent Deep Neural Networks\n(CD-DNNs) and Hidden Markov Models (HMMs). The objective is to reduce the\nlatency of the system by reducing the number of future feature frames required\nto estimate the current output. Our tests performed on the TIMIT database show\nthat the performance does not degrade when the input window is shifted up to 5\nframes in the past compared to common practice (no future frame). This\ncorresponds to improving the latency by 50 ms in our settings. Our tests also\nshow that the best results are not obtained with the symmetric window commonly\nemployed, but with an asymmetric window with eight past and two future context\nframes, although this observation should be confirmed on other data sets. The\nreduction in latency suggested by our results is critical for specific\napplications such as real-time lip synchronisation for tele-presence, but may\nalso be beneficial in general applications to improve the lag in human-machine\nspoken interaction.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Optimising The Input Window Alignment in CD-DNN Based Phoneme\n  Recognition for Low Latency Processing",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Peng Qian'}, {'name': 'Xipeng Qiu'}, {'name': 'Xuanjing Huang'}]",
//  "day": 22,
//  "id": "1604.06635v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.06635v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.06635v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Bridging LSTM Architecture and the Neural Dynamics during Reading",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jiwei Li'}]",
//  "day": 11,
//  "id": "1412.3714v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.3714v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.3714v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "This paper addresses how a recursive neural network model can automatically\nleave out useless information and emphasize important evidence, in other words,\nto perform \"weight tuning\" for higher-level representation acquisition. We\npropose two models, Weighted Neural Network (WNN) and Binary-Expectation Neural\nNetwork (BENN), which automatically control how much one specific unit\ncontributes to the higher-level representation. The proposed model can be\nviewed as incorporating a more powerful compositional function for embedding\nacquisition in recursive neural networks. Experimental results demonstrate the\nsignificant improvement over standard neural models.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Feature Weight Tuning for Recursive Neural Networks",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Sadikin Mujiono'}, {'name': 'Mohamad Ivan Fanany'}, {'name': 'Chan Basaruddin'}]",
//  "day": 6,
//  "id": "1610.01891v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.01891v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.01891v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "One essential task in information extraction from the medical corpus is drug\nname recognition. Compared with text sources come from other domains, the\nmedical text is special and has unique characteristics. In addition, the\nmedical text mining poses more challenges, e.g., more unstructured text, the\nfast growing of new terms addition, a wide range of name variation for the same\ndrug. The mining is even more challenging due to the lack of labeled dataset\nsources and external knowledge, as well as multiple token representations for a\nsingle drug name that is more common in the real application setting. Although\nmany approaches have been proposed to overwhelm the task, some problems\nremained with poor F-score performance (less than 0.75). This paper presents a\nnew treatment in data representation techniques to overcome some of those\nchallenges. We propose three data representation techniques based on the\ncharacteristics of word distribution and word similarities as a result of word\nembedding training. The first technique is evaluated with the standard NN\nmodel, i.e., MLP (Multi-Layer Perceptrons). The second technique involves two\ndeep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked\nDenoising Encoders). The third technique represents the sentence as a sequence\nthat is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term\nMemory). In extracting the drug name entities, the third technique gives the\nbest F-score performance compared to the state of the art, with its average\nF-score being 0.8645.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68Txx', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A New Data Representation Based on Training Data Characteristics to\n  Extract Drug Named-Entity in Medical Text",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Eric Malmi'}, {'name': 'Pyry Takala'}, {'name': 'Hannu Toivonen'}, {'name': 'Tapani Raiko'}, {'name': 'Aristides Gionis'}]",
//  "day": 18,
//  "id": "1505.04771v2",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1145/2939672.2939679', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1505.04771v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1505.04771v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Writing rap lyrics requires both creativity to construct a meaningful,\ninteresting story and lyrical skills to produce complex rhyme patterns, which\nform the cornerstone of good flow. We present a rap lyrics generation method\nthat captures both of these aspects. First, we develop a prediction model to\nidentify the next line of existing lyrics from a set of candidate next lines.\nThis model is based on two machine-learning techniques: the RankSVM algorithm\nand a deep neural network model with a novel structure. Results show that the\nprediction model can identify the true next line among 299 randomly selected\nlines with an accuracy of 17%, i.e., over 50 times more likely than by random.\nSecond, we employ the prediction model to combine lines from existing songs,\nproducing lyrics with rhyme and a meaning. An evaluation of the produced lyrics\nshows that in terms of quantitative rhyme density, the method outperforms the\nbest human rappers by 21%. The rap lyrics generator has been deployed as an\nonline tool called DeepBeat, and the performance of the tool has been assessed\nby analyzing its usage logs. This analysis shows that machine-learned rankings\ncorrelate with user preferences.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7; H.3.3', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "DopeLearning: A Computational Approach to Rap Lyrics Generation",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Shengxian Wan'}, {'name': 'Yanyan Lan'}, {'name': 'Jun Xu'}, {'name': 'Jiafeng Guo'}, {'name': 'Liang Pang'}, {'name': 'Xueqi Cheng'}]",
//  "day": 15,
//  "id": "1604.04378v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1604.04378v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1604.04378v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Semantic matching, which aims to determine the matching degree between two\ntexts, is a fundamental problem for many NLP applications. Recently, deep\nlearning approach has been applied to this problem and significant improvements\nhave been achieved. In this paper, we propose to view the generation of the\nglobal interaction between two texts as a recursive process: i.e. the\ninteraction of two texts at each position is a composition of the interactions\nbetween their prefixes as well as the word level interaction at the current\nposition. Based on this idea, we propose a novel deep architecture, namely\nMatch-SRNN, to model the recursive matching structure. Firstly, a tensor is\nconstructed to capture the word level interactions. Then a spatial RNN is\napplied to integrate the local interactions recursively, with importance\ndetermined by four types of gates. Finally, the matching score is calculated\nbased on the global interaction. We show that, after degenerated to the exact\nmatching scenario, Match-SRNN can approximate the dynamic programming process\nof longest common subsequence. Thus, there exists a clear interpretation for\nMatch-SRNN. Our experiments on two semantic matching tasks showed the\neffectiveness of Match-SRNN, and its ability of visualizing the learned\nmatching structure.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Alexander G. Ororbia II'}, {'name': 'Joelle Pineau'}, {'name': 'Aaron Courville'}]",
//  "day": 1,
//  "id": "1612.00377v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.00377v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.00377v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Advances in neural variational inference have facilitated the learning of\npowerful directed graphical models with continuous latent variables, such as\nvariational autoencoders. The hope is that such models will learn to represent\nrich, multi-modal latent factors in real-world data, such as natural language\ntext. However, current models often assume simplistic priors on the latent\nvariables - such as the uni-modal Gaussian distribution - which are incapable\nof representing complex latent factors efficiently. To overcome this\nrestriction, we propose the simple, but highly flexible, piecewise constant\ndistribution. This distribution has the capacity to represent an exponential\nnumber of modes of a latent target distribution, while remaining mathematically\ntractable. Our results demonstrate that incorporating this new latent\ndistribution into different models yields substantial improvements in natural\nlanguage processing tasks such as document modeling and natural language\ngeneration for dialogue.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Piecewise Latent Variables for Neural Variational Text Processing",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Baolin Peng'}, {'name': 'Kaisheng Yao'}]",
//  "day": 31,
//  "id": "1506.00195v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.00195v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.00195v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Recurrent Neural Networks (RNNs) have become increasingly popular for the\ntask of language understanding. In this task, a semantic tagger is deployed to\nassociate a semantic label to each word in an input sequence. The success of\nRNN may be attributed to its ability to memorize long-term dependence that\nrelates the current-time semantic label prediction to the observations many\ntime instances away. However, the memory capacity of simple RNNs is limited\nbecause of the gradient vanishing and exploding problem. We propose to use an\nexternal memory to improve memorization capability of RNNs. We conducted\nexperiments on the ATIS dataset, and observed that the proposed model was able\nto achieve the state-of-the-art results. We compare our proposed model with\nalternative models and report analysis results that may provide insights for\nfuture research.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Recurrent Neural Networks with External Memory for Language\n  Understanding",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Alessandro Sordoni'}, {'name': 'Michel Galley'}, {'name': 'Michael Auli'}, {'name': 'Chris Brockett'}, {'name': 'Yangfeng Ji'}, {'name': 'Margaret Mitchell'}, {'name': 'Jian-Yun Nie'}, {'name': 'Jianfeng Gao'}, {'name': 'Bill Dolan'}]",
//  "day": 22,
//  "id": "1506.06714v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.06714v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.06714v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We present a novel response generation system that can be trained end to end\non large quantities of unstructured Twitter conversations. A neural network\narchitecture is used to address sparsity issues that arise when integrating\ncontextual information into classic statistical models, allowing the system to\ntake into account previous dialog utterances. Our dynamic-context generative\nmodels show consistent gains over both context-sensitive and\nnon-context-sensitive Machine Translation and Information Retrieval baselines.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Neural Network Approach to Context-Sensitive Generation of\n  Conversational Responses",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Ryan Lowe'}, {'name': 'Nissan Pow'}, {'name': 'Iulian Serban'}, {'name': 'Joelle Pineau'}]",
//  "day": 30,
//  "id": "1506.08909v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.08909v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.08909v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost\n1 million multi-turn dialogues, with a total of over 7 million utterances and\n100 million words. This provides a unique resource for research into building\ndialogue managers based on neural language models that can make use of large\namounts of unlabeled data. The dataset has both the multi-turn property of\nconversations in the Dialog State Tracking Challenge datasets, and the\nunstructured nature of interactions from microblog services such as Twitter. We\nalso describe two neural learning architectures suitable for analyzing this\ndataset, and provide benchmark performance on the task of selecting the best\nnext response.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured\n  Multi-Turn Dialogue Systems",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Iulian V. Serban'}, {'name': 'Alessandro Sordoni'}, {'name': 'Yoshua Bengio'}, {'name': 'Aaron Courville'}, {'name': 'Joelle Pineau'}]",
//  "day": 17,
//  "id": "1507.04808v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1507.04808v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1507.04808v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "We investigate the task of building open domain, conversational dialogue\nsystems based on large dialogue corpora using generative models. Generative\nmodels produce system responses that are autonomously generated word-by-word,\nopening up the possibility for realistic, flexible interactions. In support of\nthis goal, we extend the recently proposed hierarchical recurrent\nencoder-decoder neural network to the dialogue domain, and demonstrate that\nthis model is competitive with state-of-the-art neural language models and\nback-off n-gram models. We investigate the limitations of this and similar\napproaches, and show how its performance can be improved by bootstrapping the\nlearning from a larger question-answer pair corpus and from pretrained word\nembeddings.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Building End-To-End Dialogue Systems Using Generative Hierarchical\n  Neural Network Models",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Dzmitry Bahdanau'}, {'name': 'Jan Chorowski'}, {'name': 'Dmitriy Serdyuk'}, {'name': 'Philemon Brakel'}, {'name': 'Yoshua Bengio'}]",
//  "day": 18,
//  "id": "1508.04395v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.04395v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.04395v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Many of the current state-of-the-art Large Vocabulary Continuous Speech\nRecognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov\nModels (HMMs). Most of these systems contain separate components that deal with\nthe acoustic modelling, language modelling and sequence decoding. We\ninvestigate a more direct approach in which the HMM is replaced with a\nRecurrent Neural Network (RNN) that performs sequence prediction directly at\nthe character level. Alignment between the input features and the desired\ncharacter sequence is learned automatically by an attention mechanism built\ninto the RNN. For each predicted character, the attention mechanism scans the\ninput sequence and chooses relevant frames. We propose two methods to speed up\nthis operation: limiting the scan to a subset of most promising frames and\npooling over time the information contained in neighboring frames, thereby\nreducing source sequence length. Integrating an n-gram language model into the\ndecoding process yields recognition accuracies similar to other HMM-free\nRNN-based approaches.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "End-to-End Attention-based Large Vocabulary Speech Recognition",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Baolin Peng'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}, {'name': 'Kam-Fai Wong'}]",
//  "day": 22,
//  "id": "1508.05508v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.05508v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.05508v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We propose Neural Reasoner, a framework for neural network-based reasoning\nover natural language sentences. Given a question, Neural Reasoner can infer\nover multiple supporting facts and find an answer to the question in specific\nforms. Neural Reasoner has 1) a specific interaction-pooling mechanism,\nallowing it to examine multiple facts, and 2) a deep architecture, allowing it\nto model the complicated logical relations in reasoning tasks. Assuming no\nparticular structure exists in the question and facts, Neural Reasoner is able\nto accommodate different types of reasoning and different forms of language\nexpressions. Despite the model complexity, Neural Reasoner can still be trained\neffectively in an end-to-end manner. Our empirical studies show that Neural\nReasoner can outperform existing neural reasoning systems with remarkable\nmargins on two difficult artificial tasks (Positional Reasoning and Path\nFinding) proposed in [8]. For example, it improves the accuracy on Path\nFinding(10K) from 33.4% [6] to over 98%.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards Neural Network-based Reasoning",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Hongyuan Mei'}, {'name': 'Mohit Bansal'}, {'name': 'Matthew R. Walter'}]",
//  "day": 2,
//  "id": "1509.00838v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.00838v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.00838v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose an end-to-end, domain-independent neural encoder-aligner-decoder\nmodel for selective generation, i.e., the joint task of content selection and\nsurface realization. Our model first encodes a full set of over-determined\ndatabase event records via an LSTM-based recurrent neural network, then\nutilizes a novel coarse-to-fine aligner to identify the small subset of salient\nrecords to talk about, and finally employs a decoder to generate free-form\ndescriptions of the aligned, selected records. Our model achieves the best\nselection and generation results reported to-date (with 59% relative\nimprovement in generation) on the benchmark WeatherGov dataset, despite using\nno specialized features or linguistic resources. Using an improved k-nearest\nneighbor beam filter helps further. We also perform a series of ablations and\nvisualizations to elucidate the contributions of our key model components.\nLastly, we evaluate the generalizability of our model on the RoboCup dataset,\nand get results that are competitive with or better than the state-of-the-art,\ndespite being severely data-starved.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "What to talk about and how? Selective Generation using LSTMs with\n  Coarse-to-Fine Alignment",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Tim Rockt\u00e4schel'}, {'name': 'Edward Grefenstette'}, {'name': 'Karl Moritz Hermann'}, {'name': 'Tom\u00e1\u0161 Ko\u010disk\u00fd'}, {'name': 'Phil Blunsom'}]",
//  "day": 22,
//  "id": "1509.06664v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.06664v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.06664v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Reasoning about Entailment with Neural Attention",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Yu Zhang'}, {'name': 'Guoguo Chen'}, {'name': 'Dong Yu'}, {'name': 'Kaisheng Yao'}, {'name': 'Sanjeev Khudanpur'}, {'name': 'James Glass'}]",
//  "day": 30,
//  "id": "1510.08983v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.08983v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.08983v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "In this paper, we extend the deep long short-term memory (DLSTM) recurrent\nneural networks by introducing gated direct connections between memory cells in\nadjacent layers. These direct links, called highway connections, enable\nunimpeded information flow across different layers and thus alleviate the\ngradient vanishing problem when building deeper LSTMs. We further introduce the\nlatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole\nhistory while keeping the latency under control. Efficient algorithms are\nproposed to train these novel networks using both frame and sequence\ndiscriminative criteria. Experiments on the AMI distant speech recognition\n(DSR) task indicate that we can train deeper LSTMs and achieve better\nimprovement from sequence training with highway LSTMs (HLSTMs). Our novel model\nobtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all\nprevious works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and\n$5.3\\%$ relative improvement respectively.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Highway Long Short-Term Memory RNNs for Distant Speech Recognition",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Pengcheng Yin'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}, {'name': 'Ben Kao'}]",
//  "day": 3,
//  "id": "1512.00965v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1512.00965v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1512.00965v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We proposed Neural Enquirer as a neural network architecture to execute a\nnatural language (NL) query on a knowledge-base (KB) for answers. Basically,\nNeural Enquirer finds the distributed representation of a query and then\nexecutes it on knowledge-base tables to obtain the answer as one of the values\nin the tables. Unlike similar efforts in end-to-end training of semantic\nparsers, Neural Enquirer is fully \"neuralized\": it not only gives\ndistributional representation of the query and the knowledge-base, but also\nrealizes the execution of compositional queries as a series of differentiable\noperations, with intermediate results (consisting of annotations of the tables\nat different levels) saved on multiple layers of memory. Neural Enquirer can be\ntrained with gradient descent, with which not only the parameters of the\ncontrolling components and semantic parsing component, but also the embeddings\nof the tables and query words can be learned from scratch. The training can be\ndone in an end-to-end fashion, but it can take stronger guidance, e.g., the\nstep-by-step supervision for complicated queries, and benefit from it. Neural\nEnquirer is one step towards building neural network systems which seek to\nunderstand language by executing it on real-world. Our experiments show that\nNeural Enquirer can learn to execute fairly complicated NL queries on tables\nwith rich structures.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Enquirer: Learning to Query Tables with Natural Language",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Petr Baudi\u0161'}, {'name': 'Jan Pichl'}, {'name': 'Tom\u00e1\u0161 Vysko\u010dil'}, {'name': 'Jan \u0160ediv\u00fd'}]",
//  "day": 19,
//  "id": "1603.06127v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.06127v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.06127v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We review the task of Sentence Pair Scoring, popular in the literature in\nvarious forms - viewed as Answer Sentence Selection, Semantic Text Scoring,\nNext Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. a\ncomponent of Memory Networks.\n  We argue that all such tasks are similar from the model perspective and\npropose new baselines by comparing the performance of common IR metrics and\npopular convolutional, recurrent and attention-based neural models across many\nSentence Pair Scoring tasks and datasets. We discuss the problem of evaluating\nrandomized models, propose a statistically grounded methodology, and attempt to\nimprove comparisons by releasing new datasets that are much harder than some of\nthe currently used well explored benchmarks. We introduce a unified open source\nsoftware framework with easily pluggable models and tasks, which enables us to\nexperiment with multi-task reusability of trained sentence model. We set a new\nstate-of-art in performance on the Ubuntu Dialogue dataset.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sentence Pair Scoring: Towards Unified Framework for Text Comprehension",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jiatao Gu'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}, {'name': 'Victor O. K. Li'}]",
//  "day": 21,
//  "id": "1603.06393v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.06393v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.06393v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We address an important problem in sequence-to-sequence (Seq2Seq) learning\nreferred to as copying, in which certain segments in the input sequence are\nselectively replicated in the output sequence. A similar phenomenon is\nobservable in human language communication. For example, humans tend to repeat\nentity names or even long phrases in conversation. The challenge with regard to\ncopying in Seq2Seq is that new machinery is needed to decide when to perform\nthe operation. In this paper, we incorporate copying into neural network-based\nSeq2Seq learning and propose a new model called CopyNet with encoder-decoder\nstructure. CopyNet can nicely integrate the regular way of word generation in\nthe decoder with the new copying mechanism which can choose sub-sequences in\nthe input sequence and put them at proper places in the output sequence. Our\nempirical study on both synthetic data sets and real world data sets\ndemonstrates the efficacy of CopyNet. For example, CopyNet can outperform\nregular RNN-based model with remarkable margins on text summarization tasks.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Iulian Vlad Serban'}, {'name': 'Alberto Garc\u00eda-Dur\u00e1n'}, {'name': 'Caglar Gulcehre'}, {'name': 'Sungjin Ahn'}, {'name': 'Sarath Chandar'}, {'name': 'Aaron Courville'}, {'name': 'Yoshua Bengio'}]",
//  "day": 22,
//  "id": "1603.06807v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.06807v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.06807v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Over the past decade, large-scale supervised learning corpora have enabled\nmachine learning researchers to make substantial advances. However, to this\ndate, there are no large-scale question-answer corpora available. In this paper\nwe present the 30M Factoid Question-Answer Corpus, an enormous question answer\npair corpus produced by applying a novel neural network architecture on the\nknowledge base Freebase to transduce facts into natural language questions. The\nproduced question answer pairs are evaluated both by human evaluators and using\nautomatic evaluation metrics, including well-established machine translation\nand sentence similarity metrics. Across all evaluation criteria the\nquestion-generation model outperforms the competing template-based baseline.\nFurthermore, when presented to human evaluators, the generated questions appear\ncomparable in quality to real human-generated questions.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.3.4; I.5.1; I.2.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generating Factoid Questions With Recurrent Neural Networks: The 30M\n  Factoid Question-Answer Corpus",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Chia-Wei Liu'}, {'name': 'Ryan Lowe'}, {'name': 'Iulian V. Serban'}, {'name': 'Michael Noseworthy'}, {'name': 'Laurent Charlin'}, {'name': 'Joelle Pineau'}]",
//  "day": 25,
//  "id": "1603.08023v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.08023v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.08023v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We investigate evaluation metrics for dialogue response generation systems\nwhere supervised labels, such as task completion, are not available. Recent\nworks in response generation have adopted metrics from machine translation to\ncompare a model's generated response to a single target response. We show that\nthese metrics correlate very weakly with human judgements in the non-technical\nTwitter domain, and not at all in the technical Ubuntu domain. We provide\nquantitative and qualitative results highlighting specific weaknesses in\nexisting metrics, and provide recommendations for future development of better\nautomatic evaluation metrics for dialogue systems.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "How NOT To Evaluate Your Dialogue System: An Empirical Study of\n  Unsupervised Evaluation Metrics for Dialogue Response Generation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Iulian Vlad Serban'}, {'name': 'Alessandro Sordoni'}, {'name': 'Ryan Lowe'}, {'name': 'Laurent Charlin'}, {'name': 'Joelle Pineau'}, {'name': 'Aaron Courville'}, {'name': 'Yoshua Bengio'}]",
//  "day": 19,
//  "id": "1605.06069v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.06069v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.06069v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Sequential data often possesses a hierarchical structure with complex\ndependencies between subsequences, such as found between the utterances in a\ndialogue. In an effort to model this kind of generative process, we propose a\nneural network-based generative architecture, with latent stochastic variables\nthat span a variable number of time steps. We apply the proposed model to the\ntask of dialogue response generation and compare it with recent neural network\narchitectures. We evaluate the model performance through automatic evaluation\nmetrics and by carrying out a human evaluation. The experiments demonstrate\nthat our model improves upon recently proposed models and that the latent\nvariables facilitate the generation of long outputs and maintain the context.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5.1; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating\n  Dialogues",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Dirk Weissenborn'}]",
//  "day": 13,
//  "id": "1606.03864v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.03864v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.03864v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Associative Memory for Dual-Sequence Modeling",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Marc Dymetman'}, {'name': 'Chunyang Xiao'}]",
//  "day": 8,
//  "id": "1607.02467v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1607.02467v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1607.02467v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "We introduce LL-RNNs (Log-Linear RNNs), an extension of Recurrent Neural\nNetworks that replaces the softmax output layer by a log-linear output layer,\nof which the softmax is a special case. This conceptually simple move has two\nmain advantages. First, it allows the learner to combat training data sparsity\nby allowing it to model words (or more generally, output symbols) as complex\ncombinations of attributes without requiring that each combination is directly\nobserved in the training data (as the softmax does). Second, it permits the\ninclusion of flexible prior knowledge in the form of a priori specified modular\nfeatures, where the neural network component learns to dynamically control the\nweights of a log-linear distribution exploiting these features.\n  We conduct experiments in the domain of language modelling of French, that\nexploit morphological prior knowledge and show an important decrease in\nperplexity relative to a baseline RNN.\n  We provide other motivating iillustrations, and finally argue that the\nlog-linear and the neural-network components contribute complementary strengths\nto the LL-RNN: the LL aspect allows the model to incorporate rich prior\nknowledge, while the NN aspect, according to the \"representation learning\"\nparadigm, allows the model to discover novel combination of characteristics.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Log-Linear RNNs: Towards Recurrent Neural Networks with Flexible Prior\n  Knowledge",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Ondrej Bajgar'}, {'name': 'Rudolf Kadlec'}, {'name': 'Jan Kleindienst'}]",
//  "day": 4,
//  "id": "1610.00956v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.00956v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.00956v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "There is a practically unlimited amount of natural language data available.\nStill, recent work in text comprehension has focused on datasets which are\nsmall relative to current computing possibilities. This article is making a\ncase for the community to move to larger data and as a step in that direction\nit is proposing the BookTest, a new dataset similar to the popular Children's\nBook Test (CBT), however more than 60 times larger. We show that training on\nthe new data improves the accuracy of our Attention-Sum Reader model on the\noriginal CBT test data by a much larger margin than many recent attempts to\nimprove the model architecture. On one version of the dataset our ensemble even\nexceeds the human baseline provided by Facebook. We then show in our own human\nstudy that there is still space for further improvement.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Embracing data abundance: BookTest Dataset for Reading Comprehension",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'James Bradbury'}, {'name': 'Stephen Merity'}, {'name': 'Caiming Xiong'}, {'name': 'Richard Socher'}]",
//  "day": 5,
//  "id": "1611.01576v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.01576v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.01576v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Recurrent neural networks are a powerful tool for modeling sequential data,\nbut the dependence of each timestep's computation on the previous timestep's\noutput limits parallelism and makes RNNs unwieldy for very long sequences. We\nintroduce quasi-recurrent neural networks (QRNNs), an approach to neural\nsequence modeling that alternates convolutional layers, which apply in parallel\nacross timesteps, and a minimalist recurrent pooling function that applies in\nparallel across channels. Despite lacking trainable recurrent layers, stacked\nQRNNs have better predictive accuracy than stacked LSTMs of the same hidden\nsize. Due to their increased parallelism, they are up to 16 times faster at\ntrain and test time. Experiments on language modeling, sentiment\nclassification, and character-level neural machine translation demonstrate\nthese advantages and underline the viability of QRNNs as a basic building block\nfor a variety of sequence tasks.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Quasi-Recurrent Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jakob N. Foerster'}, {'name': 'Justin Gilmer'}, {'name': 'Jan Chorowski'}, {'name': 'Jascha Sohl-Dickstein'}, {'name': 'David Sussillo'}]",
//  "day": 28,
//  "id": "1611.09434v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.09434v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.09434v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "There exist many problem domains where the interpretability of neural network\nmodels is essential for deployment. Here we introduce a recurrent architecture\ncomposed of input-switched affine transformations - in other words an RNN\nwithout any explicit nonlinearities, but with input-dependent recurrent\nweights. This simple form allows the RNN to be analyzed via straightforward\nlinear methods: we can exactly characterize the linear contribution of each\ninput to the model predictions; we can use a change-of-basis to disentangle\ninput, output, and computational hidden unit subspaces; we can fully\nreverse-engineer the architecture's solution to a simple task. Despite this\nease of interpretation, the input switched affine network achieves reasonable\nperformance on a text modeling tasks, and allows greater computational\nefficiency than networks with standard nonlinearities.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Input Switched Affine Networks: An RNN Architecture Designed for\n  Interpretability",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Micha\u0142 Daniluk'}, {'name': 'Tim Rockt\u00e4schel'}, {'name': 'Johannes Welbl'}, {'name': 'Sebastian Riedel'}]",
//  "day": 15,
//  "id": "1702.04521v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.04521v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.04521v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Neural language models predict the next token using a latent representation\nof the immediate token history. Recently, various methods for augmenting neural\nlanguage models with an attention mechanism over a differentiable memory have\nbeen proposed. For predicting the next token, these models query information\nfrom a memory of the recent history which can facilitate learning mid- and\nlong-range dependencies. However, conventional attention mechanisms used in\nmemory-augmented neural language models produce a single output vector per time\nstep. This vector is used both for predicting the next token as well as for the\nkey and value of a differentiable memory of a token history. In this paper, we\npropose a neural language model with a key-value attention mechanism that\noutputs separate representations for the key and value of a differentiable\nmemory, as well as for encoding the next-word distribution. This model\noutperforms existing memory-augmented neural language models on two corpora.\nYet, we found that our method mainly utilizes a memory of the five most recent\noutput representations. This led to the unexpected main finding that a much\nsimpler model based only on the concatenation of recent output representations\nfrom previous time steps is on par with more sophisticated memory-augmented\nneural language models.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Frustratingly Short Attention Spans in Neural Language Modeling",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhouhan Lin'}, {'name': 'Minwei Feng'}, {'name': 'Cicero Nogueira dos Santos'}, {'name': 'Mo Yu'}, {'name': 'Bing Xiang'}, {'name': 'Bowen Zhou'}, {'name': 'Yoshua Bengio'}]",
//  "day": 9,
//  "id": "1703.03130v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.03130v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.03130v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Structured Self-attentive Sentence Embedding",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Samuel R\u00f6nnqvist'}, {'name': 'Niko Schenk'}, {'name': 'Christian Chiarcos'}]",
//  "day": 26,
//  "id": "1704.08092v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.18653/v1/P17-2040', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08092v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08092v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "We introduce an attention-based Bi-LSTM for Chinese implicit discourse\nrelations and demonstrate that modeling argument pairs as a joint sequence can\noutperform word order-agnostic approaches. Our model benefits from a partial\nsampling scheme and is conceptually simple, yet achieves state-of-the-art\nperformance on the Chinese Discourse Treebank. We also visualize its attention\nactivity to illustrate the model's ability to selectively focus on the relevant\nparts of an input sequence.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Recurrent Neural Model with Attention for the Recognition of Chinese\n  Implicit Discourse Relations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Lara J. Martin'}, {'name': 'Prithviraj Ammanabrolu'}, {'name': 'Xinyu Wang'}, {'name': 'William Hancock'}, {'name': 'Shruti Singh'}, {'name': 'Brent Harrison'}, {'name': 'Mark O. Riedl'}]",
//  "day": 5,
//  "id": "1706.01331v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.01331v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.01331v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Automated story generation is the problem of automatically selecting a\nsequence of events, actions, or words that can be told as a story. We seek to\ndevelop a system that can generate stories by learning everything it needs to\nknow from textual story corpora. To date, recurrent neural networks that learn\nlanguage models at character, word, or sentence levels have had little success\ngenerating coherent stories. We explore the question of event representations\nthat provide a mid-level of abstraction between words and sentences in order to\nretain the semantic information of the original data while minimizing event\nsparsity. We present a technique for preprocessing textual story data into\nevent sequences. We then present a technique for automated story generation\nwhereby we decompose the problem into the generation of successive events\n(event2event) and the generation of natural language sentences from events\n(event2sentence). We give empirical results comparing different event\nrepresentations and their effects on event successor generation and the\ntranslation of events to natural language.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Event Representations for Automated Story Generation with Deep Neural\n  Nets",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Tong Wang'}, {'name': 'Xingdi Yuan'}, {'name': 'Adam Trischler'}]",
//  "day": 5,
//  "id": "1706.01450v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.01450v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.01450v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We propose a generative machine comprehension model that learns jointly to\nask and answer questions based on documents. The proposed model uses a\nsequence-to-sequence framework that encodes the document and generates a\nquestion (answer) given an answer (question). Significant improvement in model\nperformance is observed empirically on the SQuAD corpus, confirming our\nhypothesis that the model benefits from jointly learning to perform both tasks.\nWe believe the joint model's novelty offers a new perspective on machine\ncomprehension beyond architectural engineering, and serves as a first step\ntowards autonomous information seeking.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Joint Model for Question Answering and Question Generation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Wei Wen'}, {'name': 'Yuxiong He'}, {'name': 'Samyam Rajbhandari'}, {'name': 'Minjia Zhang'}, {'name': 'Wenhan Wang'}, {'name': 'Fang Liu'}, {'name': 'Bin Hu'}, {'name': 'Yiran Chen'}, {'name': 'Hai Li'}]",
//  "day": 15,
//  "id": "1709.05027v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.05027v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.05027v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Model compression is significant for the wide adoption of Recurrent Neural\nNetworks (RNNs) in both user devices possessing limited resources and business\nclusters requiring quick responses to large-scale service requests. This work\naims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the\nsizes of basic structures within LSTM units, including input updates, gates,\nhidden states, cell states and outputs. Independently reducing the sizes of\nbasic structures can result in inconsistent dimensions among them, and\nconsequently, end up with invalid LSTM units. To overcome the problem, we\npropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS\nwill simultaneously decrease the sizes of all basic structures by one and\nthereby always maintain the dimension consistency. By learning ISS within LSTM\nunits, the obtained LSTMs remain regular while having much smaller basic\nstructures. Based on group Lasso regularization, our method achieves 10.59x\nspeedup without losing any perplexity of a language modeling of Penn TreeBank\ndataset. It is also successfully evaluated through a compact model with only\n2.69M weights for machine Question Answering of SQuAD dataset. Our approach is\nsuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks\n(RHNs). Our source code is publicly available at\nhttps://github.com/wenwei202/iss-rnns",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Intrinsic Sparse Structures within Long Short-Term Memory",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Huda Hakami'}, {'name': 'Danushka Bollegala'}, {'name': 'Hayashi Kohei'}]",
//  "day": 19,
//  "id": "1709.06673v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.06673v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.06673v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Representing the semantic relations that exist between two given words (or\nentities) is an important first step in a wide-range of NLP applications such\nas analogical reasoning, knowledge base completion and relational information\nretrieval. A simple, yet surprisingly accurate method for representing a\nrelation between two words is to compute the vector offset (\\PairDiff) between\ntheir corresponding word embeddings. Despite the empirical success, it remains\nunclear as to whether \\PairDiff is the best operator for obtaining a relational\nrepresentation from word embeddings. We conduct a theoretical analysis of\ngeneralised bilinear operators that can be used to measure the $\\ell_{2}$\nrelational distance between two word-pairs. We show that, if the word\nembeddings are standardised and uncorrelated, such an operator will be\nindependent of bilinear terms, and can be simplified to a linear form, where\n\\PairDiff is a special case. For numerous word embedding types, we empirically\nverify the uncorrelation assumption, demonstrating the general applicability of\nour theoretical result. Moreover, we experimentally discover \\PairDiff from the\nbilinear relation composition operator on several benchmark analogy datasets.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational\n  Compositional Operators for Analogy Detection",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhengdong Lu'}, {'name': 'Haotian Cui'}, {'name': 'Xianggen Liu'}, {'name': 'Yukun Yan'}, {'name': 'Daqi Zheng'}]",
//  "day": 26,
//  "id": "1709.08853v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.08853v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.08853v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose Object-oriented Neural Programming (OONP), a framework for\nsemantically parsing documents in specific domains. Basically, OONP reads a\ndocument and parses it into a predesigned object-oriented data structure\n(referred to as ontology in this paper) that reflects the domain-specific\nsemantics of the document. An OONP parser models semantic parsing as a decision\nprocess: a neural net-based Reader sequentially goes through the document, and\nduring the process it builds and updates an intermediate ontology to summarize\nits partial understanding of the text it covers. OONP supports a rich family of\noperations (both symbolic and differentiable) for composing the ontology, and a\nbig variety of forms (both symbolic and differentiable) for representing the\nstate and the document. An OONP parser can be trained with supervision of\ndifferent forms and strength, including supervised learning (SL) ,\nreinforcement learning (RL) and hybrid of the two. Our experiments on both\nsynthetic and real-world document parsing tasks have shown that OONP can learn\nto handle fairly complicated ontology with training data of modest sizes.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Object-oriented Neural Programming (OONP) for Document Understanding",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Bin Bi'}, {'name': 'Hao Ma'}]",
//  "day": 29,
//  "id": "1709.10204v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.10204v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.10204v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "This paper proposes a novel neural machine reading model for open-domain\nquestion answering at scale. Existing machine comprehension models typically\nassume that a short piece of relevant text containing answers is already\nidentified and given to the models, from which the models are designed to\nextract answers. This assumption, however, is not realistic for building a\nlarge-scale open-domain question answering system which requires both deep text\nunderstanding and identifying relevant text from corpus simultaneously.\n  In this paper, we introduce Neural Comprehensive Ranker (NCR) that integrates\nboth passage ranking and answer extraction in one single framework. A Q&A\nsystem based on this framework allows users to issue an open-domain question\nwithout needing to provide a piece of text that must contain the answer.\nExperiments show that the unified NCR model is able to outperform the\nstates-of-the-art in both retrieval of relevant text and answer extraction.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mirco Ravanelli'}, {'name': 'Philemon Brakel'}, {'name': 'Maurizio Omologo'}, {'name': 'Yoshua Bengio'}]",
//  "day": 29,
//  "id": "1710.00641v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.00641v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.00641v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Speech recognition is largely taking advantage of deep learning, showing that\nsubstantial benefits can be obtained by modern Recurrent Neural Networks\n(RNNs). The most popular RNNs are Long Short-Term Memory (LSTMs), which\ntypically reach state-of-the-art performance in many tasks thanks to their\nability to learn long-term dependencies and robustness to vanishing gradients.\nNevertheless, LSTMs have a rather complex design with three multiplicative\ngates, that might impair their efficient implementation. An attempt to simplify\nLSTMs has recently led to Gated Recurrent Units (GRUs), which are based on just\ntwo multiplicative gates.\n  This paper builds on these efforts by further revising GRUs and proposing a\nsimplified architecture potentially more suitable for speech recognition. The\ncontribution of this work is two-fold. First, we suggest to remove the reset\ngate in the GRU design, resulting in a more efficient single-gate architecture.\nSecond, we propose to replace tanh with ReLU activations in the state update\nequations. Results show that, in our implementation, the revised architecture\nreduces the per-epoch training time with more than 30% and consistently\nimproves recognition performance across different tasks, input features, and\nnoisy conditions when compared to a standard GRU.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Improving speech recognition by revising gated recurrent units",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Baolin Peng'}, {'name': 'Xiujun Li'}, {'name': 'Jianfeng Gao'}, {'name': 'Jingjing Liu'}, {'name': 'Kam-Fai Wong'}]",
//  "day": 18,
//  "id": "1801.06176v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.06176v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.06176v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Training a task-completion dialogue agent with real users via reinforcement\nlearning (RL) could be prohibitively expensive, because it requires many\ninteractions with users. One alternative is to resort to a user simulator,\nwhile the discrepancy of between simulated and real users makes the learned\npolicy unreliable in practice. This paper addresses these challenges by\nintegrating planning into the dialogue policy learning based on Dyna-Q\nframework, and provides a more sample-efficient approach to learn the dialogue\npolices. The proposed agent consists of a planner trained on-line with limited\nreal user experience that can generate large amounts of simulated experience to\nsupplement with limited real user experience, and a policy model trained on\nthese hybrid experiences. The effectiveness of our approach is validated on a\nmovie-booking task in both a simulation setting and a human-in-the-loop\nsetting.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Integrating planning for task-completion dialogue policy learning",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Andrew L. Maas'}, {'name': 'Peng Qi'}, {'name': 'Ziang Xie'}, {'name': 'Awni Y. Hannun'}, {'name': 'Christopher T. Lengerich'}, {'name': 'Daniel Jurafsky'}, {'name': 'Andrew Y. Ng'}]",
//  "day": 30,
//  "id": "1406.7806v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1406.7806v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1406.7806v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Deep neural networks (DNNs) are now a central component of nearly all\nstate-of-the-art speech recognition systems. Building neural network acoustic\nmodels requires several design decisions including network architecture, size,\nand training loss function. This paper offers an empirical investigation on\nwhich aspects of DNN acoustic model design are most important for speech\nrecognition system performance. We report DNN classifier performance and final\nspeech recognizer word error rates, and compare DNNs using several metrics to\nquantify factors influencing differences in task performance. Our first set of\nexperiments use the standard Switchboard benchmark corpus, which contains\napproximately 300 hours of conversational telephone speech. We compare standard\nDNNs to convolutional networks, and present the first experiments using\nlocally-connected, untied neural networks for acoustic modeling. We\nadditionally build systems on a corpus of 2,100 hours of training data by\ncombining the Switchboard and Fisher corpora. This larger corpus allows us to\nmore thoroughly examine performance of large DNN models -- with up to ten times\nmore parameters than those typically used in speech recognition systems. Our\nresults suggest that a relatively simple DNN architecture and optimization\ntechnique produces strong results. These findings, along with previous work,\nhelp establish a set of best practices for building DNN hybrid speech\nrecognition systems with maximum likelihood training. Our experiments in DNN\noptimization additionally serve as a case study for training DNNs with\ndiscriminative loss functions for speech tasks, as well as DNN classifiers more\ngenerally.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Building DNN Acoustic Models for Large Vocabulary Speech Recognition",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'William Chan'}, {'name': 'Ian Lane'}]",
//  "day": 7,
//  "id": "1504.01482v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.01482v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.01482v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "We present a novel deep Recurrent Neural Network (RNN) model for acoustic\nmodelling in Automatic Speech Recognition (ASR). We term our contribution as a\nTC-DNN-BLSTM-DNN model, the model combines a Deep Neural Network (DNN) with\nTime Convolution (TC), followed by a Bidirectional Long Short-Term Memory\n(BLSTM), and a final DNN. The first DNN acts as a feature processor to our\nmodel, the BLSTM then generates a context from the sequence acoustic signal,\nand the final DNN takes the context and models the posterior probabilities of\nthe acoustic states. We achieve a 3.47 WER on the Wall Street Journal (WSJ)\neval92 task or more than 8% relative improvement over the baseline DNN models.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Recurrent Neural Networks for Acoustic Modelling",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'David Krueger'}, {'name': 'Roland Memisevic'}]",
//  "day": 26,
//  "id": "1511.08400v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.08400v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.08400v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We stabilize the activations of Recurrent Neural Networks (RNNs) by\npenalizing the squared distance between successive hidden states' norms.\n  This penalty term is an effective regularizer for RNNs including LSTMs and\nIRNNs, improving performance on character-level language modeling and phoneme\nrecognition, and outperforming weight noise and dropout.\n  We achieve competitive performance (18.6\\% PER) on the TIMIT phoneme\nrecognition task for RNNs evaluated without beam search or an RNN transducer.\n  With this penalty term, IRNN can achieve similar performance to LSTM on\nlanguage modeling, although adding the penalty term to the LSTM results in\nsuperior performance.\n  Our penalty term also prevents the exponential growth of IRNN's activations\noutside of their training horizon, allowing them to generalize to much longer\nsequences.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Regularizing RNNs by Stabilizing Activations",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Noam Shazeer'}, {'name': 'Azalia Mirhoseini'}, {'name': 'Krzysztof Maziarz'}, {'name': 'Andy Davis'}, {'name': 'Quoc Le'}, {'name': 'Geoffrey Hinton'}, {'name': 'Jeff Dean'}]",
//  "day": 23,
//  "id": "1701.06538v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.06538v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.06538v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "The capacity of a neural network to absorb information is limited by its\nnumber of parameters. Conditional computation, where parts of the network are\nactive on a per-example basis, has been proposed in theory as a way of\ndramatically increasing model capacity without a proportional increase in\ncomputation. In practice, however, there are significant algorithmic and\nperformance challenges. In this work, we address these challenges and finally\nrealize the promise of conditional computation, achieving greater than 1000x\nimprovements in model capacity with only minor losses in computational\nefficiency on modern GPU clusters. We introduce a Sparsely-Gated\nMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward\nsub-networks. A trainable gating network determines a sparse combination of\nthese experts to use for each example. We apply the MoE to the tasks of\nlanguage modeling and machine translation, where model capacity is critical for\nabsorbing the vast quantities of knowledge available in the training corpora.\nWe present model architectures in which a MoE with up to 137 billion parameters\nis applied convolutionally between stacked LSTM layers. On large language\nmodeling and machine translation benchmarks, these models achieve significantly\nbetter results than state-of-the-art at lower computational cost.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Outrageously Large Neural Networks: The Sparsely-Gated\n  Mixture-of-Experts Layer",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yacine Jernite'}, {'name': 'Samuel R. Bowman'}, {'name': 'David Sontag'}]",
//  "day": 23,
//  "id": "1705.00557v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.00557v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.00557v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "This work presents a novel objective function for the unsupervised training\nof neural network sentence encoders. It exploits signals from paragraph-level\ndiscourse coherence to train these models to understand text. Our objective is\npurely discriminative, allowing us to train models many times faster than was\npossible under prior methods, and it yields models which perform well in\nextrinsic evaluations.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Discourse-Based Objectives for Fast Unsupervised Sentence Representation\n  Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhengyang Wang'}, {'name': 'Shuiwang Ji'}]",
//  "day": 18,
//  "id": "1705.06824v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.06824v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.06824v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Visual question answering is a recently proposed artificial intelligence task\nthat requires a deep understanding of both images and texts. In deep learning,\nimages are typically modeled through convolutional neural networks, and texts\nare typically modeled through recurrent neural networks. While the requirement\nfor modeling images is similar to traditional computer vision tasks, such as\nobject recognition and image classification, visual question answering raises a\ndifferent need for textual representation as compared to other natural language\nprocessing tasks. In this work, we perform a detailed analysis on natural\nlanguage questions in visual question answering. Based on the analysis, we\npropose to rely on convolutional neural networks for learning textual\nrepresentations. By exploring the various properties of convolutional neural\nnetworks specialized for text data, such as width and depth, we present our\n\"CNN Inception + Gate\" model. We show that our model improves question\nrepresentations and thus the overall accuracy of visual question answering\nmodels. We also show that the text representation requirement in visual\nquestion answering is more complicated and comprehensive than that in\nconventional natural language processing tasks, making it a better task to\nevaluate textual representation methods. Shallow models like fastText, which\ncan obtain comparable results with deep learning models in tasks like text\nclassification, are not suitable in visual question answering.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Convolutional Text Representations for Visual Question\n  Answering",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kyunghyun Cho'}, {'name': 'Bart van Merrienboer'}, {'name': 'Caglar Gulcehre'}, {'name': 'Dzmitry Bahdanau'}, {'name': 'Fethi Bougares'}, {'name': 'Holger Schwenk'}, {'name': 'Yoshua Bengio'}]",
//  "day": 3,
//  "id": "1406.1078v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1406.1078v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1406.1078v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "In this paper, we propose a novel neural network model called RNN\nEncoder-Decoder that consists of two recurrent neural networks (RNN). One RNN\nencodes a sequence of symbols into a fixed-length vector representation, and\nthe other decodes the representation into another sequence of symbols. The\nencoder and decoder of the proposed model are jointly trained to maximize the\nconditional probability of a target sequence given a source sequence. The\nperformance of a statistical machine translation system is empirically found to\nimprove by using the conditional probabilities of phrase pairs computed by the\nRNN Encoder-Decoder as an additional feature in the existing log-linear model.\nQualitatively, we show that the proposed model learns a semantically and\nsyntactically meaningful representation of linguistic phrases.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Phrase Representations using RNN Encoder-Decoder for\n  Statistical Machine Translation",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Zhiyuan Tang'}, {'name': 'Dong Wang'}, {'name': 'Zhiyong Zhang'}]",
//  "day": 18,
//  "id": "1505.04630v5",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/ICASSP.2016.7472809', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1505.04630v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1505.04630v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Recurrent neural networks (RNNs), particularly long short-term memory (LSTM),\nhave gained much attention in automatic speech recognition (ASR). Although some\nsuccessful stories have been reported, training RNNs remains highly\nchallenging, especially with limited training data. Recent research found that\na well-trained model can be used as a teacher to train other child models, by\nusing the predictions generated by the teacher model as supervision. This\nknowledge transfer learning has been employed to train simple neural nets with\na complex one, so that the final performance can reach a level that is\ninfeasible to obtain by regular training. In this paper, we employ the\nknowledge transfer learning approach to train RNNs (precisely LSTM) using a\ndeep neural network (DNN) model as the teacher. This is different from most of\nthe existing research on knowledge transfer learning, since the teacher (DNN)\nis assumed to be weaker than the child (RNN); however, our experiments on an\nASR task showed that it works fairly well: without applying any tricks on the\nlearning scheme, this approach can train RNNs successfully even with limited\ntraining data.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Recurrent Neural Network Training with Dark Knowledge Transfer",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Ha\u015fim Sak'}, {'name': 'Andrew Senior'}, {'name': 'Fran\u00e7oise Beaufays'}]",
//  "day": 5,
//  "id": "1402.1128v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1402.1128v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1402.1128v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Long Short-Term Memory (LSTM) is a recurrent neural network (RNN)\narchitecture that has been designed to address the vanishing and exploding\ngradient problems of conventional RNNs. Unlike feedforward neural networks,\nRNNs have cyclic connections making them powerful for modeling sequences. They\nhave been successfully used for sequence labeling and sequence prediction\ntasks, such as handwriting recognition, language modeling, phonetic labeling of\nacoustic frames. However, in contrast to the deep neural networks, the use of\nRNNs in speech recognition has been limited to phone recognition in small scale\ntasks. In this paper, we present novel LSTM based RNN architectures which make\nmore effective use of model parameters to train acoustic models for large\nvocabulary speech recognition. We train and compare LSTM, RNN and DNN models at\nvarious numbers of parameters and configurations. We show that LSTM models\nconverge quickly and give state of the art speech recognition performance for\nrelatively small sized models.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Long Short-Term Memory Based Recurrent Neural Network Architectures for\n  Large Vocabulary Speech Recognition",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Peter Wittek'}, {'name': 'S\u00e1ndor Dar\u00e1nyi'}, {'name': 'Efstratios Kontopoulos'}, {'name': 'Theodoros Moysiadis'}, {'name': 'Ioannis Kompatsiaris'}]",
//  "day": 5,
//  "id": "1502.01753v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/IJCNN.2015.7280766', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1502.01753v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1502.01753v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Based on the Aristotelian concept of potentiality vs. actuality allowing for\nthe study of energy and dynamics in language, we propose a field approach to\nlexical analysis. Falling back on the distributional hypothesis to\nstatistically model word meaning, we used evolving fields as a metaphor to\nexpress time-dependent changes in a vector space model by a combination of\nrandom indexing and evolving self-organizing maps (ESOM). To monitor semantic\ndrifts within the observation period, an experiment was carried out on the term\nspace of a collection of 12.8 million Amazon book reviews. For evaluation, the\nsemantic consistency of ESOM term clusters was compared with their respective\nneighbourhoods in WordNet, and contrasted with distances among term vectors by\nrandom indexing. We found that at 0.05 level of significance, the terms in the\nclusters showed a high level of semantic consistency. Tracking the drift of\ndistributional patterns in the term space across time periods, we found that\nconsistency decreased, but not at a statistically significant level. Our method\nis highly scalable, with interpretations in philosophy.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Monitoring Term Drift Based on Semantic Consistency in an Evolving\n  Vector Field",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Jan Chorowski'}, {'name': 'Navdeep Jaitly'}]",
//  "day": 8,
//  "id": "1612.02695v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.02695v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.02695v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "The recently proposed Sequence-to-Sequence (seq2seq) framework advocates\nreplacing complex data processing pipelines, such as an entire automatic speech\nrecognition system, with a single neural network trained in an end-to-end\nfashion. In this contribution, we analyse an attention-based seq2seq speech\nrecognition system that directly transcribes recordings into characters. We\nobserve two shortcomings: overconfidence in its predictions and a tendency to\nproduce incomplete transcriptions when language models are used. We propose\npractical solutions to both problems achieving competitive speaker independent\nword error rates on the Wall Street Journal dataset: without separate language\nmodels we reach 10.6% WER, while together with a trigram language model, we\nreach 6.7% WER.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards better decoding and language model integration in sequence to\n  sequence models",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Dzmitry Bahdanau'}, {'name': 'Kyunghyun Cho'}, {'name': 'Yoshua Bengio'}]",
//  "day": 1,
//  "id": "1409.0473v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.0473v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.0473v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Neural machine translation is a recently proposed approach to machine\ntranslation. Unlike the traditional statistical machine translation, the neural\nmachine translation aims at building a single neural network that can be\njointly tuned to maximize the translation performance. The models proposed\nrecently for neural machine translation often belong to a family of\nencoder-decoders and consists of an encoder that encodes a source sentence into\na fixed-length vector from which a decoder generates a translation. In this\npaper, we conjecture that the use of a fixed-length vector is a bottleneck in\nimproving the performance of this basic encoder-decoder architecture, and\npropose to extend this by allowing a model to automatically (soft-)search for\nparts of a source sentence that are relevant to predicting a target word,\nwithout having to form these parts as a hard segment explicitly. With this new\napproach, we achieve a translation performance comparable to the existing\nstate-of-the-art phrase-based system on the task of English-to-French\ntranslation. Furthermore, qualitative analysis reveals that the\n(soft-)alignments found by the model agree well with our intuition.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Jean Pouget-Abadie'}, {'name': 'Dzmitry Bahdanau'}, {'name': 'Bart van Merrienboer'}, {'name': 'Kyunghyun Cho'}, {'name': 'Yoshua Bengio'}]",
//  "day": 3,
//  "id": "1409.1257v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.1257v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.1257v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "The authors of (Cho et al., 2014a) have shown that the recently introduced\nneural network translation systems suffer from a significant drop in\ntranslation quality when translating long sentences, unlike existing\nphrase-based translation systems. In this paper, we propose a way to address\nthis issue by automatically segmenting an input sentence into phrases that can\nbe easily translated by the neural network translation model. Once each segment\nhas been independently translated by the neural machine translation model, the\ntranslated clauses are concatenated to form a final translation. Empirical\nresults show a significant improvement in translation quality for long\nsentences.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Overcoming the Curse of Sentence Length for Neural Machine Translation\n  using Automatic Segmentation",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'William Chan'}, {'name': 'Nan Rosemary Ke'}, {'name': 'Ian Lane'}]",
//  "day": 7,
//  "id": "1504.01483v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.01483v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.01483v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Deep Neural Network (DNN) acoustic models have yielded many state-of-the-art\nresults in Automatic Speech Recognition (ASR) tasks. More recently, Recurrent\nNeural Network (RNN) models have been shown to outperform DNNs counterparts.\nHowever, state-of-the-art DNN and RNN models tend to be impractical to deploy\non embedded systems with limited computational capacity. Traditionally, the\napproach for embedded platforms is to either train a small DNN directly, or to\ntrain a small DNN that learns the output distribution of a large DNN. In this\npaper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. We\nuse the RNN model to generate soft alignments and minimize the Kullback-Leibler\ndivergence against the small DNN. The small DNN trained on the soft RNN\nalignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 task\ncompared to a baseline 4.54 WER or more than 13% relative improvement.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Transferring Knowledge from a RNN to a DNN",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Sarath Chandar'}, {'name': 'Mitesh M. Khapra'}, {'name': 'Hugo Larochelle'}, {'name': 'Balaraman Ravindran'}]",
//  "day": 27,
//  "id": "1504.07225v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.07225v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.07225v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Common Representation Learning (CRL), wherein different descriptions (or\nviews) of the data are embedded in a common subspace, is receiving a lot of\nattention recently. Two popular paradigms here are Canonical Correlation\nAnalysis (CCA) based approaches and Autoencoder (AE) based approaches. CCA\nbased approaches learn a joint representation by maximizing correlation of the\nviews when projected to the common subspace. AE based methods learn a common\nrepresentation by minimizing the error of reconstructing the two views. Each of\nthese approaches has its own advantages and disadvantages. For example, while\nCCA based approaches outperform AE based approaches for the task of transfer\nlearning, they are not as scalable as the latter. In this work we propose an AE\nbased approach called Correlational Neural Network (CorrNet), that explicitly\nmaximizes correlation among the views when projected to the common subspace.\nThrough a series of experiments, we demonstrate that the proposed CorrNet is\nbetter than the above mentioned approaches with respect to its ability to learn\ncorrelated common representations. Further, we employ CorrNet for several cross\nlanguage tasks and show that the representations learned using CorrNet perform\nbetter than the ones learned using other state of the art approaches.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Correlational Neural Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Jan Chorowski'}, {'name': 'Dzmitry Bahdanau'}, {'name': 'Dmitriy Serdyuk'}, {'name': 'Kyunghyun Cho'}, {'name': 'Yoshua Bengio'}]",
//  "day": 24,
//  "id": "1506.07503v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.07503v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.07503v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Recurrent sequence generators conditioned on input data through an attention\nmechanism have recently shown very good performance on a range of tasks in-\ncluding machine translation, handwriting synthesis and image caption gen-\neration. We extend the attention-mechanism with features needed for speech\nrecognition. We show that while an adaptation of the model used for machine\ntranslation in reaches a competitive 18.7% phoneme error rate (PER) on the\nTIMIT phoneme recognition task, it can only be applied to utterances which are\nroughly as long as the ones it was trained on. We offer a qualitative\nexplanation of this failure and propose a novel and generic method of adding\nlocation-awareness to the attention mechanism to alleviate this issue. The new\nmethod yields a model that is robust to long inputs and achieves 18% PER in\nsingle utterances and 20% in 10-times longer (repeated) utterances. Finally, we\npropose a change to the at- tention mechanism that prevents it from\nconcentrating too much on single frames, which further reduces PER to 17.6%\nlevel.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Attention-Based Models for Speech Recognition",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Ha\u015fim Sak'}, {'name': 'Andrew Senior'}, {'name': 'Kanishka Rao'}, {'name': 'Fran\u00e7oise Beaufays'}]",
//  "day": 24,
//  "id": "1507.06947v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1507.06947v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1507.06947v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "We have recently shown that deep Long Short-Term Memory (LSTM) recurrent\nneural networks (RNNs) outperform feed forward deep neural networks (DNNs) as\nacoustic models for speech recognition. More recently, we have shown that the\nperformance of sequence trained context dependent (CD) hidden Markov model\n(HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained\nphone models initialized with connectionist temporal classification (CTC). In\nthis paper, we present techniques that further improve performance of LSTM RNN\nacoustic models for large vocabulary speech recognition. We show that frame\nstacking and reduced frame rate lead to more accurate models and faster\ndecoding. CD phone modeling leads to further improvements. We also present\ninitial results for LSTM RNN models outputting words directly.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Fast and Accurate Recurrent Neural Network Acoustic Models for Speech\n  Recognition",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'William Chan'}, {'name': 'Navdeep Jaitly'}, {'name': 'Quoc V. Le'}, {'name': 'Oriol Vinyals'}]",
//  "day": 5,
//  "id": "1508.01211v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.01211v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.01211v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We present Listen, Attend and Spell (LAS), a neural network that learns to\ntranscribe speech utterances to characters. Unlike traditional DNN-HMM models,\nthis model learns all the components of a speech recognizer jointly. Our system\nhas two components: a listener and a speller. The listener is a pyramidal\nrecurrent network encoder that accepts filter bank spectra as inputs. The\nspeller is an attention-based recurrent network decoder that emits characters\nas outputs. The network produces character sequences without making any\nindependence assumptions between the characters. This is the key improvement of\nLAS over previous end-to-end CTC models. On a subset of the Google voice search\ntask, LAS achieves a word error rate (WER) of 14.1% without a dictionary or a\nlanguage model, and 10.3% with language model rescoring over the top 32 beams.\nBy comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0%.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Listen, Attend and Spell",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Shihao Ji'}, {'name': 'S. V. N. Vishwanathan'}, {'name': 'Nadathur Satish'}, {'name': 'Michael J. Anderson'}, {'name': 'Pradeep Dubey'}]",
//  "day": 21,
//  "id": "1511.06909v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.06909v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.06909v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We propose BlackOut, an approximation algorithm to efficiently train massive\nrecurrent neural network language models (RNNLMs) with million word\nvocabularies. BlackOut is motivated by using a discriminative loss, and we\ndescribe a new sampling strategy which significantly reduces computation while\nimproving stability, sample efficiency, and rate of convergence. One way to\nunderstand BlackOut is to view it as an extension of the DropOut strategy to\nthe output layer, wherein we use a discriminative training loss and a weighted\nsampling scheme. We also establish close connections between BlackOut,\nimportance sampling, and noise contrastive estimation (NCE). Our experiments,\non the recently released one billion word language modeling benchmark,\ndemonstrate scalability and accuracy of BlackOut; we outperform the\nstate-of-the art, and achieve the lowest perplexity scores on this dataset.\nMoreover, unlike other established methods which typically require GPUs or CPU\nclusters, we show that a carefully implemented version of BlackOut requires\nonly 1-10 days on a single machine to train a RNNLM with a million word\nvocabulary and billions of parameters on one billion words. Although we\ndescribe BlackOut in the context of RNNLM training, it can be used to any\nnetworks with large softmax output layers.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "BlackOut: Speeding up Recurrent Neural Network Language Models With Very\n  Large Vocabularies",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Marta R. Costa-Juss\u00e0'}, {'name': 'Jos\u00e9 A. R. Fonollosa'}]",
//  "day": 2,
//  "id": "1603.00810v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.00810v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.00810v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Neural Machine Translation (MT) has reached state-of-the-art results.\nHowever, one of the main challenges that neural MT still faces is dealing with\nvery large vocabularies and morphologically rich languages. In this paper, we\npropose a neural MT system using character-based embeddings in combination with\nconvolutional and highway layers to replace the standard lookup-based word\nrepresentations. The resulting unlimited-vocabulary and affix-aware source word\nembeddings are tested in a state-of-the-art neural MT based on an\nattention-based bidirectional recurrent neural network. The proposed MT scheme\nprovides improved results even when the source language is not morphologically\nrich. Improvements up to 3 BLEU points are obtained in the German-English WMT\ntask.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Character-based Neural Machine Translation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yangfeng Ji'}, {'name': 'Gholamreza Haffari'}, {'name': 'Jacob Eisenstein'}]",
//  "day": 7,
//  "id": "1603.01913v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.01913v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.01913v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "This paper presents a novel latent variable recurrent neural network\narchitecture for jointly modeling sequences of words and (possibly latent)\ndiscourse relations between adjacent sentences. A recurrent neural network\ngenerates individual words, thus reaping the benefits of\ndiscriminatively-trained vector representations. The discourse relations are\nrepresented with a latent variable, which can be predicted or marginalized,\ndepending on the task. The resulting model can therefore employ a training\nobjective that includes not only discourse relation classification, but also\nword prediction. As a result, it outperforms state-of-the-art alternatives for\ntwo tasks: implicit discourse relation classification in the Penn Discourse\nTreebank, and dialog act classification in the Switchboard corpus. Furthermore,\nby marginalizing over latent discourse relations at test time, we obtain a\ndiscourse informed language model, which improves over a strong LSTM baseline.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Latent Variable Recurrent Neural Network for Discourse Relation\n  Language Models",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Zhiyuan Tang'}, {'name': 'Lantian Li'}, {'name': 'Dong Wang'}]",
//  "day": 31,
//  "id": "1603.09643v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.09643v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.09643v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Although highly correlated, speech and speaker recognition have been regarded\nas two independent tasks and studied by two communities. This is certainly not\nthe way that people behave: we decipher both speech content and speaker traits\nat the same time. This paper presents a unified model to perform speech and\nspeaker recognition simultaneously and altogether. The model is based on a\nunified neural network where the output of one task is fed to the input of the\nother, leading to a multi-task recurrent network. Experiments show that the\njoint model outperforms the task-specific models on both the two tasks.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multi-task Recurrent Model for Speech and Speaker Recognition",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Sarath Chandar'}, {'name': 'Sungjin Ahn'}, {'name': 'Hugo Larochelle'}, {'name': 'Pascal Vincent'}, {'name': 'Gerald Tesauro'}, {'name': 'Yoshua Bengio'}]",
//  "day": 24,
//  "id": "1605.07427v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.07427v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.07427v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Memory networks are neural networks with an explicit memory component that\ncan be both read and written to by the network. The memory is often addressed\nin a soft way using a softmax function, making end-to-end training with\nbackpropagation possible. However, this is not computationally scalable for\napplications which require the network to read from extremely large memories.\nOn the other hand, it is well known that hard attention mechanisms based on\nreinforcement learning are challenging to train successfully. In this paper, we\nexplore a form of hierarchical memory network, which can be considered as a\nhybrid between hard and soft attention memory networks. The memory is organized\nin a hierarchical structure such that reading from it is done with less\ncomputation than soft attention over a flat memory, while also being easier to\ntrain than hard attention over a flat memory. Specifically, we propose to\nincorporate Maximum Inner Product Search (MIPS) in the training and inference\nprocedures for our hierarchical memory network. We explore the use of various\nstate-of-the art approximate MIPS techniques and report results on\nSimpleQuestions, a challenging large scale factoid question answering task.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hierarchical Memory Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Sam Wiseman'}, {'name': 'Alexander M. Rush'}]",
//  "day": 9,
//  "id": "1606.02960v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.02960v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.02960v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Sequence-to-Sequence (seq2seq) modeling has rapidly become an important\ngeneral-purpose NLP tool that has proven effective for many text-generation and\nsequence-labeling tasks. Seq2seq builds on deep neural language modeling and\ninherits its remarkable accuracy in estimating local, next-word distributions.\nIn this work, we introduce a model and beam-search training scheme, based on\nthe work of Daume III and Marcu (2005), that extends seq2seq to learn global\nsequence scores. This structured approach avoids classical biases associated\nwith local training and unifies the training loss with the test-time usage,\nwhile preserving the proven model architecture of seq2seq and its efficient\ntraining approach. We show that our system outperforms a highly-optimized\nattention-based seq2seq system and other baselines on three different sequence\nto sequence tasks: word ordering, parsing, and machine translation.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sequence-to-Sequence Learning as Beam-Search Optimization",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Ankit Vani'}, {'name': 'Yacine Jernite'}, {'name': 'David Sontag'}]",
//  "day": 23,
//  "id": "1705.08557v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08557v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08557v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "In this work, we present the Grounded Recurrent Neural Network (GRNN), a\nrecurrent neural network architecture for multi-label prediction which\nexplicitly ties labels to specific dimensions of the recurrent hidden state (we\ncall this process \"grounding\"). The approach is particularly well-suited for\nextracting large numbers of concepts from text. We apply the new model to\naddress an important problem in healthcare of understanding what medical\nconcepts are discussed in clinical text. Using a publicly available dataset\nderived from Intensive Care Units, we learn to label a patient's diagnoses and\nprocedures from their discharge summary. Our evaluation shows a clear advantage\nto using our proposed architecture over a variety of strong baselines.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Grounded Recurrent Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Tsung-Hsien Wen'}, {'name': 'Yishu Miao'}, {'name': 'Phil Blunsom'}, {'name': 'Steve Young'}]",
//  "day": 29,
//  "id": "1705.10229v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10229v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10229v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Developing a dialogue agent that is capable of making autonomous decisions\nand communicating by natural language is one of the long-term goals of machine\nlearning research. Traditional approaches either rely on hand-crafting a small\nstate-action set for applying reinforcement learning that is not scalable or\nconstructing deterministic models for learning dialogue sentences that fail to\ncapture natural conversational variability. In this paper, we propose a Latent\nIntention Dialogue Model (LIDM) that employs a discrete latent variable to\nlearn underlying dialogue intentions in the framework of neural variational\ninference. In a goal-oriented dialogue scenario, these latent intentions can be\ninterpreted as actions guiding the generation of machine responses, which can\nbe further refined autonomously by reinforcement learning. The experimental\nevaluation of LIDM shows that the model out-performs published benchmarks for\nboth corpus-based and human evaluation, demonstrating the effectiveness of\ndiscrete latent variable models for learning goal-oriented dialogues.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Latent Intention Dialogue Models",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Julius Kunze'}, {'name': 'Louis Kirsch'}, {'name': 'Ilia Kurenkov'}, {'name': 'Andreas Krug'}, {'name': 'Jens Johannsmeier'}, {'name': 'Sebastian Stober'}]",
//  "day": 1,
//  "id": "1706.00290v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.00290v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.00290v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "End-to-end training of automated speech recognition (ASR) systems requires\nmassive data and compute resources. We explore transfer learning based on model\nadaptation as an approach for training ASR models under constrained GPU memory,\nthroughput and training data. We conduct several systematic experiments\nadapting a Wav2Letter convolutional neural network originally trained for\nEnglish ASR to the German language. We show that this technique allows faster\ntraining on consumer-grade resources while requiring less training data in\norder to achieve the same accuracy, thereby lowering the cost of training ASR\nmodels in other languages. Model introspection revealed that small adaptations\nto the network's weights were sufficient for good performance, especially for\ninner layers.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Transfer Learning for Speech Recognition on a Budget",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Matt Shannon'}]",
//  "day": 8,
//  "id": "1706.02776v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.02776v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.02776v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Optimizing expected word error rate via sampling for speech recognition",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Artem M. Grachev'}, {'name': 'Dmitry I. Ignatov'}, {'name': 'Andrey V. Savchenko'}]",
//  "day": 20,
//  "id": "1708.05963v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.05963v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.05963v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "In this paper, we consider several compression techniques for the language\nmodeling problem based on recurrent neural networks (RNNs). It is known that\nconventional RNNs, e.g, LSTM-based networks in language modeling, are\ncharacterized with either high space complexity or substantial inference time.\nThis problem is especially crucial for mobile applications, in which the\nconstant interaction with the remote server is inappropriate. By using the Penn\nTreebank (PTB) dataset we compare pruning, quantization, low-rank\nfactorization, tensor train decomposition for LSTM networks in terms of model\nsize and suitability for fast inference.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '62M45, 68T50', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.7, I.2.6, I.5.1, I.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Networks Compression for Language Modeling",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mostafa Dehghani'}, {'name': 'Aliaksei Severyn'}, {'name': 'Sascha Rothe'}, {'name': 'Jaap Kamps'}]",
//  "day": 1,
//  "id": "1711.00313v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.00313v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.00313v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Training deep neural networks requires massive amounts of training data, but\nfor many tasks only limited labeled data is available. This makes weak\nsupervision attractive, using weak or noisy signals like the output of\nheuristic methods or user click-through data for training. In a semi-supervised\nsetting, we can use a large set of data with weak labels to pretrain a neural\nnetwork and then fine-tune the parameters with a small amount of data with true\nlabels. This feels intuitively sub-optimal as these two independent stages\nleave the model unaware about the varying label quality. What if we could\nsomehow inform the model about the label quality? In this paper, we propose a\nsemi-supervised learning method where we train two neural networks in a\nmulti-task fashion: a \"target network\" and a \"confidence network\". The target\nnetwork is optimized to perform a given task and is trained using a large set\nof unlabeled data that are weakly annotated. We propose to weight the gradient\nupdates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model. We evaluate our learning strategy on two different\ntasks: document ranking and sentiment classification. The results demonstrate\nthat our approach not only enhances the performance compared to the baselines\nbut also speeds up the learning process from weak labels.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Avoiding Your Teacher's Mistakes: Training Neural Networks with\n  Controlled Weak Supervision",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Christopher Tegho'}, {'name': 'Pawe\u0142 Budzianowski'}, {'name': 'Milica Ga\u0161i\u0107'}]",
//  "day": 30,
//  "id": "1711.11486v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.11486v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.11486v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "In statistical dialogue management, the dialogue manager learns a policy that\nmaps a belief state to an action for the system to perform. Efficient\nexploration is key to successful policy optimisation. Current deep\nreinforcement learning methods are very promising but rely on epsilon-greedy\nexploration, thus subjecting the user to a random choice of action during\nlearning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)\nestimate uncertainties and are sample efficient, leading to better user\nexperience, but on the expense of a greater computational complexity. This\npaper examines approaches to extract uncertainty estimates from deep Q-networks\n(DQN) in the context of dialogue management. We perform an extensive benchmark\nof deep Bayesian methods to extract uncertainty estimates, namely\nBayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble and\nalpha-divergences, combining it with DQN algorithm.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy\n  Optimisation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yuanhang Su'}, {'name': 'Yuzhong Huang'}, {'name': 'C. -C. Jay Kuo'}]",
//  "day": 27,
//  "id": "1803.01686v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1803.01686v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1803.01686v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "In this work, we investigate the memory capability of recurrent neural\nnetworks (RNNs), where this capability is defined as a function that maps an\nelement in a sequence to the current output. We first analyze the system\nfunction of a recurrent neural network (RNN) cell, and provide analytical\nresults for three RNNs. They are the simple recurrent neural network (SRN), the\nlong short-term memory (LSTM), and the gated recurrent unit (GRU). Based on the\nanalysis, we propose a new design to extend the memory length of a cell, and\ncall it the extended long short-term memory (ELSTM). Next, we present a\ndependent bidirectional recurrent neural network (DBRNN) for the\nsequence-in-sequence-out (SISO) problem, which is more robust to previous\nerroneous predictions. Extensive experiments are carried out on different\nlanguage tasks to demonstrate the superiority of our proposed ELSTM and DBRNN\nsolutions.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent\n  Neural Network",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Lin Ma'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}]",
//  "day": 1,
//  "id": "1506.00333v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.00333v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.00333v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "In this paper, we propose to employ the convolutional neural network (CNN)\nfor the image question answering (QA). Our proposed CNN provides an end-to-end\nframework with convolutional architectures for learning not only the image and\nquestion representations, but also their inter-modal interactions to produce\nthe answer. More specifically, our model consists of three CNNs: one image CNN\nto encode the image content, one sentence CNN to compose the words of the\nquestion, and one multimodal convolution layer to learn their joint\nrepresentation for the classification in the space of candidate answer words.\nWe demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA\ndatasets, which are two benchmark datasets for the image QA, with the\nperformances significantly outperforming the state-of-the-art.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning to Answer Questions From Image Using Convolutional Neural\n  Network",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Zichao Yang'}, {'name': 'Xiaodong He'}, {'name': 'Jianfeng Gao'}, {'name': 'Li Deng'}, {'name': 'Alex Smola'}]",
//  "day": 7,
//  "id": "1511.02274v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.02274v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.02274v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "This paper presents stacked attention networks (SANs) that learn to answer\nnatural language questions from images. SANs use semantic representation of a\nquestion as query to search for the regions in an image that are related to the\nanswer. We argue that image question answering (QA) often requires multiple\nsteps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\nimage multiple times to infer the answer progressively. Experiments conducted\non four image QA data sets demonstrate that the proposed SANs significantly\noutperform previous state-of-the-art approaches. The visualization of the\nattention layers illustrates the progress that the SAN locates the relevant\nvisual clues that lead to the answer of the question layer-by-layer.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Stacked Attention Networks for Image Question Answering",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Jacob Andreas'}, {'name': 'Marcus Rohrbach'}, {'name': 'Trevor Darrell'}, {'name': 'Dan Klein'}]",
//  "day": 9,
//  "id": "1511.02799v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.02799v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.02799v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Visual question answering is fundamentally compositional in nature---a\nquestion like \"where is the dog?\" shares substructure with questions like \"what\ncolor is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously\nexploit the representational capacity of deep networks and the compositional\nlinguistic structure of questions. We describe a procedure for constructing and\nlearning *neural module networks*, which compose collections of jointly-trained\nneural \"modules\" into deep networks for question answering. Our approach\ndecomposes questions into their linguistic substructures, and uses these\nstructures to dynamically instantiate modular networks (with reusable\ncomponents for recognizing dogs, classifying colors, etc.). The resulting\ncompound networks are jointly trained. We evaluate our approach on two\nchallenging datasets for visual question answering, achieving state-of-the-art\nresults on both the VQA natural image dataset and a new dataset of complex\nquestions about abstract shapes.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Module Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Federico Raue'}, {'name': 'Andreas Dengel'}, {'name': 'Thomas M. Breuel'}, {'name': 'Marcus Liwicki'}]",
//  "day": 13,
//  "id": "1511.04401v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.04401v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.04401v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "In this paper, we extend a symbolic association framework for being able to\nhandle missing elements in multimodal sequences. The general scope of the work\nis the symbolic associations of object-word mappings as it happens in language\ndevelopment in infants. In other words, two different representations of the\nsame abstract concepts can associate in both directions. This scenario has been\nlong interested in Artificial Intelligence, Psychology, and Neuroscience. In\nthis work, we extend a recent approach for multimodal sequences (visual and\naudio) to also cope with missing elements in one or both modalities. Our method\nuses two parallel Long Short-Term Memories (LSTMs) with a learning rule based\non EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We\npropose to include an extra step for the combination with the max operation for\nexploiting the common elements between both sequences. The motivation behind is\nthat the combination acts as a condition selector for choosing the best\nrepresentation from both LSTMs. We evaluated the proposed extension in the\nfollowing scenarios: missing elements in one modality (visual or audio) and\nmissing elements in both modalities (visual and sound). The performance of our\nextension reaches better results than the original model and similar results to\nindividual LSTM trained in each modality.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Symbol Grounding Association in Multimodal Sequences with Missing\n  Elements",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Dan Hendrycks'}, {'name': 'Mantas Mazeika'}, {'name': 'Duncan Wilson'}, {'name': 'Kevin Gimpel'}]",
//  "day": 14,
//  "id": "1802.05300v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.05300v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.05300v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "The growing importance of massive datasets with the advent of deep learning\nmakes robustness to label noise a critical property for classifiers to have.\nSources of label noise include automatic labeling for large datasets,\nnon-expert labeling, and label corruption by data poisoning adversaries. In the\nlatter case, corruptions may be arbitrarily bad, even so bad that a classifier\npredicts the wrong labels with high confidence. To protect against such sources\nof noise, we leverage the fact that a small set of clean labels is often easy\nto procure. We demonstrate that robustness to label noise up to severe\nstrengths can be achieved by using a set of trusted data with clean labels, and\npropose a loss correction that utilizes trusted examples in a data-efficient\nmanner to mitigate the effects of label noise on deep neural network\nclassifiers. Across vision and natural language processing tasks, we experiment\nwith various label noises at several strengths, and show that our method\nsignificantly outperforms existing methods.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe\n  Noise",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Kyunghyun Cho'}, {'name': 'Aaron Courville'}, {'name': 'Yoshua Bengio'}]",
//  "day": 4,
//  "id": "1507.01053v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/TMM.2015.2477044', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1507.01053v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1507.01053v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Whereas deep neural networks were first mostly used for classification tasks,\nthey are rapidly expanding in the realm of structured output problems, where\nthe observed target is composed of multiple random variables that have a rich\njoint distribution, given the input. We focus in this paper on the case where\nthe input also has a rich structure and the input and output structures are\nsomehow related. We describe systems that learn to attend to different places\nin the input, for each element of the output, for a variety of tasks: machine\ntranslation, image caption generation, video clip description and speech\nrecognition. All these systems are based on a shared set of building blocks:\ngated recurrent neural networks and convolutional neural networks, along with\ntrained attention mechanisms. We report on experimental results with these\nsystems, showing impressively good performance and the advantage of the\nattention mechanism.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Describing Multimedia Content using Attention-based Encoder--Decoder\n  Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Desmond Elliott'}, {'name': 'Stella Frank'}, {'name': 'Eva Hasler'}]",
//  "day": 15,
//  "id": "1510.04709v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.04709v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.04709v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "In this paper we present an approach to multi-language image description\nbringing together insights from neural machine translation and neural image\ndescription. To create a description of an image for a given target language,\nour sequence generation models condition on feature vectors from the image, the\ndescription from the source language, and/or a multimodal vector computed over\nthe image and a description in the source language. In image description\nexperiments on the IAPR-TC12 dataset of images aligned with English and German\nsentences, we find significant and substantial improvements in BLEU4 and Meteor\nscores for models trained over multiple languages, compared to a monolingual\nbaseline.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multilingual Image Description with Neural Sequence Models",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Oswaldo Ludwig'}, {'name': 'Xiao Liu'}, {'name': 'Parisa Kordjamshidi'}, {'name': 'Marie-Francine Moens'}]",
//  "day": 28,
//  "id": "1603.08474v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.08474v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.08474v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "This paper introduces the visually informed embedding of word (VIEW), a\ncontinuous vector representation for a word extracted from a deep neural model\ntrained using the Microsoft COCO data set to forecast the spatial arrangements\nbetween visual objects, given a textual description. The model is composed of a\ndeep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory\n(LSTM) network, the latter being preceded by an embedding layer. The VIEW is\napplied to transferring multimodal background knowledge to Spatial Role\nLabeling (SpRL) algorithms, which recognize spatial relations between objects\nmentioned in the text. This work also contributes with a new method to select\ncomplementary features and a fine-tuning method for MLP that improves the $F1$\nmeasure in classifying the words into spatial roles. The VIEW is evaluated with\nthe Task 3 of SemEval-2013 benchmark data set, SpaceEval.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Embedding for Spatial Role Labeling",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yuntian Deng'}, {'name': 'Anssi Kanervisto'}, {'name': 'Jeffrey Ling'}, {'name': 'Alexander M. Rush'}]",
//  "day": 16,
//  "id": "1609.04938v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.04938v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.04938v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We present a neural encoder-decoder model to convert images into\npresentational markup based on a scalable coarse-to-fine attention mechanism.\nOur method is evaluated in the context of image-to-LaTeX generation, and we\nintroduce a new dataset of real-world rendered mathematical expressions paired\nwith LaTeX markup. We show that unlike neural OCR techniques using CTC-based\nmodels, attention-based approaches can tackle this non-standard OCR task. Our\napproach outperforms classical mathematical OCR systems by a large margin on\nin-domain rendered data, and, with pretraining, also performs well on\nout-of-domain handwritten data. To reduce the inference complexity associated\nwith the attention-based approaches, we introduce a new coarse-to-fine\nattention layer that selects a support region before applying attention.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Image-to-Markup Generation with Coarse-to-Fine Attention",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Sumeet S. Singh'}]",
//  "day": 15,
//  "id": "1802.05415v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.05415v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.05415v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We present a deep recurrent neural network model with soft visual attention\nthat learns to generate LaTeX markup of real-world math formulas given their\nimages. Applying neural sequence generation techniques that have been very\nsuccessful in the fields of machine translation and image/handwriting/speech\ncaptioning, recognition, transcription and synthesis, we construct an\nimage-to-markup model that learns to produce syntactically and semantically\ncorrect LaTeX markup code of over 150 words long and achieves a BLEU score of\n89%; the best reported so far for the Im2Latex problem. We also visually\ndemonstrate that the model learns to scan the image left-right / up-down much\nas a human would read it.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Teaching Machines to Code: Neural Markup Generation with Visual\n  Attention",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Mohammad Javad Shafiee'}, {'name': 'Elnaz Barshan'}, {'name': 'Alexander Wong'}]",
//  "day": 7,
//  "id": "1704.02081v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.02081v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.02081v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "A promising paradigm for achieving highly efficient deep neural networks is\nthe idea of evolutionary deep intelligence, which mimics biological evolution\nprocesses to progressively synthesize more efficient networks. A crucial design\nfactor in evolutionary deep intelligence is the genetic encoding scheme used to\nsimulate heredity and determine the architectures of offspring networks. In\nthis study, we take a deeper look at the notion of synaptic cluster-driven\nevolution of deep neural networks which guides the evolution process towards\nthe formation of a highly sparse set of synaptic clusters in offspring\nnetworks. Utilizing a synaptic cluster-driven genetic encoding, the\nprobabilistic encoding of synaptic traits considers not only individual\nsynaptic properties but also inter-synaptic relationships within a deep neural\nnetwork. This process results in highly sparse offspring networks which are\nparticularly tailored for parallel computational devices such as GPUs and deep\nneural network accelerator chips. Comprehensive experimental results using four\nwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and\nDetectNet) on two different tasks (object categorization and object detection)\ndemonstrate the efficiency of the proposed method. Cluster-driven genetic\nencoding scheme synthesizes networks that can achieve state-of-the-art\nperformance with significantly smaller number of synapses than that of the\noriginal ancestor network. ($\\sim$125-fold decrease in synapses for MNIST).\nFurthermore, the improved cluster efficiency in the generated offspring\nnetworks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold\ndecrease in clusters for KITTI) is particularly useful for accelerated\nperformance on parallel computing hardware architectures such as those in GPUs\nand deep neural network accelerator chips.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Evolution in Groups: A deeper look at synaptic cluster driven evolution\n  of deep neural networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mete Ozay'}, {'name': 'Ilke \u00d6ztekin'}, {'name': 'Uygar \u00d6ztekin'}, {'name': 'Fatos T. Yarman Vural'}]",
//  "day": 10,
//  "id": "1205.2382v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1205.2382v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1205.2382v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "A relatively recent advance in cognitive neuroscience has been multi-voxel\npattern analysis (MVPA), which enables researchers to decode brain states\nand/or the type of information represented in the brain during a cognitive\noperation. MVPA methods utilize machine learning algorithms to distinguish\namong types of information or cognitive states represented in the brain, based\non distributed patterns of neural activity. In the current investigation, we\npropose a new approach for representation of neural data for pattern analysis,\nnamely a Mesh Learning Model. In this approach, at each time instant, a star\nmesh is formed around each voxel, such that the voxel corresponding to the\ncenter node is surrounded by its p-nearest neighbors. The arc weights of each\nmesh are estimated from the voxel intensity values by least squares method. The\nestimated arc weights of all the meshes, called Mesh Arc Descriptors (MADs),\nare then used to train a classifier, such as Neural Networks, k-Nearest\nNeighbor, Na\\\"ive Bayes and Support Vector Machines. The proposed Mesh Model\nwas tested on neuroimaging data acquired via functional magnetic resonance\nimaging (fMRI) during a recognition memory experiment using categorized word\nlists, employing a previously established experimental paradigm (\\\"Oztekin &\nBadre, 2011). Results suggest that the proposed Mesh Learning approach can\nprovide an effective algorithm for pattern analysis of brain activity during\ncognitive processing.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Mesh Learning for Classifying Cognitive Processes",
//  "year": 2012
//},
//{
//  "author": "[{'name': 'A. H. Karimi'}, {'name': 'M. J. Shafiee'}, {'name': 'A. Ghodsi'}, {'name': 'A. Wong'}]",
//  "day": 1,
//  "id": "1707.00081v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.00081v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.00081v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "In this work, we perform an exploratory study on synthesizing deep neural\nnetworks using biological synaptic strength distributions, and the potential\ninfluence of different distributions on modelling performance particularly for\nthe scenario associated with small data sets. Surprisingly, a CNN with\nconvolutional layer synaptic strengths drawn from biologically-inspired\ndistributions such as log-normal or correlated center-surround distributions\nperformed relatively well suggesting a possibility for designing deep neural\nnetwork architectures that do not require many data samples to learn, and can\nsidestep current training procedures while maintaining or boosting modelling\nperformance.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Synthesizing Deep Neural Network Architectures using Biological Synaptic\n  Strength Distributions",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yukun Bao'}, {'name': 'Zhongyi Hu'}, {'name': 'Tao Xiong'}]",
//  "day": 9,
//  "id": "1401.1926v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1016/j.neucom.2013.01.027', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1401.1926v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1401.1926v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Addressing the issue of SVMs parameters optimization, this study proposes an\nefficient memetic algorithm based on Particle Swarm Optimization algorithm\n(PSO) and Pattern Search (PS). In the proposed memetic algorithm, PSO is\nresponsible for exploration of the search space and the detection of the\npotential regions with optimum solutions, while pattern search (PS) is used to\nproduce an effective exploitation on the potential regions obtained by PSO.\nMoreover, a novel probabilistic selection strategy is proposed to select the\nappropriate individuals among the current population to undergo local\nrefinement, keeping a well balance between exploration and exploitation.\nExperimental results confirm that the local refinement with PS and our proposed\nselection strategy are effective, and finally demonstrate effectiveness and\nrobustness of the proposed PSO-PS based MA for SVMs parameters optimization.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A PSO and Pattern Search based Memetic Algorithm for SVMs Parameters\n  Optimization",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Laurent Dinh'}, {'name': 'Jascha Sohl-Dickstein'}, {'name': 'Samy Bengio'}]",
//  "day": 27,
//  "id": "1605.08803v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.08803v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.08803v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Density estimation using Real NVP",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tim Salimans'}, {'name': 'Jonathan Ho'}, {'name': 'Xi Chen'}, {'name': 'Szymon Sidor'}, {'name': 'Ilya Sutskever'}]",
//  "day": 10,
//  "id": "1703.03864v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.03864v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.03864v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We explore the use of Evolution Strategies (ES), a class of black box\noptimization algorithms, as an alternative to popular MDP-based RL techniques\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\nthat ES is a viable solution strategy that scales extremely well with the\nnumber of CPUs available: By using a novel communication strategy based on\ncommon random numbers, our ES implementation only needs to communicate scalars,\nmaking it possible to scale to over a thousand parallel workers. This allows us\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\nmost Atari games after one hour of training. In addition, we highlight several\nadvantages of ES as a black box optimization technique: it is invariant to\naction frequency and delayed rewards, tolerant of extremely long horizons, and\ndoes not need temporal discounting or value function approximation.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Peter Karkus'}, {'name': 'David Hsu'}, {'name': 'Wee Sun Lee'}]",
//  "day": 20,
//  "id": "1703.06692v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.06692v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.06692v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "This paper introduces the QMDP-net, a neural network architecture for\nplanning under partial observability. The QMDP-net combines the strengths of\nmodel-free learning and model-based planning. It is a recurrent policy network,\nbut it represents a policy for a parameterized set of tasks by connecting a\nmodel with a planning algorithm that solves the model, thus embedding the\nsolution structure of planning in a network learning architecture. The QMDP-net\nis fully differentiable and allows for end-to-end training. We train a QMDP-net\non different tasks so that it can generalize to new ones in the parameterized\ntask set and \"transfer\" to other similar tasks beyond the set. In preliminary\nexperiments, QMDP-net showed strong performance on several robotic tasks in\nsimulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it\nsometimes outperforms the QMDP algorithm in the experiments, as a result of\nend-to-end learning.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "QMDP-Net: Deep Learning for Planning under Partial Observability",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Gregory Farquhar'}, {'name': 'Tim Rockt\u00e4schel'}, {'name': 'Maximilian Igl'}, {'name': 'Shimon Whiteson'}]",
//  "day": 31,
//  "id": "1710.11417v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.11417v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.11417v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Nan Rosemary Ke'}, {'name': 'Anirudh Goyal'}, {'name': 'Olexa Bilaniuk'}, {'name': 'Jonathan Binas'}, {'name': 'Laurent Charlin'}, {'name': 'Chris Pal'}, {'name': 'Yoshua Bengio'}]",
//  "day": 7,
//  "id": "1711.02326v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.02326v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.02326v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "A major drawback of backpropagation through time (BPTT) is the difficulty of\nlearning long-term dependencies, coming from having to propagate credit\ninformation backwards through every single step of the forward computation.\nThis makes BPTT both computationally impractical and biologically implausible.\nFor this reason, full backpropagation through time is rarely used on long\nsequences, and truncated backpropagation through time is used as a heuristic.\nHowever, this usually leads to biased estimates of the gradient in which longer\nterm dependencies are ignored. Addressing this issue, we propose an alternative\nalgorithm, Sparse Attentive Backtracking, which might also be related to\nprinciples used by brains to learn long-term dependencies. Sparse Attentive\nBacktracking learns an attention mechanism over the hidden states of the past\nand selectively backpropagates through paths with high attention weights. This\nallows the model to learn long term dependencies while only backtracking for a\nsmall number of time steps, not just from the recent past but also from\nattended relevant past states.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent\n  Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Anakha V Babu'}, {'name': 'Bipin Rajendran'}]",
//  "day": 9,
//  "id": "1711.03640v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.03640v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.03640v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We study the performance of stochastically trained deep neural networks\n(DNNs) whose synaptic weights are implemented using emerging memristive devices\nthat exhibit limited dynamic range, resolution, and variability in their\nprogramming characteristics. We show that a key device parameter to optimize\nthe learning efficiency of DNNs is the variability in its programming\ncharacteristics. DNNs with such memristive synapses, even with dynamic range as\nlow as $15$ and only $32$ discrete levels, when trained based on stochastic\nupdates suffer less than $3\\%$ loss in accuracy compared to floating point\nsoftware baseline. We also study the performance of stochastic memristive DNNs\nwhen used as inference engines with noise corrupted data and find that if the\ndevice variability can be minimized, the relative degradation in performance\nfor the Stochastic DNN is better than that of the software baseline. Hence, our\nstudy presents a new optimization corner for memristive devices for building\nlarge noise-immune deep learning systems.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Stochastic Deep Learning in Memristive Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yukun Bao'}, {'name': 'Tao Xiong'}, {'name': 'Zhongyi Hu'}]",
//  "day": 31,
//  "id": "1401.0104v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/TCYB.2013.2265084', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1401.0104v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1401.0104v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Multi-step-ahead time series prediction is one of the most challenging\nresearch topics in the field of time series modeling and prediction, and is\ncontinually under research. Recently, the multiple-input several\nmultiple-outputs (MISMO) modeling strategy has been proposed as a promising\nalternative for multi-step-ahead time series prediction, exhibiting advantages\ncompared with the two currently dominating strategies, the iterated and the\ndirect strategies. Built on the established MISMO strategy, this study proposes\na particle swarm optimization (PSO)-based MISMO modeling strategy, which is\ncapable of determining the number of sub-models in a self-adaptive mode, with\nvarying prediction horizons. Rather than deriving crisp divides with equal-size\ns prediction horizons from the established MISMO, the proposed PSO-MISMO\nstrategy, implemented with neural networks, employs a heuristic to create\nflexible divides with varying sizes of prediction horizons and to generate\ncorresponding sub-models, providing considerable flexibility in model\nconstruction, which has been validated with simulated and real datasets.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "PSO-MISMO Modeling Strategy for Multi-Step-Ahead Time Series Prediction",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Behnam Neyshabur'}, {'name': 'Ryota Tomioka'}, {'name': 'Nathan Srebro'}]",
//  "day": 27,
//  "id": "1503.00036v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1503.00036v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1503.00036v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We investigate the capacity, convexity and characterization of a general\nfamily of norm-constrained feed-forward networks.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Norm-Based Capacity Control in Neural Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Konrad Zolna'}]",
//  "day": 5,
//  "id": "1612.01589v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.01589v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.01589v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "The method presented extends a given regression neural network to make its\nperformance improve. The modification affects the learning procedure only,\nhence the extension may be easily omitted during evaluation without any change\nin prediction. It means that the modified model may be evaluated as quickly as\nthe original one but tends to perform better.\n  This improvement is possible because the modification gives better expressive\npower, provides better behaved gradients and works as a regularization. The\nknowledge gained by the temporarily extended neural network is contained in the\nparameters shared with the original neural network.\n  The only cost is an increase in learning time.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Improving the Performance of Neural Networks in Regression Tasks Using\n  Drawering",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yujia Li'}, {'name': 'Kevin Swersky'}, {'name': 'Richard Zemel'}]",
//  "day": 17,
//  "id": "1412.5244v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.5244v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.5244v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "A key element in transfer learning is representation learning; if\nrepresentations can be developed that expose the relevant factors underlying\nthe data, then new tasks and domains can be learned readily based on mappings\nof these salient factors. We propose that an important aim for these\nrepresentations are to be unbiased. Different forms of representation learning\ncan be derived from alternative definitions of unwanted bias, e.g., bias to\nparticular tasks, domains, or irrelevant underlying data dimensions. One very\nuseful approach to estimating the amount of bias in a representation comes from\nmaximum mean discrepancy (MMD) [5], a measure of distance between probability\ndistributions. We are not the first to suggest that MMD can be a useful\ncriterion in developing representations that apply across multiple domains or\ntasks [1]. However, in this paper we describe a number of novel applications of\nthis criterion that we have devised, all based on the idea of developing\nunbiased representations. These formulations include: a standard domain\nadaptation framework; a method of learning invariant representations; an\napproach based on noise-insensitive autoencoders; and a novel form of\ngenerative model.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning unbiased features",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'David Balduzzi'}, {'name': 'Muhammad Ghifary'}]",
//  "day": 10,
//  "id": "1509.03005v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.03005v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.03005v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "This paper proposes GProp, a deep reinforcement learning algorithm for\ncontinuous policies with compatible function approximation. The algorithm is\nbased on two innovations. Firstly, we present a temporal-difference based\nmethod for learning the gradient of the value-function. Secondly, we present\nthe deviator-actor-critic (DAC) model, which comprises three neural networks\nthat estimate the value function, its gradient, and determine the actor's\npolicy respectively. We evaluate GProp on two challenging tasks: a contextual\nbandit problem constructed from nonparametric regression datasets that is\ndesigned to probe the ability of reinforcement learning algorithms to\naccurately estimate gradients; and the octopus arm, a challenging reinforcement\nlearning benchmark. GProp is competitive with fully supervised methods on the\nbandit task and achieves the best performance to date on the octopus arm.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Compatible Value Gradients for Reinforcement Learning of Continuous Deep\n  Policies",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Takayuki Osogami'}, {'name': 'Makoto Otsuka'}]",
//  "day": 29,
//  "id": "1509.08634v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.08634v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.08634v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose a particularly structured Boltzmann machine, which we refer to as\na dynamic Boltzmann machine (DyBM), as a stochastic model of a\nmulti-dimensional time-series. The DyBM can have infinitely many layers of\nunits but allows exact and efficient inference and learning when its parameters\nhave a proposed structure. This proposed structure is motivated by postulates\nand observations, from biological neural networks, that the synaptic weight is\nstrengthened or weakened, depending on the timing of spikes (i.e., spike-timing\ndependent plasticity or STDP). We show that the learning rule of updating the\nparameters of the DyBM in the direction of maximizing the likelihood of given\ntime-series can be interpreted as STDP with long term potentiation and long\nterm depression. The learning rule has a guarantee of convergence and can be\nperformed in a distributed matter (i.e., local in space) with limited memory\n(i.e., local in time).",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning dynamic Boltzmann machines with spike-timing dependent\n  plasticity",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Yujia Li'}, {'name': 'Daniel Tarlow'}, {'name': 'Marc Brockschmidt'}, {'name': 'Richard Zemel'}]",
//  "day": 17,
//  "id": "1511.05493v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.05493v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.05493v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Graph-structured data appears frequently in domains including chemistry,\nnatural language semantics, social networks, and knowledge bases. In this work,\nwe study feature learning techniques for graph-structured inputs. Our starting\npoint is previous work on Graph Neural Networks (Scarselli et al., 2009), which\nwe modify to use gated recurrent units and modern optimization techniques and\nthen extend to output sequences. The result is a flexible and broadly useful\nclass of neural network models that has favorable inductive biases relative to\npurely sequence-based models (e.g., LSTMs) when the problem is\ngraph-structured. We demonstrate the capabilities on some simple AI (bAbI) and\ngraph algorithm learning tasks. We then show it achieves state-of-the-art\nperformance on a problem from program verification, in which subgraphs need to\nbe matched to abstract data structures.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Gated Graph Sequence Neural Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Gabriel Dulac-Arnold'}, {'name': 'Richard Evans'}, {'name': 'Hado van Hasselt'}, {'name': 'Peter Sunehag'}, {'name': 'Timothy Lillicrap'}, {'name': 'Jonathan Hunt'}, {'name': 'Timothy Mann'}, {'name': 'Theophane Weber'}, {'name': 'Thomas Degris'}, {'name': 'Ben Coppin'}]",
//  "day": 24,
//  "id": "1512.07679v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1512.07679v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1512.07679v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Being able to reason in an environment with a large number of discrete\nactions is essential to bringing reinforcement learning to a larger class of\nproblems. Recommender systems, industrial plants and language models are only\nsome of the many real-world tasks involving large numbers of discrete actions\nfor which current methods are difficult or even often impossible to apply. An\nability to generalize over the set of actions as well as sub-linear complexity\nrelative to the size of the set are both necessary to handle such tasks.\nCurrent approaches are not able to provide both of these, which motivates the\nwork in this paper. Our proposed approach leverages prior information about the\nactions to embed them in a continuous space upon which it can generalize.\nAdditionally, approximate nearest-neighbor methods allow for logarithmic-time\nlookup complexity relative to the number of actions, which is necessary for\ntime-wise tractable training. This combined approach allows reinforcement\nlearning methods to be applied to large-scale learning problems previously\nintractable with current methods. We demonstrate our algorithm's abilities on a\nseries of tasks having up to one million actions.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Reinforcement Learning in Large Discrete Action Spaces",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Aviv Tamar'}, {'name': 'Yi Wu'}, {'name': 'Garrett Thomas'}, {'name': 'Sergey Levine'}, {'name': 'Pieter Abbeel'}]",
//  "day": 9,
//  "id": "1602.02867v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1602.02867v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1602.02867v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We introduce the value iteration network (VIN): a fully differentiable neural\nnetwork with a `planning module' embedded within. VINs can learn to plan, and\nare suitable for predicting outcomes that involve planning-based reasoning,\nsuch as policies for reinforcement learning. Key to our approach is a novel\ndifferentiable approximation of the value-iteration algorithm, which can be\nrepresented as a convolutional neural network, and trained end-to-end using\nstandard backpropagation. We evaluate VIN based policies on discrete and\ncontinuous path-planning domains, and on a natural-language based search task.\nWe show that by learning an explicit planning computation, VIN policies\ngeneralize better to new, unseen domains.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Value Iteration Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mikael Henaff'}, {'name': 'Arthur Szlam'}, {'name': 'Yann LeCun'}]",
//  "day": 22,
//  "id": "1602.06662v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1602.06662v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1602.06662v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Although RNNs have been shown to be powerful tools for processing sequential\ndata, finding architectures or optimization strategies that allow them to model\nvery long term dependencies is still an active area of research. In this work,\nwe carefully analyze two synthetic datasets originally outlined in (Hochreiter\nand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store\ninformation over many time steps. We explicitly construct RNN solutions to\nthese problems, and using these constructions, illuminate both the problems\nthemselves and the way in which RNNs store different types of information in\ntheir hidden states. These constructions furthermore explain the success of\nrecent methods that specify unitary initializations or constraints on the\ntransition matrices.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Recurrent Orthogonal Networks and Long-Memory Tasks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Hado van Hasselt'}, {'name': 'Arthur Guez'}, {'name': 'Matteo Hessel'}, {'name': 'Volodymyr Mnih'}, {'name': 'David Silver'}]",
//  "day": 24,
//  "id": "1602.07714v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1602.07714v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1602.07714v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Most learning algorithms are not invariant to the scale of the function that\nis being approximated. We propose to adaptively normalize the targets used in\nlearning. This is useful in value-based reinforcement learning, where the\nmagnitude of appropriate value approximations can change over time when we\nupdate the policy of behavior. Our main motivation is prior work on learning to\nplay Atari games, where the rewards were all clipped to a predetermined range.\nThis clipping facilitates learning across many different games with a single\nlearning algorithm, but a clipped reward function can result in qualitatively\ndifferent behavior. Using the adaptive normalization we can remove this\ndomain-specific heuristic without diminishing overall performance.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning values across many orders of magnitude",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Laura Deming'}, {'name': 'Sasha Targ'}, {'name': 'Nate Sauder'}, {'name': 'Diogo Almeida'}, {'name': 'Chun Jimmie Ye'}]",
//  "day": 23,
//  "id": "1605.07156v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.07156v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.07156v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Each human genome is a 3 billion base pair set of encoding instructions.\nDecoding the genome using deep learning fundamentally differs from most tasks,\nas we do not know the full structure of the data and therefore cannot design\narchitectures to suit it. As such, architectures that fit the structure of\ngenomics should be learned not prescribed. Here, we develop a novel search\nalgorithm, applicable across domains, that discovers an optimal architecture\nwhich simultaneously learns general genomic patterns and identifies the most\nimportant sequence motifs in predicting functional genomic outcomes. The\narchitectures we find using this algorithm succeed at using only RNA expression\ndata to predict gene regulatory structure, learn human-interpretable\nvisualizations of key sequence motifs, and surpass state-of-the-art results on\nbenchmark genomics challenges.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Genetic Architect: Discovering Genomic Structure with Learned Neural\n  Architectures",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tejas D. Kulkarni'}, {'name': 'Ardavan Saeedi'}, {'name': 'Simanta Gautam'}, {'name': 'Samuel J. Gershman'}]",
//  "day": 8,
//  "id": "1606.02396v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.02396v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.02396v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Learning robust value functions given raw observations and rewards is now\npossible with model-free and model-based deep reinforcement learning\nalgorithms. There is a third alternative, called Successor Representations\n(SR), which decomposes the value function into two components -- a reward\npredictor and a successor map. The successor map represents the expected future\nstate occupancy from any given state and the reward predictor maps states to\nscalar rewards. The value function of a state can be computed as the inner\nproduct between the successor map and the reward weights. In this paper, we\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\nlearning framework. DSR has several appealing properties including: increased\nsensitivity to distal reward changes due to factorization of reward and world\ndynamics, and the ability to extract bottleneck states (subgoals) given\nsuccessor maps trained under a random policy. We show the efficacy of our\napproach on two diverse environments given raw pixel observations -- simple\ngrid-world domains (MazeBase) and the Doom game engine.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Successor Reinforcement Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yan Duan'}, {'name': 'John Schulman'}, {'name': 'Xi Chen'}, {'name': 'Peter L. Bartlett'}, {'name': 'Ilya Sutskever'}, {'name': 'Pieter Abbeel'}]",
//  "day": 9,
//  "id": "1611.02779v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.02779v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.02779v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Deep reinforcement learning (deep RL) has been successful in learning\nsophisticated behaviors automatically; however, the learning process requires a\nhuge number of trials. In contrast, animals can learn new tasks in just a few\ntrials, benefiting from their prior knowledge about the world. This paper seeks\nto bridge this gap. Rather than designing a \"fast\" reinforcement learning\nalgorithm, we propose to represent it as a recurrent neural network (RNN) and\nlearn it from data. In our proposed method, RL$^2$, the algorithm is encoded in\nthe weights of the RNN, which are learned slowly through a general-purpose\n(\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm\nwould receive, including observations, actions, rewards, and termination flags;\nand it retains its state across episodes in a given Markov Decision Process\n(MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on\nthe current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both\nsmall-scale and large-scale problems. On the small-scale side, we train it to\nsolve randomly generated multi-arm bandit problems and finite MDPs. After\nRL$^2$ is trained, its performance on new MDPs is close to human-designed\nalgorithms with optimality guarantees. On the large-scale side, we test RL$^2$\non a vision-based navigation task and show that it scales up to\nhigh-dimensional problems.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jasmine Collins'}, {'name': 'Jascha Sohl-Dickstein'}, {'name': 'David Sussillo'}]",
//  "day": 29,
//  "id": "1611.09913v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.09913v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.09913v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Two potential bottlenecks on the expressiveness of recurrent neural networks\n(RNNs) are their ability to store information about the task in their\nparameters, and to store information about the input history in their units. We\nshow experimentally that all common RNN architectures achieve nearly the same\nper-task and per-unit capacity bounds with careful training, for a variety of\ntasks and stacking depths. They can store an amount of task information which\nis linear in the number of parameters, and is approximately 5 bits per\nparameter. They can additionally store approximately one real number from their\ninput history per hidden unit. We further find that for several tasks it is the\nper-task parameter capacity bound that determines performance. These results\nsuggest that many previous results comparing RNN architectures are driven\nprimarily by differences in training effectiveness, rather than differences in\ncapacity. Supporting this observation, we compare training difficulty for\nseveral architectures, and show that vanilla RNNs are far more difficult to\ntrain, yet have slightly higher capacity. Finally, we propose two novel RNN\narchitectures, one of which is easier to train than the LSTM or GRU for deeply\nstacked architectures.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Capacity and Trainability in Recurrent Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mohammad Taha Bahadori'}, {'name': 'Krzysztof Chalupka'}, {'name': 'Edward Choi'}, {'name': 'Robert Chen'}, {'name': 'Walter F. Stewart'}, {'name': 'Jimeng Sun'}]",
//  "day": 8,
//  "id": "1702.02604v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.02604v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.02604v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "In application domains such as healthcare, we want accurate predictive models\nthat are also causally interpretable. In pursuit of such models, we propose a\ncausal regularizer to steer predictive models towards causally-interpretable\nsolutions and theoretically study its properties. In a large-scale analysis of\nElectronic Health Records (EHR), our causally-regularized model outperforms its\nL1-regularized counterpart in causal accuracy and is competitive in predictive\nperformance. We perform non-linear causality analysis by causally regularizing\na special neural network architecture. We also show that the proposed causal\nregularizer can be used together with neural representation learning algorithms\nto yield up to 20% improvement over multilayer perceptron in detecting\nmultivariate causation, a situation common in healthcare, where many causal\nfactors should occur simultaneously to have an effect on the target variable.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Causal Regularization",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Dario Garcia-Gasulla'}, {'name': 'Ferran Par\u00e9s'}, {'name': 'Armand Vilalta'}, {'name': 'Jonatan Moreno'}, {'name': 'Eduard Ayguad\u00e9'}, {'name': 'Jes\u00fas Labarta'}, {'name': 'Ulises Cort\u00e9s'}, {'name': 'Toyotaro Suzumura'}]",
//  "day": 3,
//  "id": "1703.01127v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.01127v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.01127v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Deep neural networks are representation learning techniques. During training,\na deep net is capable of generating a descriptive language of unprecedented\nsize and detail in machine learning. Extracting the descriptive language coded\nwithin a trained CNN model (in the case of image data), and reusing it for\nother purposes is a field of interest, as it provides access to the visual\ndescriptors previously learnt by the CNN after processing millions of images,\nwithout requiring an expensive training phase. Contributions to this field\n(commonly known as feature representation transfer or transfer learning) have\nbeen purely empirical so far, extracting all CNN features from a single layer\nclose to the output and testing their performance by feeding them to a\nclassifier. This approach has provided consistent results, although its\nrelevance is limited to classification tasks. In a completely different\napproach, in this paper we statistically measure the discriminative power of\nevery single feature found within a deep CNN, when used for characterizing\nevery class of 11 datasets. We seek to provide new insights into the behavior\nof CNN features, particularly the ones from convolutional layers, as this can\nbe relevant for their application to knowledge representation and reasoning.\nOur results confirm that low and middle level features may behave differently\nto high level features, but only under certain conditions. We find that all CNN\nfeatures can be used for knowledge representation purposes both by their\npresence or by their absence, doubling the information a single CNN feature may\nprovide. We also study how much noise these features may include, and propose a\nthresholding approach to discard most of it. All these insights have a direct\napplication to the generation of CNN embedding spaces.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "On the Behavior of Convolutional Nets for Feature Extraction",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Aditya Grover'}, {'name': 'Manik Dhar'}, {'name': 'Stefano Ermon'}]",
//  "day": 24,
//  "id": "1705.08868v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08868v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08868v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Adversarial learning of probabilistic models has recently emerged as a\npromising alternative to maximum likelihood. Implicit models such as generative\nadversarial networks (GAN) often generate better samples compared to explicit\nmodels trained by maximum likelihood. Yet, GANs sidestep the characterization\nof an explicit density which makes quantitative evaluations challenging. To\nbridge this gap, we propose Flow-GANs, a generative adversarial network for\nwhich we can perform exact likelihood evaluation, thus supporting both\nadversarial and maximum likelihood training. When trained adversarially,\nFlow-GANs generate high-quality samples but attain extremely poor\nlog-likelihood scores, inferior even to a mixture model memorizing the training\ndata; the opposite is true when trained by maximum likelihood. Results on MNIST\nand CIFAR-10 demonstrate that hybrid training can attain high held-out\nlikelihoods while retaining visual fidelity in the generated samples.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in\n  Generative Models",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chris J. Maddison'}, {'name': 'Dieterich Lawson'}, {'name': 'George Tucker'}, {'name': 'Nicolas Heess'}, {'name': 'Mohammad Norouzi'}, {'name': 'Andriy Mnih'}, {'name': 'Arnaud Doucet'}, {'name': 'Yee Whye Teh'}]",
//  "day": 25,
//  "id": "1705.09279v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.09279v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.09279v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "When used as a surrogate objective for maximum likelihood estimation in\nlatent variable models, the evidence lower bound (ELBO) produces\nstate-of-the-art results. Inspired by this, we consider the extension of the\nELBO to a family of lower bounds defined by a particle filter's estimator of\nthe marginal likelihood, the filtering variational objectives (FIVOs). FIVOs\ntake the same arguments as the ELBO, but can exploit a model's sequential\nstructure to form tighter bounds. We present results that relate the tightness\nof FIVO's bound to the variance of the particle filter's estimator by\nconsidering the generic case of bounds defined as log-transformed likelihood\nestimators. Experimentally, we show that training with FIVO results in\nsubstantial improvements over training the same model architecture with the\nELBO on sequential data.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Filtering Variational Objectives",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jiaxin Shi'}, {'name': 'Shengyang Sun'}, {'name': 'Jun Zhu'}]",
//  "day": 29,
//  "id": "1705.10119v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10119v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10119v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Recent progress in variational inference has paid much attention to the\nflexibility of variational posteriors. One promising direction is to use\nimplicit distributions, i.e., distributions without tractable densities as the\nvariational posterior. However, existing methods on implicit posteriors still\nface challenges of noisy estimation and computational infeasibility when\napplied to models with high-dimensional latent variables. In this paper, we\npresent a new approach named Kernel Implicit Variational Inference that\naddresses these challenges. As far as we know, for the first time implicit\nvariational inference is successfully applied to Bayesian neural networks,\nwhich shows promising results on both regression and classification tasks.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Kernel Implicit Variational Inference",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Julien Perez'}, {'name': 'Tomi Silander'}]",
//  "day": 31,
//  "id": "1705.10993v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10993v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10993v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Partially observable environments present an important open challenge in the\ndomain of sequential control learning with delayed rewards. Despite numerous\nattempts during the two last decades, the majority of reinforcement learning\nalgorithms and associated approximate models, applied to this context, still\nassume Markovian state transitions. In this paper, we explore the use of a\nrecently proposed attention-based model, the Gated End-to-End Memory Network,\nfor sequential control. We call the resulting model the Gated End-to-End Memory\nPolicy Network. More precisely, we use a model-free value-based algorithm to\nlearn policies for partially observed domains using this memory-enhanced neural\nnetwork. This model is end-to-end learnable and it features unbounded memory.\nIndeed, because of its attention mechanism and associated non-parametric\nmemory, the proposed model allows us to define an attention mechanism over the\nobservation stream unlike recurrent models. We show encouraging results that\nillustrate the capability of our attention-based model in the context of the\ncontinuous-state non-stationary control problem of stock trading. We also\npresent an OpenAI Gym environment for simulated stock exchange and explain its\nrelevance as a benchmark for the field of non-Markovian decision process\nlearning.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Non-Markovian Control with Gated End-to-End Memory Policy Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Emmanuel Dufourq'}, {'name': 'Bruce A. Bassett'}]",
//  "day": 3,
//  "id": "1707.00703v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.00703v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.00703v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Regression or classification? This is perhaps the most basic question faced\nwhen tackling a new supervised learning problem. We present an Evolutionary\nDeep Learning (EDL) algorithm that automatically solves this by identifying the\nquestion type with high accuracy, along with a proposed deep architecture.\nTypically, a significant amount of human insight and preparation is required\nprior to executing machine learning algorithms. For example, when creating deep\nneural networks, the number of parameters must be selected in advance and\nfurthermore, a lot of these choices are made based upon pre-existing knowledge\nof the data such as the use of a categorical cross entropy loss function.\nHumans are able to study a dataset and decide whether it represents a\nclassification or a regression problem, and consequently make decisions which\nwill be applied to the execution of the neural network. We propose the\nAutomated Problem Identification (API) algorithm, which uses an evolutionary\nalgorithm interface to TensorFlow to manipulate a deep neural network to decide\nif a dataset represents a classification or a regression problem. We test API\non 16 different classification, regression and sentiment analysis datasets with\nup to 10,000 features and up to 17,000 unique target values. API achieves an\naverage accuracy of $96.3\\%$ in identifying the problem type without hardcoding\nany insights about the general characteristics of regression or classification\nproblems. For example, API successfully identifies classification problems even\nwith 1000 target values. Furthermore, the algorithm recommends which loss\nfunction to use and also recommends a neural network architecture. Our work is\ntherefore a step towards fully automated machine learning.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Automated Problem Identification: Regression vs Classification via\n  Evolutionary Deep Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Nikhil Mishra'}, {'name': 'Mostafa Rohaninejad'}, {'name': 'Xi Chen'}, {'name': 'Pieter Abbeel'}]",
//  "day": 11,
//  "id": "1707.03141v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.03141v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.03141v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Deep neural networks excel in regimes with large amounts of data, but tend to\nstruggle when data is scarce or when they need to adapt quickly to changes in\nthe task. In response, recent work in meta-learning proposes training a\nmeta-learner on a distribution of similar tasks, in the hopes of generalization\nto novel but related tasks by learning a high-level strategy that captures the\nessence of the problem it is asked to solve. However, many recent meta-learning\napproaches are extensively hand-designed, either using architectures\nspecialized to a particular application, or hard-coding algorithmic components\nthat constrain how the meta-learner solves the task. We propose a class of\nsimple and generic meta-learner architectures that use a novel combination of\ntemporal convolutions and soft attention; the former to aggregate information\nfrom past experience and the latter to pinpoint specific pieces of information.\nIn the most extensive set of meta-learning experiments to date, we evaluate the\nresulting Simple Neural AttentIve Learner (or SNAIL) on several\nheavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\nlearning, SNAIL attains state-of-the-art performance by significant margins.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Simple Neural Attentive Meta-Learner",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Simone Scardapane'}, {'name': 'Steven Van Vaerenbergh'}, {'name': 'Simone Totaro'}, {'name': 'Aurelio Uncini'}]",
//  "day": 13,
//  "id": "1707.04035v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.04035v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.04035v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Neural networks are generally built by interleaving (adaptable) linear layers\nwith (fixed) nonlinear activation functions. To increase their flexibility,\nseveral authors have proposed methods for adapting the activation functions\nthemselves, endowing them with varying degrees of flexibility. None of these\napproaches, however, have gained wide acceptance in practice, and research in\nthis topic remains open. In this paper, we introduce a novel family of flexible\nactivation functions that are based on an inexpensive kernel expansion at every\nneuron. Leveraging over several properties of kernel-based models, we propose\nmultiple variations for designing and initializing these kernel activation\nfunctions (KAFs), including a multidimensional scheme allowing to nonlinearly\ncombine information from different paths in the network. The resulting KAFs can\napproximate any mapping defined over a subset of the real line, either convex\nor nonconvex. Furthermore, they are smooth over their entire domain, linear in\ntheir parameters, and they can be regularized using any known scheme, including\nthe use of $\\ell_1$ penalties to enforce sparseness. To the best of our\nknowledge, no other known model satisfies all these properties simultaneously.\nIn addition, we provide a relatively complete overview on alternative\ntechniques for adapting the activation functions, which is currently lacking in\nthe literature. A large set of experiments validates our proposal.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Kafnets: kernel-based non-parametric activation functions for neural\n  networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Razvan Pascanu'}, {'name': 'Yujia Li'}, {'name': 'Oriol Vinyals'}, {'name': 'Nicolas Heess'}, {'name': 'Lars Buesing'}, {'name': 'Sebastien Racani\u00e8re'}, {'name': 'David Reichert'}, {'name': 'Th\u00e9ophane Weber'}, {'name': 'Daan Wierstra'}, {'name': 'Peter Battaglia'}]",
//  "day": 19,
//  "id": "1707.06170v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.06170v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.06170v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Conventional wisdom holds that model-based planning is a powerful approach to\nsequential decision-making. It is often very challenging in practice, however,\nbecause while a model can be used to evaluate a plan, it does not prescribe how\nto construct a plan. Here we introduce the \"Imagination-based Planner\", the\nfirst model-based, sequential decision-making agent that can learn to\nconstruct, evaluate, and execute plans. Before any action, it can perform a\nvariable number of imagination steps, which involve proposing an imagined\naction and evaluating it with its model-based imagination. All imagined actions\nand outcomes are aggregated, iteratively, into a \"plan context\" which\nconditions future real and imagined actions. The agent can even decide how to\nimagine: testing out alternative imagined actions, chaining sequences of\nactions together, or building a more complex \"imagination tree\" by navigating\nflexibly among the previously imagined states using a learned policy. And our\nagent can learn to plan economically, jointly optimizing for external rewards\nand computational costs associated with using its imagination. We show that our\narchitecture can learn to solve a challenging continuous control problem, and\nalso learn elaborate planning strategies in a discrete maze-solving task. Our\nwork opens a new direction toward learning the components of a model-based\nplanning system and how to use them.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning model-based planning from scratch",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Isabeau Pr\u00e9mont-Schwarz'}, {'name': 'Alexander Ilin'}, {'name': 'Tele Hotloo Hao'}, {'name': 'Antti Rasmus'}, {'name': 'Rinu Boney'}, {'name': 'Harri Valpola'}]",
//  "day": 28,
//  "id": "1707.09219v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.09219v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.09219v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "We propose a recurrent extension of the Ladder networks whose structure is\nmotivated by the inference required in hierarchical latent variable models. We\ndemonstrate that the recurrent Ladder is able to handle a wide variety of\ncomplex learning tasks that benefit from iterative inference and temporal\nmodeling. The architecture shows close-to-optimal results on temporal modeling\nof video data, competitive results on music modeling, and improved perceptual\ngrouping based on higher order abstractions, such as stochastic textures and\nmotion cues. We present results for fully supervised, semi-supervised, and\nunsupervised tasks. The results suggest that the proposed architecture and\nprinciples are powerful tools for learning a hierarchy of abstractions,\nlearning iterative inference and handling temporal information.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Recurrent Ladder Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kenji Kawaguchi'}, {'name': 'Leslie Pack Kaelbling'}, {'name': 'Yoshua Bengio'}]",
//  "day": 16,
//  "id": "1710.05468v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.05468v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.05468v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "With a direct analysis of neural networks, this paper presents a\nmathematically tight generalization theory to partially address an open problem\nregarding the generalization of deep learning. Unlike previous bound-based\ntheory, our main theory is quantitatively as tight as possible for every\ndataset individually, while producing qualitative insights competitively. Our\nresults give insight into why and how deep learning can generalize well,\ndespite its large capacity, complexity, possible algorithmic instability,\nnonrobustness, and sharp minima, answering to an open question in the\nliterature. We also discuss limitations of our results and propose additional\nopen problems.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generalization in Deep Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yannic Kilcher'}, {'name': 'Gary Becigneul'}, {'name': 'Thomas Hofmann'}]",
//  "day": 31,
//  "id": "1710.11386v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.11386v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.11386v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "It is commonly agreed that the use of relevant invariances as a good\nstatistical bias is important in machine-learning. However, most approaches\nthat explicitly incorporate invariances into a model architecture only make use\nof very simple transformations, such as translations and rotations. Hence,\nthere is a need for methods to model and extract richer transformations that\ncapture much higher-level invariances. To that end, we introduce a tool\nallowing to parametrize the set of filters of a trained convolutional neural\nnetwork with the latent space of a generative adversarial network. We then show\nthat the method can capture highly non-linear invariances of the data by\nvisualizing their effect in the data space.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Parametrizing filters of a CNN with a GAN",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhen He'}, {'name': 'Shaobing Gao'}, {'name': 'Liang Xiao'}, {'name': 'Daxue Liu'}, {'name': 'Hangen He'}, {'name': 'David Barber'}]",
//  "day": 5,
//  "id": "1711.01577v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.01577v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.01577v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Long Short-Term Memory (LSTM) is a popular approach to boosting the ability\nof Recurrent Neural Networks to store longer term temporal information. The\ncapacity of an LSTM network can be increased by widening and adding layers.\nHowever, usually the former introduces additional parameters, while the latter\nincreases the runtime. As an alternative we propose the Tensorized LSTM in\nwhich the hidden states are represented by tensors and updated via a\ncross-layer convolution. By increasing the tensor size, the network can be\nwidened efficiently without additional parameters since the parameters are\nshared across different locations in the tensor; by delaying the output, the\nnetwork can be deepened implicitly with little additional runtime since deep\ncomputations for each timestep are merged into temporal computations of the\nsequence. Experiments conducted on five challenging sequence learning tasks\nshow the potential of the proposed model.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence\n  Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Shruti R. Kulkarni'}, {'name': 'John M. Alexiades'}, {'name': 'Bipin Rajendran'}]",
//  "day": 9,
//  "id": "1711.03637v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.03637v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.03637v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We describe a novel spiking neural network (SNN) for automated, real-time\nhandwritten digit classification and its implementation on a GP-GPU platform.\nInformation processing within the network, from feature extraction to\nclassification is implemented by mimicking the basic aspects of neuronal spike\ninitiation and propagation in the brain. The feature extraction layer of the\nSNN uses fixed synaptic weight maps to extract the key features of the image\nand the classifier layer uses the recently developed NormAD approximate\ngradient descent based supervised learning algorithm for spiking neural\nnetworks to adjust the synaptic weights. On the standard MNIST database images\nof handwritten digits, our network achieves an accuracy of 99.80% on the\ntraining set and 98.06% on the test set, with nearly 7x fewer parameters\ncompared to the state-of-the-art spiking networks. We further use this network\nin a GPU based user-interface system demonstrating real-time SNN simulation to\ninfer digits written by different users. On a test set of 500 such images, this\nreal-time platform achieves an accuracy exceeding 97% while making a prediction\nwithin an SNN emulation time of less than 100ms.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning and Real-time Classification of Hand-written Digits With\n  Spiking Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Joan Serr\u00e0'}, {'name': 'D\u00eddac Sur\u00eds'}, {'name': 'Marius Miron'}, {'name': 'Alexandros Karatzoglou'}]",
//  "day": 4,
//  "id": "1801.01423v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.01423v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.01423v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Catastrophic forgetting occurs when a neural network loses the information\nlearned in a previous task after training on subsequent tasks. This problem\nremains a hurdle for artificial intelligence systems with sequential learning\ncapabilities. In this paper, we propose a task-based hard attention mechanism\nthat preserves previous tasks' information without affecting the current task's\nlearning. A hard attention mask is learned concurrently to every task, through\nstochastic gradient descent, and previous masks are exploited to condition such\nlearning. We show that the proposed mechanism is effective for reducing\ncatastrophic forgetting, cutting current rates by 45 to 80%. We also show that\nit is robust to different hyperparameter choices, and that it offers a number\nof monitoring capabilities. The approach features the possibility to control\nboth the stability and compactness of the learned knowledge, which we believe\nmakes it also attractive for online learning or network compression\napplications.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Overcoming catastrophic forgetting with hard attention to the task",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Zachary C. Lipton'}, {'name': 'Yu-Xiang Wang'}, {'name': 'Alex Smola'}]",
//  "day": 12,
//  "id": "1802.03916v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.03916v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.03916v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Faced with distribution shift between training and test set, we wish to\ndetect and quantify the shift, and to correct our classifiers without test set\nlabels. Motivated by medical diagnosis, where diseases (targets), cause\nsymptoms (observations), we focus on label shift, where the label marginal\n$p(y)$ changes but the conditional $p(x|y)$ does not. We propose Black Box\nShift Estimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits\narbitrary black box predictors to reduce dimensionality prior to shift\ncorrection. While better predictors give tighter estimates, BBSE works even\nwhen predictors are biased, inaccurate, or uncalibrated, so long as their\nconfusion matrices are invertible. We prove BBSE's consistency, bound its\nerror, and introduce a statistical test that uses BBSE to detect shift. We also\nleverage BBSE to correct classifiers. Experiments demonstrate accurate\nestimates and improved prediction, even on high-dimensional datasets of natural\nimages.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Detecting and Correcting for Label Shift with Black Box Predictors",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Kenji Kawaguchi'}, {'name': 'Yoshua Bengio'}]",
//  "day": 21,
//  "id": "1802.07426v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.07426v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.07426v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "This paper introduces a novel measure-theoretic learning theory to analyze\ngeneralization behaviors of practical interest. The proposed learning theory\nhas the following abilities: 1) to utilize the qualities of each learned\nrepresentation on the path from raw inputs to outputs in representation\nlearning, 2) to guarantee good generalization errors possibly with arbitrarily\nrich hypothesis spaces (e.g., arbitrarily large capacity and Rademacher\ncomplexity) and non-stable/non-robust learning algorithms, and 3) to clearly\ndistinguish each individual problem instance from each other. Our\ngeneralization bounds are relative to a representation of the data, and hold\ntrue even if the representation is learned. We discuss several consequences of\nour results on deep learning, one-shot learning and curriculum learning. Unlike\nstatistical learning theory, the proposed learning theory analyzes each problem\ninstance individually via measure theory, rather than a set of problem\ninstances via statistics. Because of the differences in the assumptions and the\nobjectives, the proposed learning theory is meant to be complementary to\nprevious learning theory and is not designed to compete with it.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generalization in Machine Learning via Analytical Learning Theory",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Roman Novak'}, {'name': 'Yasaman Bahri'}, {'name': 'Daniel A. Abolafia'}, {'name': 'Jeffrey Pennington'}, {'name': 'Jascha Sohl-Dickstein'}]",
//  "day": 23,
//  "id": "1802.08760v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.08760v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.08760v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "In practice it is often found that large over-parameterized neural networks\ngeneralize better than their smaller counterparts, an observation that appears\nto conflict with classical notions of function complexity, which typically\nfavor smaller models. In this work, we investigate this tension between\ncomplexity and generalization through an extensive empirical exploration of two\nnatural metrics of complexity related to sensitivity to input perturbations.\nOur experiments survey thousands of models with various fully-connected\narchitectures, optimizers, and other hyper-parameters, as well as four\ndifferent image classification datasets.\n  We find that trained neural networks are more robust to input perturbations\nin the vicinity of the training data manifold, as measured by the norm of the\ninput-output Jacobian of the network, and that it correlates well with\ngeneralization. We further establish that factors associated with poor\ngeneralization $-$ such as full-batch training or using random labels $-$\ncorrespond to lower robustness, while factors associated with good\ngeneralization $-$ such as data augmentation and ReLU non-linearities $-$ give\nrise to more robust functions. Finally, we demonstrate how the input-output\nJacobian norm can be predictive of generalization at the level of individual\ntest points.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sensitivity and Generalization in Neural Networks: an Empirical Study",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Ari S. Morcos'}, {'name': 'David G. T. Barrett'}, {'name': 'Neil C. Rabinowitz'}, {'name': 'Matthew Botvinick'}]",
//  "day": 19,
//  "id": "1803.06959v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1803.06959v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1803.06959v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "On the importance of single directions for generalization",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Srinivas C. Turaga'}, {'name': 'Kevin L. Briggman'}, {'name': 'Moritz Helmstaedter'}, {'name': 'Winfried Denk'}, {'name': 'H. Sebastian Seung'}]",
//  "day": 28,
//  "id": "0911.5372v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/0911.5372v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/0911.5372v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Images can be segmented by first using a classifier to predict an affinity\ngraph that reflects the degree to which image pixels must be grouped together\nand then partitioning the graph to yield a segmentation. Machine learning has\nbeen applied to the affinity classifier to produce affinity graphs that are\ngood in the sense of minimizing edge misclassification rates. However, this\nerror measure is only indirectly related to the quality of segmentations\nproduced by ultimately partitioning the affinity graph. We present the first\nmachine learning algorithm for training a classifier to produce affinity graphs\nthat are good in the sense of producing segmentations that directly minimize\nthe Rand index, a well known segmentation performance measure. The Rand index\nmeasures segmentation performance by quantifying the classification of the\nconnectivity of image pixel pairs after segmentation. By using the simple graph\npartitioning algorithm of finding the connected components of the thresholded\naffinity graph, we are able to train an affinity classifier to directly\nminimize the Rand index of segmentations resulting from the graph partitioning.\nOur learning algorithm corresponds to the learning of maximin affinities\nbetween image pixel pairs, which are predictive of the pixel-pair connectivity.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Maximin affinity learning of image segmentation",
//  "year": 2009
//},
//{
//  "author": "[{'name': 'Sergey S. Tarasenko'}]",
//  "day": 14,
//  "id": "1102.2739v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1102.2739v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1102.2739v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "This study is focused on the development of the cortex-like visual object\nrecognition system. We propose a general framework, which consists of three\nhierarchical levels (modules). These modules functionally correspond to the V1,\nV4 and IT areas. Both bottom-up and top-down connections between the\nhierarchical levels V4 and IT are employed. The higher the degree of matching\nbetween the input and the preferred stimulus, the shorter the response time of\nthe neuron. Therefore information about a single stimulus is distributed in\ntime and is transmitted by the waves of spikes. The reciprocal connections and\nwaves of spikes implement predictive coding: an initial hypothesis is generated\non the basis of information delivered by the first wave of spikes and is tested\nwith the information carried by the consecutive waves. The development is\nconsidered as extraction and accumulation of features in V4 and objects in IT.\nOnce stored a feature can be disposed, if rarely activated. This cause update\nof feature repository. Consequently, objects in IT are also updated. This\nillustrates the growing process and dynamical change of topological structures\nof V4, IT and connections between these areas.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A General Framework for Development of the Cortex-like Visual Object\n  Recognition System: Waves of Spikes, Predictive Coding and Universal\n  Dictionary of Features",
//  "year": 2011
//},
//{
//  "author": "[{'name': 'Dan C. Cire\u015fan'}, {'name': 'Ueli Meier'}, {'name': 'Luca M. Gambardella'}, {'name': 'J\u00fcrgen Schmidhuber'}]",
//  "day": 23,
//  "id": "1103.4487v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1103.4487v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1103.4487v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Handwritten Digit Recognition with a Committee of Deep Neural Nets on\n  GPUs",
//  "year": 2011
//},
//{
//  "author": "[{'name': 'Ridwan Al Iqbal'}]",
//  "day": 2,
//  "id": "1110.0214v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1110.0214v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1110.0214v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Artificial Neural Network is among the most popular algorithm for supervised\nlearning. However, Neural Networks have a well-known drawback of being a \"Black\nBox\" learner that is not comprehensible to the Users. This lack of transparency\nmakes it unsuitable for many high risk tasks such as medical diagnosis that\nrequires a rational justification for making a decision. Rule Extraction\nmethods attempt to curb this limitation by extracting comprehensible rules from\na trained Network. Many such extraction algorithms have been developed over the\nyears with their respective strengths and weaknesses. They have been broadly\ncategorized into three types based on their approach to use internal model of\nthe Network. Eclectic Methods are hybrid algorithms that combine the other\napproaches to attain more performance. In this paper, we present an Eclectic\nmethod called HERETIC. Our algorithm uses Inductive Decision Tree learning\ncombined with information of the neural network structure for extracting\nlogical rules. Experiments and theoretical analysis show HERETIC to be better\nin terms of speed and performance.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Eclectic Extraction of Propositional Rules from Neural Networks",
//  "year": 2011
//},
//{
//  "author": "[{'name': 'Arnab Ghosh'}, {'name': 'Viveka Kulharia'}, {'name': 'Vinay Namboodiri'}]",
//  "day": 5,
//  "id": "1612.01294v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.01294v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.01294v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Communicating and sharing intelligence among agents is an important facet of\nachieving Artificial General Intelligence. As a first step towards this\nchallenge, we introduce a novel framework for image generation: Message Passing\nMulti-Agent Generative Adversarial Networks (MPM GANs). While GANs have\nrecently been shown to be very effective for image generation and other tasks,\nthese networks have been limited to mostly single generator-discriminator\nnetworks. We show that we can obtain multi-agent GANs that communicate through\nmessage passing to achieve better image generation. The objectives of the\nindividual agents in this framework are two fold: a co-operation objective and\na competing objective. The co-operation objective ensures that the message\nsharing mechanism guides the other generator to generate better than itself\nwhile the competing objective encourages each generator to generate better than\nits counterpart. We analyze and visualize the messages that these GANs share\namong themselves in various scenarios. We quantitatively show that the message\nsharing formulation serves as a regularizer for the adversarial training.\nQualitatively, we show that the different generators capture different traits\nof the underlying data distribution.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Message Passing Multi-Agent GANs",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tong Che'}, {'name': 'Yanran Li'}, {'name': 'Athul Paul Jacob'}, {'name': 'Yoshua Bengio'}, {'name': 'Wenjie Li'}]",
//  "day": 7,
//  "id": "1612.02136v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.02136v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.02136v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Mode Regularized Generative Adversarial Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Bharat Singh'}, {'name': 'Soham De'}, {'name': 'Yangmuzi Zhang'}, {'name': 'Thomas Goldstein'}, {'name': 'Gavin Taylor'}]",
//  "day": 15,
//  "id": "1510.04609v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.04609v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.04609v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "The increasing complexity of deep learning architectures is resulting in\ntraining time requiring weeks or even months. This slow training is due in part\nto vanishing gradients, in which the gradients used by back-propagation are\nextremely large for weights connecting deep layers (layers near the output\nlayer), and extremely small for shallow layers (near the input layer); this\nresults in slow learning in the shallow layers. Additionally, it has also been\nshown that in highly non-convex problems, such as deep neural networks, there\nis a proliferation of high-error low curvature saddle points, which slows down\nlearning dramatically. In this paper, we attempt to overcome the two above\nproblems by proposing an optimization method for training deep neural networks\nwhich uses learning rates which are both specific to each layer in the network\nand adaptive to the curvature of the function, increasing the learning rate at\nlow curvature points. This enables us to speed up learning in the shallow\nlayers of the network and quickly escape high-error low curvature saddle\npoints. We test our method on standard image classification datasets such as\nMNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracy\nas well as reduces the required training time over standard algorithms.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Layer-Specific Adaptive Learning Rates for Deep Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Baochen Sun'}, {'name': 'Jiashi Feng'}, {'name': 'Kate Saenko'}]",
//  "day": 17,
//  "id": "1511.05547v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.05547v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.05547v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Unlike human learning, machine learning often fails to handle changes between\ntraining (source) and test (target) input distributions. Such domain shifts,\ncommon in practical scenarios, severely damage the performance of conventional\nmachine learning methods. Supervised domain adaptation methods have been\nproposed for the case when the target data have labels, including some that\nperform very well despite being \"frustratingly easy\" to implement. However, in\npractice, the target domain is often unlabeled, requiring unsupervised\nadaptation. We propose a simple, effective, and efficient method for\nunsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL\nminimizes domain shift by aligning the second-order statistics of source and\ntarget distributions, without requiring any target labels. Even though it is\nextraordinarily simple--it can be implemented in four lines of Matlab\ncode--CORAL performs remarkably well in extensive evaluations on standard\nbenchmark datasets.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Return of Frustratingly Easy Domain Adaptation",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Lukas Cavigelli'}, {'name': 'Luca Benini'}]",
//  "day": 14,
//  "id": "1512.04295v2",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/TCSVT.2016.2592330', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1512.04295v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1512.04295v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "An ever increasing number of computer vision and image/video processing\nchallenges are being approached using deep convolutional neural networks,\nobtaining state-of-the-art results in object recognition and detection,\nsemantic segmentation, action recognition, optical flow and superresolution.\nHardware acceleration of these algorithms is essential to adopt these\nimprovements in embedded and mobile computer vision systems. We present a new\narchitecture, design and implementation as well as the first reported silicon\nmeasurements of such an accelerator, outperforming previous work in terms of\npower-, area- and I/O-efficiency. The manufactured device provides up to 196\nGOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a power\nefficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it\nthe first architecture scalable to TOp/s performance.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'B.7.1; I.2.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Origami: A 803 GOp/s/W Convolutional Network Accelerator",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Aravind S. Lakshminarayanan'}, {'name': 'Ramnandan Krishnamurthy'}, {'name': 'Peeyush Kumar'}, {'name': 'Balaraman Ravindran'}]",
//  "day": 17,
//  "id": "1605.05359v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.05359v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.05359v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "This paper introduces an automated skill acquisition framework in\nreinforcement learning which involves identifying a hierarchical description of\nthe given task in terms of abstract states and extended actions between\nabstract states. Identifying such structures present in the task provides ways\nto simplify and speed up reinforcement learning algorithms. These structures\nalso help to generalize such algorithms over multiple tasks without relearning\npolicies from scratch. We use ideas from dynamical systems to find metastable\nregions in the state space and associate them with abstract states. The\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\naligned to the underlying structure. Skills are defined in terms of the\nsequence of actions that lead to transitions between such abstract states. The\nconnectivity information from PCCA+ is used to generate these skills or\noptions. These skills are independent of the learning task and can be\nefficiently reused across a variety of tasks defined over the same model. This\napproach works well even without the exact model of the environment by using\nsample trajectories to construct an approximate estimate. We also present our\napproach to scaling the skill acquisition framework to complex tasks with large\nstate spaces for which we perform state aggregation using the representation\nlearned from an action conditional video prediction network and use the skill\nacquisition framework on the aggregated state space.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Option Discovery in Hierarchical Reinforcement Learning using\n  Spatio-Temporal Clustering",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Andreas Veit'}, {'name': 'Michael Wilber'}, {'name': 'Serge Belongie'}]",
//  "day": 20,
//  "id": "1605.06431v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.06431v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.06431v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "In this work we propose a novel interpretation of residual networks showing\nthat they can be seen as a collection of many paths of differing length.\nMoreover, residual networks seem to enable very deep networks by leveraging\nonly the short paths during training. To support this observation, we rewrite\nresidual networks as an explicit collection of paths. Unlike traditional\nmodels, paths through residual networks vary in length. Further, a lesion study\nreveals that these paths show ensemble-like behavior in the sense that they do\nnot strongly depend on each other. Finally, and most surprising, most paths are\nshorter than one might expect, and only the short paths are needed during\ntraining, as longer paths do not contribute any gradient. For example, most of\nthe gradient in a residual network with 110 layers comes from paths that are\nonly 10-34 layers deep. Our results reveal one of the key characteristics that\nseem to enable the training of very deep networks: Residual networks avoid the\nvanishing gradient problem by introducing short paths which can carry gradient\nthroughout the extent of very deep networks.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Anh Nguyen'}, {'name': 'Alexey Dosovitskiy'}, {'name': 'Jason Yosinski'}, {'name': 'Thomas Brox'}, {'name': 'Jeff Clune'}]",
//  "day": 30,
//  "id": "1605.09304v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.09304v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.09304v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images).",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Rathinakumar Appuswamy'}, {'name': 'Tapan Nayak'}, {'name': 'John Arthur'}, {'name': 'Steven Esser'}, {'name': 'Paul Merolla'}, {'name': 'Jeffrey Mckinstry'}, {'name': 'Timothy Melano'}, {'name': 'Myron Flickner'}, {'name': 'Dharmendra Modha'}]",
//  "day": 8,
//  "id": "1606.02407v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.02407v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.02407v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We derive a relationship between network representation in energy-efficient\nneuromorphic architectures and block Toplitz convolutional matrices. Inspired\nby this connection, we develop deep convolutional networks using a family of\nstructured convolutional matrices and achieve state-of-the-art trade-off\nbetween energy efficiency and classification accuracy for well-known image\nrecognition tasks. We also put forward a novel method to train binary\nconvolutional networks by utilising an existing connection between\nnoisy-rectified linear units and binary activations.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Structured Convolution Matrices for Energy-efficient Deep learning",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Baochen Sun'}, {'name': 'Kate Saenko'}]",
//  "day": 6,
//  "id": "1607.01719v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1607.01719v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1607.01719v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Deep neural networks are able to learn powerful representations from large\nquantities of labeled input data, however they cannot always generalize well\nacross changes in input distributions. Domain adaptation algorithms have been\nproposed to compensate for the degradation in performance due to domain shift.\nIn this paper, we address the case when the target domain is unlabeled,\nrequiring unsupervised adaptation. CORAL is a \"frustratingly easy\" unsupervised\ndomain adaptation method that aligns the second-order statistics of the source\nand target distributions with a linear transformation. Here, we extend CORAL to\nlearn a nonlinear transformation that aligns correlations of layer activations\nin deep neural networks (Deep CORAL). Experiments on standard benchmark\ndatasets show state-of-the-art performance.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep CORAL: Correlation Alignment for Deep Domain Adaptation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jun Liu'}, {'name': 'Amir Shahroudy'}, {'name': 'Dong Xu'}, {'name': 'Gang Wang'}]",
//  "day": 24,
//  "id": "1607.07043v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1607.07043v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1607.07043v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "3D action recognition - analysis of human actions based on 3D skeleton data -\nbecomes popular recently due to its succinctness, robustness, and\nview-invariant representation. Recent attempts on this problem suggested to\ndevelop RNN-based learning methods to model the contextual dependency in the\ntemporal domain. In this paper, we extend this idea to spatio-temporal domains\nto analyze the hidden sources of action-related information within the input\ndata over both domains concurrently. Inspired by the graphical structure of the\nhuman skeleton, we further propose a more powerful tree-structure based\ntraversal method. To handle the noise and occlusion in 3D skeleton data, we\nintroduce new gating mechanism within LSTM to learn the reliability of the\nsequential input data and accordingly adjust its effect on updating the\nlong-term context information stored in the memory cell. Our method achieves\nstate-of-the-art performance on 4 challenging benchmark datasets for 3D human\naction analysis.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Suraj Srinivas'}, {'name': 'R. Venkatesh Babu'}]",
//  "day": 21,
//  "id": "1611.06791v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.06791v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.06791v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Deep Neural Networks often require good regularizers to generalize well.\nDropout is one such regularizer that is widely used among Deep Learning\npractitioners. Recent work has shown that Dropout can also be viewed as\nperforming Approximate Bayesian Inference over the network parameters. In this\nwork, we generalize this notion and introduce a rich family of regularizers\nwhich we call Generalized Dropout. One set of methods in this family, called\nDropout++, is a version of Dropout with trainable parameters. Classical Dropout\nemerges as a special case of this method. Another member of this family selects\nthe width of neural network layers. Experiments show that these methods help in\nimproving generalization performance over Dropout.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generalized Dropout",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'I. Theodorakopoulos'}, {'name': 'V. Pothos'}, {'name': 'D. Kastaniotis'}, {'name': 'N. Fragoulis'}]",
//  "day": 18,
//  "id": "1701.05221v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.05221v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.05221v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "A new, radical CNN design approach is presented in this paper, considering\nthe reduction of the total computational load during inference. This is\nachieved by a new holistic intervention on both the CNN architecture and the\ntraining procedure, which targets to the parsimonious inference by learning to\nexploit or remove the redundant capacity of a CNN architecture. This is\naccomplished, by the introduction of a new structural element that can be\ninserted as an add-on to any contemporary CNN architecture, whilst preserving\nor even improving its recognition accuracy. Our approach formulates a\nsystematic and data-driven method for developing CNNs that are trained to\neventually change size and form in real-time during inference, targeting to the\nsmaller possible computational footprint. Results are provided for the optimal\nimplementation on a few modern, high-end mobile computing platforms indicating\na significant speed-up of up to x3 times.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T10, 62H30, 68Q32, 68T05, 68Q32, 91E40', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.5; F.1.1; F.4.1; K.3.2; I.4; I.4.8', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Parsimonious Inference on Convolutional Neural Networks: Learning and\n  applying on-line kernel activation rules",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chelsea Finn'}, {'name': 'Pieter Abbeel'}, {'name': 'Sergey Levine'}]",
//  "day": 9,
//  "id": "1703.03400v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.03400v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.03400v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We propose an algorithm for meta-learning that is model-agnostic, in the\nsense that it is compatible with any model trained with gradient descent and\napplicable to a variety of different learning problems, including\nclassification, regression, and reinforcement learning. The goal of\nmeta-learning is to train a model on a variety of learning tasks, such that it\ncan solve new learning tasks using only a small number of training samples. In\nour approach, the parameters of the model are explicitly trained such that a\nsmall number of gradient steps with a small amount of training data from a new\ntask will produce good generalization performance on that task. In effect, our\nmethod trains the model to be easy to fine-tune. We demonstrate that this\napproach leads to state-of-the-art performance on two few-shot image\nclassification benchmarks, produces good results on few-shot regression, and\naccelerates fine-tuning for policy gradient reinforcement learning with neural\nnetwork policies.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Asit Mishra'}, {'name': 'Jeffrey J Cook'}, {'name': 'Eriko Nurvitadhi'}, {'name': 'Debbie Marr'}]",
//  "day": 10,
//  "id": "1704.03079v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.03079v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.03079v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "For computer vision applications, prior works have shown the efficacy of\nreducing the numeric precision of model parameters (network weights) in deep\nneural networks but also that reducing the precision of activations hurts model\naccuracy much more than reducing the precision of model parameters. We study\nschemes to train networks from scratch using reduced-precision activations\nwithout hurting the model accuracy. We reduce the precision of activation maps\n(along with model parameters) using a novel quantization scheme and increase\nthe number of filter maps in a layer, and find that this scheme compensates or\nsurpasses the accuracy of the baseline full-precision network. As a result, one\ncan significantly reduce the dynamic memory footprint, memory bandwidth,\ncomputational energy and speed up the training and inference process with\nappropriate hardware support. We call our scheme WRPN - wide reduced-precision\nnetworks. We report results using our proposed schemes and show that our\nresults are better than previously reported accuracies on ILSVRC-12 dataset\nwhile being computationally less expensive compared to previously reported\nreduced-precision networks.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "WRPN: Training and Inference using Wide Reduced-Precision Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'David Rolnick'}, {'name': 'Andreas Veit'}, {'name': 'Serge Belongie'}, {'name': 'Nir Shavit'}]",
//  "day": 30,
//  "id": "1705.10694v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10694v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10694v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Deep neural networks trained on large supervised datasets have led to\nimpressive results in image classification and other tasks. However,\nwell-annotated datasets can be time-consuming and expensive to collect, lending\nincreased interest to larger but noisy datasets that are more easily obtained.\nIn this paper, we show that deep neural networks are capable of generalizing\nfrom training data for which true labels are massively outnumbered by incorrect\nlabels. We demonstrate remarkably high test performance after training on\ncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain\ntest accuracy above 90 percent even after each clean training example has been\ndiluted with 100 randomly-labeled examples. Such behavior holds across multiple\npatterns of label noise, even when erroneous labels are biased towards\nconfusing classes. We show that training in this regime requires a significant\nbut manageable increase in dataset size that is related to the factor by which\ncorrect labels have been diluted. Finally, we provide an analysis of our\nresults that shows how increasing noise decreases the effective batch size.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Learning is Robust to Massive Label Noise",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Stefan Lattner'}, {'name': 'Maarten Grachten'}]",
//  "day": 5,
//  "id": "1707.01357v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.01357v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.01357v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Content-invariance in mapping codes learned by GAEs is a useful feature for\nvarious relation learning tasks. In this paper we show that the\ncontent-invariance of mapping codes for images of 2D and 3D rotated objects can\nbe substantially improved by extending the standard GAE loss (symmetric\nreconstruction error) with a regularization term that penalizes the symmetric\ncross-reconstruction error. This error term involves reconstruction of pairs\nwith mapping codes obtained from other pairs exhibiting similar\ntransformations. Although this would principally require knowledge of the\ntransformations exhibited by training pairs, our experiments show that a\nbootstrapping approach can sidestep this issue, and that the regularization\nterm can effectively be used in an unsupervised setting.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object\n  Rotation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jindong Wang'}, {'name': 'Yiqiang Chen'}, {'name': 'Shuji Hao'}, {'name': 'Xiaohui Peng'}, {'name': 'Lisha Hu'}]",
//  "day": 12,
//  "id": "1707.03502v2",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1016/j.patrec.2018.02.010', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.03502v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.03502v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Sensor-based activity recognition seeks the profound high-level knowledge\nabout human activities from multitudes of low-level sensor readings.\nConventional pattern recognition approaches have made tremendous progress in\nthe past years. However, those methods often heavily rely on heuristic\nhand-crafted feature extraction, which could hinder their generalization\nperformance. Additionally, existing methods are undermined for unsupervised and\nincremental learning tasks. Recently, the recent advancement of deep learning\nmakes it possible to perform automatic high-level feature extraction thus\nachieves promising performance in many areas. Since then, deep learning based\nmethods have been widely adopted for the sensor-based activity recognition\ntasks. This paper surveys the recent advance of deep learning based\nsensor-based activity recognition. We summarize existing literature from three\naspects: sensor modality, deep model, and application. We also present detailed\ninsights on existing work and propose grand challenges for future research.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Learning for Sensor-based Activity Recognition: A Survey",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chengxi Ye'}, {'name': 'Yezhou Yang'}, {'name': 'Cornelia Fermuller'}, {'name': 'Yiannis Aloimonos'}]",
//  "day": 2,
//  "id": "1708.00631v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.00631v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.00631v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We explain that the difficulties of training deep neural networks come from a\nsyndrome of three consistency issues. This paper describes our efforts in their\nanalysis and treatment. The first issue is the training speed inconsistency in\ndifferent layers. We propose to address it with an intuitive,\nsimple-to-implement, low footprint second-order method. The second issue is the\nscale inconsistency between the layer inputs and the layer residuals. We\nexplain how second-order information provides favorable convenience in removing\nthis roadblock. The third and most challenging issue is the inconsistency in\nresidual propagation. Based on the fundamental theorem of linear algebra, we\nprovide a mathematical characterization of the famous vanishing gradient\nproblem. Thus, an important design principle for future optimization and neural\nnetwork design is derived. We conclude this paper with the construction of a\nnovel contractive neural network.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "On the Importance of Consistency in Training Deep Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mario Amrehn'}, {'name': 'Sven Gaube'}, {'name': 'Mathias Unberath'}, {'name': 'Frank Schebesch'}, {'name': 'Tim Horz'}, {'name': 'Maddalena Strumia'}, {'name': 'Stefan Steidl'}, {'name': 'Markus Kowarschik'}, {'name': 'Andreas Maier'}]",
//  "day": 11,
//  "id": "1709.03450v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.2312/vcbm.20171248', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.03450v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.03450v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "For complex segmentation tasks, fully automatic systems are inherently\nlimited in their achievable accuracy for extracting relevant objects.\nEspecially in cases where only few data sets need to be processed for a highly\naccurate result, semi-automatic segmentation techniques exhibit a clear benefit\nfor the user. One area of application is medical image processing during an\nintervention for a single patient. We propose a learning-based cooperative\nsegmentation approach which includes the computing entity as well as the user\ninto the task. Our system builds upon a state-of-the-art fully convolutional\nartificial neural network (FCN) as well as an active user model for training.\nDuring the segmentation process, a user of the trained system can iteratively\nadd additional hints in form of pictorial scribbles as seed points into the FCN\nsystem to achieve an interactive and precise segmentation result. The\nsegmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\ncan yield superior results compared to networks without the user input channel\ncomponent, due to a consistent improvement in segmentation quality after each\ninteraction.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T05, 68T45', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.4.6; I.5.5', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image\n  Segmentation Based on a User Model",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Altaf H. Khan'}]",
//  "day": 15,
//  "id": "1712.05695v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.05695v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.05695v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Most of the weights in a Lightweight Neural Network have a value of zero,\nwhile the remaining ones are either +1 or -1. These universal approximators\nrequire approximately 1.1 bits/weight of storage, posses a quick forward pass\nand achieve classification accuracies similar to conventional continuous-weight\nnetworks. Their training regimen focuses on error reduction initially, but\nlater emphasizes discretization of weights. They ignore insignificant inputs,\nremove unnecessary weights, and drop unneeded hidden neurons. We have\nsuccessfully tested them on the MNIST, credit card fraud, and credit card\ndefaults data sets using networks having 2 to 16 hidden layers and up to 4.4\nmillion weights.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Lightweight Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Nathaniel Thomas'}, {'name': 'Tess Smidt'}, {'name': 'Steven Kearnes'}, {'name': 'Lusann Yang'}, {'name': 'Li Li'}, {'name': 'Kai Kohlhoff'}, {'name': 'Patrick Riley'}]",
//  "day": 22,
//  "id": "1802.08219v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.08219v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.08219v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We introduce tensor field networks, which are locally equivariant to 3D\nrotations, translations, and permutations of points at every layer. 3D rotation\nequivariance removes the need for data augmentation to identify features in\narbitrary orientations. Our network uses filters built from spherical\nharmonics; due to the mathematical consequences of this filter choice, each\nlayer accepts as input (and guarantees as output) scalars, vectors, and\nhigher-order tensors, in the geometric sense of these terms. We demonstrate how\ntensor field networks learn to model simple physics (Newtonian gravitation and\nmoment of inertia), classify simple 3D shapes (trained on one orientation and\ntested on shapes in arbitrary orientations), and, given a small organic\nmolecule with an atom removed, replace the correct element at the correct\nlocation in space.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Tensor Field Networks: Rotation- and Translation-Equivariant Neural\n  Networks for 3D Point Clouds",
//  "year": 2018
//},
//{
//  "author": "[{'name': '\u00c7a\u011flar G\u00fcl\u00e7ehre'}, {'name': 'Yoshua Bengio'}]",
//  "day": 17,
//  "id": "1301.4083v6",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1301.4083v6', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1301.4083v6', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Knowledge Matters: Importance of Prior Information for Optimization",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Kishore Konda'}, {'name': 'Roland Memisevic'}, {'name': 'David Krueger'}]",
//  "day": 13,
//  "id": "1402.3337v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1402.3337v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1402.3337v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Regularized training of an autoencoder typically results in hidden unit\nbiases that take on large negative values. We show that negative biases are a\nnatural result of using a hidden layer whose responsibility is to both\nrepresent the input data and act as a selection mechanism that ensures sparsity\nof the representation. We then show that negative biases impede the learning of\ndata distributions whose intrinsic dimensionality is high. We also propose a\nnew activation function that decouples the two roles of the hidden layer and\nthat allows us to learn representations on data with very high intrinsic\ndimensionality, where standard autoencoders typically fail. Since the decoupled\nactivation function acts like an implicit regularizer, the model can be trained\nby minimizing the reconstruction error of training data, without requiring any\nadditional regularization.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Zero-bias autoencoders and the benefits of co-adapting features",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Bodo Rueckauer'}, {'name': 'Iulia-Alexandra Lungu'}, {'name': 'Yuhuang Hu'}, {'name': 'Michael Pfeiffer'}]",
//  "day": 13,
//  "id": "1612.04052v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.04052v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.04052v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Deep convolutional neural networks (CNNs) have shown great potential for\nnumerous real-world machine learning applications, but performing inference in\nlarge CNNs in real-time remains a challenge. We have previously demonstrated\nthat traditional CNNs can be converted into deep spiking neural networks\n(SNNs), which exhibit similar accuracy while reducing both latency and\ncomputational load as a consequence of their data-driven, event-based style of\ncomputing. Here we provide a novel theory that explains why this conversion is\nsuccessful, and derive from it several new tools to convert a larger and more\npowerful class of deep networks into SNNs. We identify the main sources of\napproximation errors in previous conversion methods, and propose simple\nmechanisms to fix these issues. Furthermore, we develop spiking implementations\nof common CNN operations such as max-pooling, softmax, and batch-normalization,\nwhich allow almost loss-less conversion of arbitrary CNN architectures into the\nspiking domain. Empirical evaluation of different network architectures on the\nMNIST and CIFAR10 benchmarks leads to the best SNN results reported to date.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Theory and Tools for the Conversion of Analog to Spiking Convolutional\n  Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Xun Huang'}, {'name': 'Yixuan Li'}, {'name': 'Omid Poursaeed'}, {'name': 'John Hopcroft'}, {'name': 'Serge Belongie'}]",
//  "day": 13,
//  "id": "1612.04357v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.04357v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.04357v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "In this paper, we propose a novel generative model named Stacked Generative\nAdversarial Networks (SGAN), which is trained to invert the hierarchical\nrepresentations of a bottom-up discriminative network. Our model consists of a\ntop-down stack of GANs, each learned to generate lower-level representations\nconditioned on higher-level representations. A representation discriminator is\nintroduced at each feature hierarchy to encourage the representation manifold\nof the generator to align with that of the bottom-up discriminative network,\nleveraging the powerful discriminative representations to guide the generative\nmodel. In addition, we introduce a conditional loss that encourages the use of\nconditional information from the layer above, and a novel entropy loss that\nmaximizes a variational lower bound on the conditional entropy of generator\noutputs. We first train each stack independently, and then train the whole\nmodel end-to-end. Unlike the original GAN that uses a single noise vector to\nrepresent all the variations, our SGAN decomposes variations into multiple\nlevels and gradually resolves uncertainties in the top-down generative process.\nBased on visual inspection, Inception scores and visual Turing test, we\ndemonstrate that SGAN is able to generate images of much higher quality than\nGANs without stacking.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Stacked Generative Adversarial Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'David Warde-Farley'}, {'name': 'Andrew Rabinovich'}, {'name': 'Dragomir Anguelov'}]",
//  "day": 20,
//  "id": "1412.6563v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.6563v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.6563v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We study the problem of large scale, multi-label visual recognition with a\nlarge number of possible classes. We propose a method for augmenting a trained\nneural network classifier with auxiliary capacity in a manner designed to\nsignificantly improve upon an already well-performing model, while minimally\nimpacting its computational footprint. Using the predictions of the network\nitself as a descriptor for assessing visual similarity, we define a\npartitioning of the label space into groups of visually similar entities. We\nthen augment the network with auxilliary hidden layer pathways with\nconnectivity only to these groups of label units. We report a significant\nimprovement in mean average precision on a large-scale object recognition task\nwith the augmented model, while increasing the number of multiply-adds by less\nthan 3%.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Self-informed neural network structure learning",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Forest Agostinelli'}, {'name': 'Matthew Hoffman'}, {'name': 'Peter Sadowski'}, {'name': 'Pierre Baldi'}]",
//  "day": 21,
//  "id": "1412.6830v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.6830v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.6830v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Artificial neural networks typically have a fixed, non-linear activation\nfunction at each neuron. We have designed a novel form of piecewise linear\nactivation function that is learned independently for each neuron using\ngradient descent. With this adaptive activation function, we are able to\nimprove upon deep neural network architectures composed of static rectified\nlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),\nCIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgs\nboson decay modes.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Activation Functions to Improve Deep Neural Networks",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Antti Rasmus'}, {'name': 'Tapani Raiko'}, {'name': 'Harri Valpola'}]",
//  "day": 22,
//  "id": "1412.7210v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.7210v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.7210v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Suitable lateral connections between encoder and decoder are shown to allow\nhigher layers of a denoising autoencoder (dAE) to focus on invariant\nrepresentations. In regular autoencoders, detailed information needs to be\ncarried through the highest layers but lateral connections from encoder to\ndecoder relieve this pressure. It is shown that abstract invariant features can\nbe translated to detailed reconstructions when invariant features are allowed\nto modulate the strength of the lateral connection. Three dAE structures with\nmodulated and additive lateral connections, and without lateral connections\nwere compared in experiments using real-world images. The experiments verify\nthat adding modulated lateral connections to the model 1) improves the accuracy\nof the probability model for inputs, as measured by denoising performance; 2)\nresults in representations whose degree of invariance grows faster towards the\nhigher layers; and 3) supports the formation of diverse invariant poolings.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Denoising autoencoder with modulated lateral connections learns\n  invariant representations of natural images",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Ankit B. Patel'}, {'name': 'Tan Nguyen'}, {'name': 'Richard G. Baraniuk'}]",
//  "day": 2,
//  "id": "1504.00641v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1504.00641v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1504.00641v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "A grand challenge in machine learning is the development of computational\nalgorithms that match or outperform humans in perceptual inference tasks that\nare complicated by nuisance variation. For instance, visual object recognition\ninvolves the unknown object position, orientation, and scale in object\nrecognition while speech recognition involves the unknown voice pronunciation,\npitch, and speed. Recently, a new breed of deep learning algorithms have\nemerged for high-nuisance inference tasks that routinely yield pattern\nrecognition systems with near- or super-human capabilities. But a fundamental\nquestion remains: Why do they work? Intuitions abound, but a coherent framework\nfor understanding, analyzing, and synthesizing deep learning architectures has\nremained elusive. We answer this question by developing a new probabilistic\nframework for deep learning based on the Deep Rendering Model: a generative\nprobabilistic model that explicitly captures latent nuisance variation. By\nrelaxing the generative model to a discriminative one, we can recover two of\nthe current leading deep learning systems, deep convolutional neural networks\nand random decision forests, providing insights into their successes and\nshortcomings, as well as a principled route to their improvement.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Probabilistic Theory of Deep Learning",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Rein Houthooft'}, {'name': 'Filip De Turck'}]",
//  "day": 3,
//  "id": "1508.00451v4",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1016/j.patcog.2016.03.014', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.00451v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.00451v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Tackling pattern recognition problems in areas such as computer vision,\nbioinformatics, speech or text recognition is often done best by taking into\naccount task-specific statistical relations between output variables. In\nstructured prediction, this internal structure is used to predict multiple\noutputs simultaneously, leading to more accurate and coherent predictions.\nStructural support vector machines (SSVMs) are nonprobabilistic models that\noptimize a joint input-output function through margin-based learning. Because\nSSVMs generally disregard the interplay between unary and interaction factors\nduring the training phase, final parameters are suboptimal. Moreover, its\nfactors are often restricted to linear combinations of input features, limiting\nits generalization power. To improve prediction accuracy, this paper proposes:\n(i) Joint inference and learning by integration of back-propagation and\nloss-augmented inference in SSVM subgradient descent; (ii) Extending SSVM\nfactors to neural networks that form highly nonlinear functions of input\nfeatures. Image segmentation benchmark results demonstrate improvements over\nconventional SSVM training methods in terms of accuracy, highlighting the\nfeasibility of end-to-end SSVM training with neural factors.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Integrated Inference and Learning of Neural Factors in Structural\n  Support Vector Machines",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Patrick W. Gallagher'}, {'name': 'Shuai Tang'}, {'name': 'Zhuowen Tu'}]",
//  "day": 23,
//  "id": "1511.07125v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.07125v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.07125v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\".",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Adrien Gaidon'}, {'name': 'Qiao Wang'}, {'name': 'Yohann Cabon'}, {'name': 'Eleonora Vig'}]",
//  "day": 20,
//  "id": "1605.06457v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1605.06457v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1605.06457v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Modern computer vision algorithms typically require expensive data\nacquisition and accurate manual labeling. In this work, we instead leverage the\nrecent progress in computer graphics to generate fully labeled, dynamic, and\nphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtual\nworld cloning method, and validate our approach by building and publicly\nreleasing a new video dataset, called Virtual KITTI (see\nhttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),\nautomatically labeled with accurate ground truth for object detection,\ntracking, scene and instance segmentation, depth, and optical flow. We provide\nquantitative experimental evidence suggesting that (i) modern deep learning\nalgorithms pre-trained on real data behave similarly in real and virtual\nworlds, and (ii) pre-training on virtual data improves performance. As the gap\nbetween real and virtual worlds is small, virtual worlds enable measuring the\nimpact of various weather and imaging conditions on recognition performance,\nall other things being equal. We show these factors may affect drastically\notherwise high-performing deep models for tracking.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Virtual Worlds as Proxy for Multi-Object Tracking Analysis",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jianwen Xie'}, {'name': 'Song-Chun Zhu'}, {'name': 'Ying Nian Wu'}]",
//  "day": 3,
//  "id": "1606.00972v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.00972v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.00972v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Video sequences contain rich dynamic patterns, such as dynamic texture\npatterns that exhibit stationarity in the temporal domain, and action patterns\nthat are non-stationary in either spatial or temporal domain. We show that a\nspatial-temporal generative ConvNet can be used to model and synthesize dynamic\npatterns. The model defines a probability distribution on the video sequence,\nand the log probability is defined by a spatial-temporal ConvNet that consists\nof multiple layers of spatial-temporal filters to capture spatial-temporal\npatterns of different scales. The model can be learned from the training video\nsequences by an \"analysis by synthesis\" learning algorithm that iterates the\nfollowing two steps. Step 1 synthesizes video sequences from the currently\nlearned model. Step 2 then updates the model parameters based on the difference\nbetween the synthesized video sequences and the observed training sequences. We\nshow that the learning algorithm can synthesize realistic dynamic patterns.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mohammad Javad Shafiee'}, {'name': 'Akshaya Mishra'}, {'name': 'Alexander Wong'}]",
//  "day": 14,
//  "id": "1606.04393v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.04393v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.04393v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Taking inspiration from biological evolution, we explore the idea of \"Can\ndeep neural networks evolve naturally over successive generations into highly\nefficient deep neural networks?\" by introducing the notion of synthesizing new\nhighly efficient, yet powerful deep neural networks over successive generations\nvia an evolutionary process from ancestor deep neural networks. The\narchitectural traits of ancestor deep neural networks are encoded using\nsynaptic probability models, which can be viewed as the `DNA' of these\nnetworks. New descendant networks with differing network architectures are\nsynthesized based on these synaptic probability models from the ancestor\nnetworks and computational environmental factor models, in a random manner to\nmimic heredity, natural selection, and random mutation. These offspring\nnetworks are then trained into fully functional networks, like one would train\na newborn, and have more efficient, more diverse network architectures than\ntheir ancestor networks, while achieving powerful modeling capabilities.\nExperimental results for the task of visual saliency demonstrated that the\nsynthesized `evolved' offspring networks can achieve state-of-the-art\nperformance while having network architectures that are significantly more\nefficient (with a staggering $\\sim$48-fold decrease in synapses by the fourth\ngeneration) compared to the original ancestor network.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural\n  Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tian Han'}, {'name': 'Yang Lu'}, {'name': 'Song-Chun Zhu'}, {'name': 'Ying Nian Wu'}]",
//  "day": 28,
//  "id": "1606.08571v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.08571v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.08571v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "This paper proposes an alternating back-propagation algorithm for learning\nthe generator network model. The model is a non-linear generalization of factor\nanalysis. In this model, the mapping from the continuous latent factors to the\nobserved signal is parametrized by a convolutional neural network. The\nalternating back-propagation algorithm iterates the following two steps: (1)\nInferential back-propagation, which infers the latent factors by Langevin\ndynamics or gradient descent. (2) Learning back-propagation, which updates the\nparameters given the inferred latent factors by gradient descent. The gradient\ncomputations in both steps are powered by back-propagation, and they share most\nof their code in common. We show that the alternating back-propagation\nalgorithm can learn realistic generator models of natural images, video\nsequences, and sounds. Moreover, it can also be used to learn from incomplete\nor indirect training data.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Alternating Back-Propagation for Generator Network",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Ilija Ilievski'}, {'name': 'Jiashi Feng'}]",
//  "day": 31,
//  "id": "1608.00218v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.00218v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.00218v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Recently, several optimization methods have been successfully applied to the\nhyperparameter optimization of deep neural networks (DNNs). The methods work by\nmodeling the joint distribution of hyperparameter values and corresponding\nerror. Those methods become less practical when applied to modern DNNs whose\ntraining may take a few days and thus one cannot collect sufficient\nobservations to accurately model the distribution. To address this challenging\nissue, we propose a method that learns to transfer optimal hyperparameter\nvalues for a small source dataset to hyperparameter values with comparable\nperformance on a dataset of interest. As opposed to existing transfer learning\nmethods, our proposed method does not use hand-designed features. Instead, it\nuses surrogates to model the hyperparameter-error distributions of the two\ndatasets and trains a neural network to learn the transfer function. Extensive\nexperiments on three CV benchmark datasets clearly demonstrate the efficiency\nof our method.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hyperparameter Transfer Learning through Surrogate Alignment for\n  Efficient Deep Neural Network Training",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Hao Wang'}, {'name': 'Dit-Yan Yeung'}]",
//  "day": 24,
//  "id": "1608.06884v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.06884v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.06884v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "While perception tasks such as visual object recognition and text\nunderstanding play an important role in human intelligence, the subsequent\ntasks that involve inference, reasoning and planning require an even higher\nlevel of intelligence. The past few years have seen major advances in many\nperception tasks using deep learning models. For higher-level inference,\nhowever, probabilistic graphical models with their Bayesian nature are still\nmore powerful and flexible. To achieve integrated intelligence that involves\nboth perception and inference, it is naturally desirable to tightly integrate\ndeep learning and Bayesian models within a principled probabilistic framework,\nwhich we call Bayesian deep learning. In this unified framework, the perception\nof text or images using deep learning can boost the performance of higher-level\ninference and in return, the feedback from the inference process is able to\nenhance the perception of text or images. This paper proposes a general\nframework for Bayesian deep learning and reviews its recent applications on\nrecommender systems, topic models, and control. In this paper, we also discuss\nthe relationship and differences between Bayesian deep learning and other\nrelated topics like Bayesian treatment of neural networks.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards Bayesian Deep Learning: A Framework and Some Existing Methods",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mason McGill'}, {'name': 'Pietro Perona'}]",
//  "day": 17,
//  "id": "1703.06217v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.06217v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.06217v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We propose and systematically evaluate three strategies for training\ndynamically-routed artificial neural networks: graphs of learned\ntransformations through which different input signals may take different paths.\nThough some approaches have advantages over others, the resulting networks are\noften qualitatively similar. We find that, in dynamically-routed networks\ntrained to classify images, layers and branches become specialized to process\ndistinct categories of images. Additionally, given a fixed computational\nbudget, dynamically-routed networks tend to perform better than comparable\nstatically-routed networks.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deciding How to Decide: Dynamic Routing in Artificial Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Hongyang Gao'}, {'name': 'Hao Yuan'}, {'name': 'Zhengyang Wang'}, {'name': 'Shuiwang Ji'}]",
//  "day": 18,
//  "id": "1705.06820v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.06820v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.06820v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Deconvolutional layers have been widely used in a variety of deep models for\nup-sampling, including encoder-decoder networks for semantic segmentation and\ndeep generative models for unsupervised learning. One of the key limitations of\ndeconvolutional operations is that they result in the so-called checkerboard\nproblem. This is caused by the fact that no direct relationship exists among\nadjacent pixels on the output feature map. To address this problem, we propose\nthe pixel deconvolutional layer (PixelDCL) to establish direct relationships\namong adjacent pixels on the up-sampled feature map. Our method is based on a\nfresh interpretation of the regular deconvolution operation. The resulting\nPixelDCL can be used to replace any deconvolutional layer in a plug-and-play\nmanner without compromising the fully trainable capabilities of original\nmodels. The proposed PixelDCL may result in slight decrease in efficiency, but\nthis can be overcome by an implementation trick. Experimental results on\nsemantic segmentation demonstrate that PixelDCL can consider spatial features\nsuch as edges and shapes and yields more accurate segmentation outputs than\ndeconvolutional layers. When used in image generation tasks, our PixelDCL can\nlargely overcome the checkerboard problem suffered by regular deconvolution\noperations.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Pixel Deconvolutional Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Stanislav Fort'}]",
//  "day": 9,
//  "id": "1708.02735v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.02735v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.02735v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We propose a novel architecture for $k$-shot classification on the Omniglot\ndataset. Building on prototypical networks, we extend their architecture to\nwhat we call Gaussian prototypical networks. Prototypical networks learn a map\nbetween images and embedding vectors, and use their clustering for\nclassification. In our model, a part of the encoder output is interpreted as a\nconfidence region estimate about the embedding point, and expressed as a\nGaussian covariance matrix. Our network then constructs a direction and class\ndependent distance metric on the embedding space, using uncertainties of\nindividual data points as weights. We show that Gaussian prototypical networks\nare a preferred architecture over vanilla prototypical networks with an\nequivalent number of parameters. We report state-of-the-art performance in\n1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot\n5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.\nWe explore artificially down-sampling a fraction of images in the training set,\nwhich improves our performance even further. We therefore hypothesize that\nGaussian prototypical networks might perform better in less homogeneous,\nnoisier datasets, which are commonplace in real world applications.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Leslie N. Smith'}, {'name': 'Nicholay Topin'}]",
//  "day": 23,
//  "id": "1708.07120v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.07120v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.07120v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "In this paper, we show a phenomenon, which we named \"super-convergence\",\nwhere residual networks can be trained using an order of magnitude fewer\niterations than is used with standard training methods. The existence of\nsuper-convergence is relevant to understanding why deep networks generalize\nwell. One of the key elements of super-convergence is training with cyclical\nlearning rates and a large maximum learning rate. Furthermore, we present\nevidence that training with large learning rates improves performance by\nregularizing the network. In addition, we show that super-convergence provides\na greater boost in performance relative to standard training when the amount of\nlabeled training data is limited. We also derive a simplification of the\nHessian Free optimization method to compute an estimate of the optimal learning\nrate. The architectures and code to replicate the figures in this paper are\navailable at github.com/lnsmith54/super-convergence.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Super-Convergence: Very Fast Training of Residual Networks Using Large\n  Learning Rates",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Boris Flach'}, {'name': 'Alexander Shekhovtsov'}, {'name': 'Ondrej Fikar'}]",
//  "day": 25,
//  "id": "1709.08524v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.08524v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.08524v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Learning, taking into account full distribution of the data, referred to as\ngenerative, is not feasible with deep neural networks (DNNs) because they model\nonly the conditional distribution of the outputs given the inputs. Current\nsolutions are either based on joint probability models facing difficult\nestimation problems or learn two separate networks, mapping inputs to outputs\n(recognition) and vice-versa (generation). We propose an intermediate approach.\nFirst, we show that forward computation in DNNs with logistic sigmoid\nactivations corresponds to a simplified approximate Bayesian inference in a\ndirected probabilistic multi-layer model. This connection allows to interpret\nDNN as a probabilistic model of the output and all hidden units given the\ninput. Second, we propose that in order for the recognition and generation\nnetworks to be more consistent with the joint model of the data, weights of the\nrecognition and generator network should be related by transposition. We\ndemonstrate in a tentative experiment that such a coupled pair can be learned\ngeneratively, modelling the full distribution of the data, and has enough\ncapacity to perform well in both recognition and generation.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generative learning for deep networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Hanxiao Liu'}, {'name': 'Karen Simonyan'}, {'name': 'Oriol Vinyals'}, {'name': 'Chrisantha Fernando'}, {'name': 'Koray Kavukcuoglu'}]",
//  "day": 1,
//  "id": "1711.00436v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.00436v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.00436v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We explore efficient neural architecture search methods and show that a\nsimple yet powerful evolutionary algorithm can discover new architectures with\nexcellent performance. Our approach combines a novel hierarchical genetic\nrepresentation scheme that imitates the modularized design pattern commonly\nadopted by human experts, and an expressive search space that supports complex\ntopologies. Our algorithm efficiently discovers architectures that outperform a\nlarge number of manually designed models for image classification, obtaining\ntop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which\nis competitive with the best existing neural architecture search approaches. We\nalso present results using random search, achieving 0.3% less top-1 accuracy on\nCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36\nhours down to 1 hour.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hierarchical Representations for Efficient Architecture Search",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Antreas Antoniou'}, {'name': 'Amos Storkey'}, {'name': 'Harrison Edwards'}]",
//  "day": 12,
//  "id": "1711.04340v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.04340v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.04340v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Effective training of neural networks requires much data. In the low-data\nregime, parameters are underdetermined, and learnt networks generalise poorly.\nData Augmentation alleviates this by using existing data more effectively.\nHowever standard data augmentation produces only limited plausible alternative\ndata. Given there is potential to generate a much broader set of augmentations,\nwe design and train a generative model to do data augmentation. The model,\nbased on image conditional Generative Adversarial Networks, takes data from a\nsource domain and learns to take any data item and generalise it to generate\nother within-class data items. As this generative process does not depend on\nthe classes themselves, it can be applied to novel unseen classes of data. We\nshow that a Data Augmentation Generative Adversarial Network (DAGAN) augments\nstandard vanilla classifiers well. We also show a DAGAN can enhance few-shot\nlearning systems such as Matching Networks. We demonstrate these approaches on\nOmniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In\nour experiments we can see over 13% increase in accuracy in the low-data regime\nexperiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face\n(4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5%\n(from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Data Augmentation Generative Adversarial Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Dror Sholomon'}, {'name': 'Eli David'}, {'name': 'Nathan S. Netanyahu'}]",
//  "day": 23,
//  "id": "1711.08762v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1007/978-3-319-44781-0_21', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.08762v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.08762v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "This paper introduces the first deep neural network-based estimation metric\nfor the jigsaw puzzle problem. Given two puzzle piece edges, the neural network\npredicts whether or not they should be adjacent in the correct assembly of the\npuzzle, using nothing but the pixels of each piece. The proposed metric\nexhibits an extremely high precision even though no manual feature extraction\nis performed. When incorporated into an existing puzzle solver, the solution's\naccuracy increases significantly, achieving thereby a new state-of-the-art\nstandard.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "DNN-Buddies: A Deep Neural Network-Based Estimation Metric for the\n  Jigsaw Puzzle Problem",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Eli David'}, {'name': 'Nathan S. Netanyahu'}]",
//  "day": 23,
//  "id": "1711.08763v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1007/978-3-319-44781-0_3', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.08763v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.08763v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "In this paper we describe the problem of painter classification, and propose\na novel approach based on deep convolutional autoencoder neural networks. While\nprevious approaches relied on image processing and manual feature extraction\nfrom paintings, our approach operates on the raw pixel level, without any\npreprocessing or manual feature extraction. We first train a deep convolutional\nautoencoder on a dataset of paintings, and subsequently use it to initialize a\nsupervised convolutional neural network for the classification phase.\n  The proposed approach substantially outperforms previous methods, improving\nthe previous state-of-the-art for the 3-painter classification problem from\n90.44% accuracy (previous state-of-the-art) to 96.52% accuracy, i.e., a 63%\nreduction in error rate.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "DeepPainter: Painter Classification Using Deep Convolutional\n  Autoencoders",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ido Cohen'}, {'name': 'Eli David'}, {'name': 'Nathan S. Netanyahu'}, {'name': 'Noa Liscovitch'}, {'name': 'Gal Chechik'}]",
//  "day": 27,
//  "id": "1711.09663v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1007/978-3-319-68612-7_33', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.09663v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.09663v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "This paper presents a novel deep learning-based method for learning a\nfunctional representation of mammalian neural images. The method uses a deep\nconvolutional denoising autoencoder (CDAE) for generating an invariant, compact\nrepresentation of in situ hybridization (ISH) images. While most existing\nmethods for bio-imaging analysis were not developed to handle images with\nhighly complex anatomical structures, the results presented in this paper show\nthat functional representation extracted by CDAE can help learn features of\nfunctional gene ontology categories for their classification in a highly\naccurate manner. Using this CDAE representation, our method outperforms the\nprevious state-of-the-art classification rate, by improving the average AUC\nfrom 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operates\non input images that were downsampled significantly with respect to the\noriginal ones to make it computationally feasible.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "DeepBrain: Functional Representation of Neural In-Situ Hybridization\n  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Omid Poursaeed'}, {'name': 'Isay Katsman'}, {'name': 'Bicheng Gao'}, {'name': 'Serge Belongie'}]",
//  "day": 6,
//  "id": "1712.02328v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.02328v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.02328v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "In this paper, we propose novel generative models for creating adversarial\nexamples, slightly perturbed images resembling natural images but maliciously\ncrafted to fool pre-trained models. We present trainable deep neural networks\nfor transforming images to adversarial perturbations. Our proposed models can\nproduce image-agnostic and image-dependent perturbations for both targeted and\nnon-targeted attacks. We also demonstrate that similar architectures can\nachieve impressive results in fooling classification and semantic segmentation\nmodels, obviating the need for hand-crafting attack methods for each task.\nUsing extensive experiments on challenging high-resolution datasets such as\nImageNet and Cityscapes, we show that our perturbations achieve high fooling\nrates with small perturbation norms. Moreover, our attacks are considerably\nfaster than current iterative methods at inference time.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generative Adversarial Perturbations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Logan Engstrom'}, {'name': 'Brandon Tran'}, {'name': 'Dimitris Tsipras'}, {'name': 'Ludwig Schmidt'}, {'name': 'Aleksander Madry'}]",
//  "day": 7,
//  "id": "1712.02779v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.02779v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.02779v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We show that simple transformations, namely translations and rotations alone,\nare sufficient to fool neural network-based vision models on a significant\nfraction of inputs. This is in sharp contrast to previous work that relied on\nmore complicated optimization approaches that are unlikely to appear outside of\na truly adversarial setting. Moreover, fooling rotations and translations are\neasy to find and require only a few black-box queries to the target model.\nOverall, our findings emphasize the need for designing robust classifiers even\nin natural, benign contexts.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Rotation and a Translation Suffice: Fooling CNNs with Simple\n  Transformations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Boyang Deng'}, {'name': 'Junjie Yan'}, {'name': 'Dahua Lin'}]",
//  "day": 9,
//  "id": "1712.03351v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.03351v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.03351v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "The quest for performant networks has been a significant force that drives\nthe advancements of deep learning in recent years. While rewarding, improving\nnetwork design has never been an easy journey. The large design space combined\nwith the tremendous cost required for network training poses a major obstacle\nto this endeavor. In this work, we propose a new approach to this problem,\nnamely, predicting the performance of a network before training, based on its\narchitecture. Specifically, we develop a unified way to encode individual\nlayers into vectors and bring them together to form an integrated description\nvia LSTM. Taking advantage of the recurrent network's strong expressive power,\nthis method can reliably predict the performances of various network\narchitectures. Our empirical studies showed that it not only achieved accurate\npredictions but also produced consistent rankings across datasets -- a key\ndesideratum in performance prediction.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Peephole: Predicting Network Performance Before Training",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Abien Fred Agarap'}]",
//  "day": 10,
//  "id": "1712.03541v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.03541v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.03541v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Convolutional neural networks (CNNs) are similar to \"ordinary\" neural\nnetworks in the sense that they are made up of hidden layers consisting of\nneurons with \"learnable\" parameters. These neurons receive inputs, performs a\ndot product, and then follows it with a non-linearity. The whole network\nexpresses the mapping between raw image pixels and their class scores.\nConventionally, the Softmax function is the classifier used at the last layer\nof this network. However, there have been studies (Alalshekmubarak and Smith,\n2013; Agarap, 2017; Tang, 2013) conducted to challenge this norm. The cited\nstudies introduce the usage of linear support vector machine (SVM) in an\nartificial neural network architecture. This project is yet another take on the\nsubject, and is inspired by (Tang, 2013). Empirical data has shown that the\nCNN-SVM model was able to achieve a test accuracy of ~99.04% using the MNIST\ndataset (LeCun, Cortes, and Burges, 2010). On the other hand, the CNN-Softmax\nwas able to achieve a test accuracy of ~99.23% using the same dataset. Both\nmodels were also tested on the recently-published Fashion-MNIST dataset (Xiao,\nRasul, and Vollgraf, 2017), which is suppose to be a more difficult image\nclassification dataset than MNIST (Zalandoresearch, 2017). This proved to be\nthe case as CNN-SVM reached a test accuracy of ~90.72%, while the CNN-Softmax\nreached a test accuracy of ~91.86%. The said results may be improved if data\npreprocessing techniques were employed on the datasets, and if the base CNN\nmodel was a relatively more sophisticated than the one used in this study.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "An Architecture Combining Convolutional Neural Network (CNN) and Support\n  Vector Machine (SVM) for Image Classification",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ekaba Bisong'}]",
//  "day": 22,
//  "id": "1712.08314v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.08314v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.08314v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Artifical Neural Networks are a particular class of learning systems modeled\nafter biological neural functions with an interesting penchant for Hebbian\nlearning, that is \"neurons that wire together, fire together\". However, unlike\ntheir natural counterparts, artificial neural networks have a close and\nstringent coupling between the modules of neurons in the network. This coupling\nor locking imposes upon the network a strict and inflexible structure that\nprevent layers in the network from updating their weights until a full\nfeed-forward and backward pass has occurred. Such a constraint though may have\nsufficed for a while, is now no longer feasible in the era of very-large-scale\nmachine learning, coupled with the increased desire for parallelization of the\nlearning process across multiple computing infrastructures. To solve this\nproblem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are\nintroduced as a viable alternative to the backpropagation algorithm. This paper\nperforms a speed benchmark to compare the speed and accuracy capabilities of\nSG-DNI as opposed to a standard neural interface using multilayer perceptron\nMLP. SG-DNI shows good promise, in that it not only captures the learning\nproblem, it is also over 3-fold faster due to it asynchronous learning\ncapabilities.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Benchmarking Decoupled Neural Interfaces with Synthetic Gradients",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Amin Fehri'}, {'name': 'Santiago Velasco-Forero'}, {'name': 'Fernand Meyer'}]",
//  "day": 20,
//  "id": "1802.07008v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.07008v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.07008v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Image segmentation is the process of partitioning an image into a set of\nmeaningful regions according to some criteria. Hierarchical segmentation has\nemerged as a major trend in this regard as it favors the emergence of important\nregions at different scales. On the other hand, many methods allow us to have\nprior information on the position of structures of interest in the images. In\nthis paper, we present a versatile hierarchical segmentation method that takes\ninto account any prior spatial information and outputs a hierarchical\nsegmentation that emphasizes the contours or regions of interest while\npreserving the important structures in the image. An application of this method\nto the weakly-supervised segmentation problem is presented.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Segmentation hi\u00e9rarchique faiblement supervis\u00e9e",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Mark D. McDonnell'}]",
//  "day": 23,
//  "id": "1802.08530v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.08530v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.08530v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "For fast and energy-efficient deployment of trained deep neural networks on\nresource-constrained embedded hardware, each learned weight parameter should\nideally be represented and stored using a single bit. Error-rates usually\nincrease when this requirement is imposed. Here, we report large improvements\nin error rates on multiple datasets, for deep convolutional neural networks\ndeployed with 1-bit-per-weight. Using wide residual networks as our main\nbaseline, our approach simplifies existing methods that binarize weights by\napplying the sign function in training; we apply scaling factors for each layer\nwith constant unlearned values equal to the layer-specific standard deviations\nused for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with\n1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve\nerror rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We\nalso considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test\nresults of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error\nrates halve previously reported values, and are within about 1% of our\nerror-rates for the same network with full-precision weights. For networks that\noverfit, we also show significant improvements in error rate by not learning\nbatch normalization scale and offset parameters. This applies to both full\nprecision and 1-bit-per-weight networks. Using a warm-restart learning-rate\nschedule, we found that training for 1-bit-per-weight is just as fast as\nfull-precision networks, with better accuracy than standard schedules, and\nachieved about 98%-99% of peak performance in just 62 training epochs for\nCIFAR-10/100. For full training code and trained models in MATLAB, Keras and\nPyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Training wide residual networks for deployment using a single bit for\n  each weight",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Abien Fred Agarap'}]",
//  "day": 22,
//  "id": "1803.08375v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1803.08375v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1803.08375v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Learning using Rectified Linear Units (ReLU)",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Djork-Arn\u00e9 Clevert'}, {'name': 'Andreas Mayr'}, {'name': 'Thomas Unterthiner'}, {'name': 'Sepp Hochreiter'}]",
//  "day": 23,
//  "id": "1502.06464v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1502.06464v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1502.06464v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We propose rectified factor networks (RFNs) to efficiently construct very\nsparse, non-linear, high-dimensional representations of the input. RFN models\nidentify rare and small events in the input, have a low interference between\ncode units, have a small reconstruction error, and explain the data covariance\nstructure. RFN learning is a generalized alternating minimization algorithm\nderived from the posterior regularization method which enforces non-negative\nand normalized posterior means. We proof convergence and correctness of the RFN\nlearning algorithm. On benchmarks, RFNs are compared to other unsupervised\nmethods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to\nprevious sparse coding methods, RFNs yield sparser codes, capture the data's\ncovariance structure more precisely, and have a significantly smaller\nreconstruction error. We test RFNs as pretraining technique for deep networks\non different vision datasets, where RFNs were superior to RBMs and\nautoencoders. On gene expression data from two pharmaceutical drug discovery\nstudies, RFNs detected small and rare gene modules that revealed highly\nrelevant new biological insights which were so far missed by other unsupervised\nmethods.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Rectified Factor Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Qi Wang'}, {'name': 'Joseph JaJa'}]",
//  "day": 18,
//  "id": "1312.1909v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1312.1909v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1312.1909v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Motivated by an important insight from neural science, we propose a new\nframework for understanding the success of the recently proposed \"maxout\"\nnetworks. The framework is based on encoding information on sparse pathways and\nrecognizing the correct pathway at inference time. Elaborating further on this\ninsight, we propose a novel deep network architecture, called \"channel-out\"\nnetwork, which takes a much better advantage of sparse pathway encoding. In\nchannel-out networks, pathways are not only formed a posteriori, but they are\nalso actively selected according to the inference outputs from the lower\nlayers. From a mathematical perspective, channel-out networks can represent a\nwider class of piece-wise continuous functions, thereby endowing the network\nwith more expressive power than that of maxout networks. We test our\nchannel-out networks on several well-known image classification benchmarks,\nsetting new state-of-the-art performance on CIFAR-100 and STL-10, which\nrepresent some of the \"harder\" image classification benchmarks.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "From Maxout to Channel-Out: Encoding Information on Sparse Pathways",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Takashi Shinozaki'}, {'name': 'Yasushi Naruse'}]",
//  "day": 20,
//  "id": "1312.5845v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1312.5845v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1312.5845v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We propose a novel learning method for multilayered neural networks which\nuses feedforward supervisory signal and associates classification of a new\ninput with that of pre-trained input. The proposed method effectively uses rich\ninput information in the earlier layer for robust leaning and revising internal\nrepresentation in a multilayer neural network.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Competitive Learning with Feedforward Supervisory Signal for Pre-trained\n  Multilayered Networks",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Chen-Yu Lee'}, {'name': 'Saining Xie'}, {'name': 'Patrick Gallagher'}, {'name': 'Zhengyou Zhang'}, {'name': 'Zhuowen Tu'}]",
//  "day": 18,
//  "id": "1409.5185v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.5185v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.5185v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Our proposed deeply-supervised nets (DSN) method simultaneously minimizes\nclassification error while making the learning process of hidden layers direct\nand transparent. We make an attempt to boost the classification performance by\nstudying a new formulation in deep networks. Three aspects in convolutional\nneural networks (CNN) style architectures are being looked at: (1) transparency\nof the intermediate layers to the overall classification; (2)\ndiscriminativeness and robustness of learned features, especially in the early\nlayers; (3) effectiveness in training due to the presence of the exploding and\nvanishing gradients. We introduce \"companion objective\" to the individual\nhidden layers, in addition to the overall objective at the output layer (a\ndifferent strategy to layer-wise pre-training). We extend techniques from\nstochastic gradient methods to analyze our algorithm. The advantage of our\nmethod is evident and our experimental result on benchmark datasets shows\nsignificant performance gain over existing methods (e.g. all state-of-the-art\nresults on MNIST, CIFAR-10, CIFAR-100, and SVHN).",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deeply-Supervised Nets",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Behnam Neyshabur'}, {'name': 'Ruslan Salakhutdinov'}, {'name': 'Nathan Srebro'}]",
//  "day": 8,
//  "id": "1506.02617v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.02617v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.02617v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We revisit the choice of SGD for training deep neural networks by\nreconsidering the appropriate geometry in which to optimize the weights. We\nargue for a geometry invariant to rescaling of weights that does not affect the\noutput of the network, and suggest Path-SGD, which is an approximate steepest\ndescent method with respect to a path-wise regularizer related to max-norm\nregularization. Path-SGD is easy and efficient to implement and leads to\nempirical gains over SGD and AdaGrad.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Path-SGD: Path-Normalized Optimization in Deep Neural Networks",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Alan Mosca'}, {'name': 'George D. Magoulas'}]",
//  "day": 15,
//  "id": "1509.04612v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1509.04612v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1509.04612v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "The Resilient Propagation (Rprop) algorithm has been very popular for\nbackpropagation training of multilayer feed-forward neural networks in various\napplications. The standard Rprop however encounters difficulties in the context\nof deep neural networks as typically happens with gradient-based learning\nalgorithms. In this paper, we propose a modification of the Rprop that combines\nstandard Rprop steps with a special drop out technique. We apply the method for\ntraining Deep Neural Networks as standalone components and in ensemble\nformulations. Results on the MNIST dataset show that the proposed modification\nalleviates standard Rprop's problems demonstrating improved learning speed and\naccuracy.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Adapting Resilient Propagation for Deep Learning",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Nastaran Mohammadian Rad'}, {'name': 'Andrea Bizzego'}, {'name': 'Seyed Mostafa Kia'}, {'name': 'Giuseppe Jurman'}, {'name': 'Paola Venuti'}, {'name': 'Cesare Furlanello'}]",
//  "day": 5,
//  "id": "1511.01865v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1511.01865v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1511.01865v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Autism Spectrum Disorders (ASDs) are often associated with specific atypical\npostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have\na specific visibility. While the identification and the quantification of SMM\npatterns remain complex, its automation would provide support to accurate\ntuning of the intervention in the therapy of autism. Therefore, it is essential\nto develop automatic SMM detection systems in a real world setting, taking care\nof strong inter-subject and intra-subject variability. Wireless accelerometer\nsensing technology can provide a valid infrastructure for real-time SMM\ndetection, however such variability remains a problem also for machine learning\nmethods, in particular whenever handcrafted features extracted from\naccelerometer signal are considered. Here, we propose to employ the deep\nlearning paradigm in order to learn discriminating features from multi-sensor\naccelerometer signals. Our results provide preliminary evidence that feature\nlearning and transfer learning embedded in the deep architecture achieve higher\naccurate SMM detectors in longitudinal scenarios.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Convolutional Neural Network for Stereotypical Motor Movement Detection\n  in Autism",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Sasha Targ'}, {'name': 'Diogo Almeida'}, {'name': 'Kevin Lyman'}]",
//  "day": 25,
//  "id": "1603.08029v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.08029v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.08029v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Residual networks (ResNets) have recently achieved state-of-the-art on\nchallenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep\ndual-stream architecture that generalizes ResNets and standard CNNs and is\neasily implemented with no computational overhead. RiR consistently improves\nperformance over ResNets, outperforms architectures with similar amounts of\naugmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Resnet in Resnet: Generalizing Residual Architectures",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mohammad Javad Shafiee'}, {'name': 'Alexander Wong'}]",
//  "day": 6,
//  "id": "1609.01360v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.01360v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.01360v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "There has been significant recent interest towards achieving highly efficient\ndeep neural network architectures. A promising paradigm for achieving this is\nthe concept of evolutionary deep intelligence, which attempts to mimic\nbiological evolution processes to synthesize highly-efficient deep neural\nnetworks over successive generations. An important aspect of evolutionary deep\nintelligence is the genetic encoding scheme used to mimic heredity, which can\nhave a significant impact on the quality of offspring deep neural networks.\nMotivated by the neurobiological phenomenon of synaptic clustering, we\nintroduce a new genetic encoding scheme where synaptic probability is driven\ntowards the formation of a highly sparse set of synaptic clusters. Experimental\nresults for the task of image classification demonstrated that the synthesized\noffspring networks using this synaptic cluster-driven genetic encoding scheme\ncan achieve state-of-the-art performance while having network architectures\nthat are not only significantly more efficient (with a ~125-fold decrease in\nsynapses for MNIST) compared to the original ancestor network, but also\ntailored for GPU-accelerated machine learning applications.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Evolutionary Synthesis of Deep Neural Networks via Synaptic\n  Cluster-driven Genetic Encoding",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Andrew Brock'}, {'name': 'Theodore Lim'}, {'name': 'J. M. Ritchie'}, {'name': 'Nick Weston'}]",
//  "day": 22,
//  "id": "1609.07093v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.07093v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.07093v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "The increasingly photorealistic sample quality of generative image models\nsuggests their feasibility in applications beyond image generation. We present\nthe Neural Photo Editor, an interface that leverages the power of generative\nneural networks to make large, semantically coherent changes to existing\nimages. To tackle the challenge of achieving accurate reconstructions without\nloss of feature quality, we introduce the Introspective Adversarial Network, a\nnovel hybridization of the VAE and GAN. Our model efficiently captures\nlong-range dependencies through use of a computational block based on\nweight-shared dilated convolutions, and improves generalization performance\nwith Orthogonal Regularization, a novel weight regularization method. We\nvalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samples\nand reconstructions with high visual fidelity.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Neural Photo Editing with Introspective Adversarial Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Tolga Bolukbasi'}, {'name': 'Joseph Wang'}, {'name': 'Ofer Dekel'}, {'name': 'Venkatesh Saligrama'}]",
//  "day": 25,
//  "id": "1702.07811v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.07811v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.07811v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We present an approach to adaptively utilize deep neural networks in order to\nreduce the evaluation time on new examples without loss of accuracy. Rather\nthan attempting to redesign or approximate existing networks, we propose two\nschemes that adaptively utilize networks. We first pose an adaptive network\nevaluation scheme, where we learn a system to adaptively choose the components\nof a deep network to be evaluated for each example. By allowing examples\ncorrectly classified using early layers of the system to exit, we avoid the\ncomputational time associated with full evaluation of the network. We extend\nthis to learn a network selection system that adaptively selects the network to\nbe evaluated for each example. We show that computational time can be\ndramatically reduced by exploiting the fact that many examples can be correctly\nclassified using relatively efficient networks and that complex,\ncomputationally costly networks are only necessary for a small fraction of\nexamples. We pose a global objective for learning an adaptive early exit or\nnetwork selection policy and solve it by reducing the policy learning problem\nto a layer-by-layer weighted binary classification problem. Empirically, these\napproaches yield dramatic reductions in computational cost, with up to a 2.8x\nspeedup on state-of-the-art networks from the ImageNet image recognition\nchallenge with minimal (<1%) loss of top5 accuracy.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Adaptive Neural Networks for Efficient Inference",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhengyang Wang'}, {'name': 'Hao Yuan'}, {'name': 'Shuiwang Ji'}]",
//  "day": 18,
//  "id": "1705.06821v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.06821v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.06821v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "The key idea of variational auto-encoders (VAEs) resembles that of\ntraditional auto-encoder models in which spatial information is supposed to be\nexplicitly encoded in the latent space. However, the latent variables in VAEs\nare vectors, which are commonly interpreted as multiple feature maps of size\n1x1. Such representations can only convey spatial information implicitly when\ncoupled with powerful decoders. In this work, we propose spatial VAEs that use\nlatent variables as feature maps of larger size to explicitly capture spatial\ninformation. This is achieved by allowing the latent variables to be sampled\nfrom matrix-variate normal (MVN) distributions whose parameters are computed\nfrom the encoder network. To increase dependencies among locations on latent\nfeature maps and reduce the number of parameters, we further propose spatial\nVAEs via low-rank MVN distributions. Experimental results show that the\nproposed spatial VAEs outperform original VAEs in capturing rich structural and\nspatial information.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Spatial Variational Auto-Encoding via Matrix-Variate Normal\n  Distributions",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jun Li'}, {'name': 'Yongjun Chen'}, {'name': 'Lei Cai'}, {'name': 'Ian Davidson'}, {'name': 'Shuiwang Ji'}]",
//  "day": 24,
//  "id": "1705.08881v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08881v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08881v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "The key idea of current deep learning methods for dense prediction is to\napply a model on a regular patch centered on each pixel to make pixel-wise\npredictions. These methods are limited in the sense that the patches are\ndetermined by network architecture instead of learned from data. In this work,\nwe propose the dense transformer networks, which can learn the shapes and sizes\nof patches from data. The dense transformer networks employ an encoder-decoder\narchitecture, and a pair of dense transformer modules are inserted into each of\nthe encoder and decoder paths. The novelty of this work is that we provide\ntechnical solutions for learning the shapes and sizes of patches from data and\nefficiently restoring the spatial correspondence required for dense prediction.\nThe proposed dense transformer modules are differentiable, thus the entire\nnetwork can be trained. We apply the proposed networks on natural and\nbiological image segmentation tasks and show superior performance is achieved\nin comparison to baseline methods.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Dense Transformer Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Saikat Chatterjee'}, {'name': 'Alireza M. Javid'}, {'name': 'Mostafa Sadeghi'}, {'name': 'Partha P. Mitra'}, {'name': 'Mikael Skoglund'}]",
//  "day": 23,
//  "id": "1710.08177v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.08177v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.08177v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "We develop an algorithm for systematic design of a large artificial neural\nnetwork using a progression property. We find that some non-linear functions,\nsuch as the rectifier linear unit and its derivatives, hold the property. The\nsystematic design addresses the choice of network size and regularization of\nparameters. The number of nodes and layers in network increases in progression\nwith the objective of consistently reducing an appropriate cost. Each layer is\noptimized at a time, where appropriate parameters are learned using convex\noptimization. Regularization parameters for convex optimization do not need a\nsignificant manual effort for tuning. We also use random instances for some\nweight matrices, and that helps to reduce the number of parameters we learn.\nThe developed network is expected to show good generalization power due to\nappropriate regularization and use of random weights in the layers. This\nexpectation is verified by extensive experiments for classification and\nregression problems, using standard databases.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Progressive Learning for Systematic Design of Large Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Shibani Santurkar'}, {'name': 'Ludwig Schmidt'}, {'name': 'Aleksander M\u0105dry'}]",
//  "day": 2,
//  "id": "1711.00970v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.00970v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.00970v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "A fundamental, and still largely unanswered, question in the context of\nGenerative Adversarial Networks (GANs) is whether GANs are actually able to\ncapture the key characteristics of the datasets they are trained on. The\ncurrent approaches to examining this issue require significant human\nsupervision, such as visual inspection of sampled images, and often offer only\nfairly limited scalability. In this paper, we propose new techniques that\nemploy a classification-based perspective to evaluate synthetic GAN\ndistributions and their capability to accurately reflect the essential\nproperties of the training data. These techniques require only minimal human\nsupervision and can easily be scaled and adapted to evaluate a variety of\nstate-of-the-art GANs on large, popular datasets. Our analysis indicates that\nGANs have significant problems in reproducing the more distributional\nproperties of the training dataset. In particular, when seen through the lens\nof classification, the diversity of GAN data is orders of magnitude less than\nthat of the original data.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Classification-Based Perspective on GAN Distributions",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ethan Perez'}, {'name': 'Harm de Vries'}, {'name': 'Florian Strub'}, {'name': 'Vincent Dumoulin'}, {'name': 'Aaron Courville'}]",
//  "day": 10,
//  "id": "1707.03017v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.03017v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.03017v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Achieving artificial visual reasoning - the ability to answer image-related\nquestions which require a multi-step, high-level process - is an important step\ntowards artificial general intelligence. This multi-modal task requires\nlearning a question-dependent, structured reasoning process over images from\nlanguage. Standard deep learning approaches tend to exploit biases in the data\nrather than learn this underlying structure, while leading methods learn to\nvisually reason successfully but are hand-crafted for reasoning. We show that a\ngeneral-purpose, Conditional Batch Normalization approach achieves\nstate-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4%\nerror rate. We outperform the next best end-to-end method (4.5%) and even\nmethods that use extra supervision (3.1%). We probe our model to shed light on\nhow it reasons, showing it has learned a question-dependent, multi-step\nprocess. Previous work has operated under the assumption that visual reasoning\ncalls for a specialized architecture, but we show that a general architecture\nwith proper conditioning can learn to visually reason effectively.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Visual Reasoning Without Strong Priors",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jieyu Zhao'}, {'name': 'Tianlu Wang'}, {'name': 'Mark Yatskar'}, {'name': 'Vicente Ordonez'}, {'name': 'Kai-Wei Chang'}]",
//  "day": 29,
//  "id": "1707.09457v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.09457v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.09457v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Language is increasingly being used to define rich visual recognition\nproblems with supporting image collections sourced from the web. Structured\nprediction models are used in these tasks to take advantage of correlations\nbetween co-occurring labels and visual input but risk inadvertently encoding\nsocial biases found in web corpora. In this work, we study data and models\nassociated with multilabel object classification and visual semantic role\nlabeling. We find that (a) datasets for these tasks contain significant gender\nbias and (b) models trained on these datasets further amplify existing bias.\nFor example, the activity cooking is over 33% more likely to involve females\nthan males in a training set, and a trained model further amplifies the\ndisparity to 68% at test time. We propose to inject corpus-level constraints\nfor calibrating existing structured prediction models and design an algorithm\nbased on Lagrangian relaxation for collective inference. Our method results in\nalmost no performance loss for the underlying recognition task but decreases\nthe magnitude of bias amplification by 47.5% and 40.5% for multilabel\nclassification and visual semantic role labeling, respectively.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using\n  Corpus-level Constraints",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Guillem Collell'}, {'name': 'Luc Van Gool'}, {'name': 'Marie-Francine Moens'}]",
//  "day": 18,
//  "id": "1711.06821v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.06821v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.06821v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Spatial understanding is a fundamental problem with wide-reaching real-world\napplications. The representation of spatial knowledge is often modeled with\nspatial templates, i.e., regions of acceptability of two objects under an\nexplicit spatial relationship (e.g., \"on\", \"below\", etc.). In contrast with\nprior work that restricts spatial templates to explicit spatial prepositions\n(e.g., \"glass on table\"), here we extend this concept to implicit spatial\nlanguage, i.e., those relationships (generally actions) for which the spatial\narrangement of the objects is only implicitly implied (e.g., \"man riding\nhorse\"). In contrast with explicit relationships, predicting spatial\narrangements from implicit spatial language requires significant common sense\nspatial understanding. Here, we introduce the task of predicting spatial\ntemplates for two objects under a relationship, which can be seen as a spatial\nquestion-answering task with a (2D) continuous output (\"where is the man w.r.t.\na horse when the man is walking the horse?\"). We present two simple\nneural-based models that leverage annotated images and structured text to learn\nthis task. The good performance of these models reveals that spatial locations\nare to a large extent predictable from implicit spatial language. Crucially,\nthe models attain similar performance in a challenging generalized setting,\nwhere the object-relation-object combinations (e.g.,\"man walking dog\") have\nnever been seen before. Next, we go one step further by presenting the models\nwith unseen objects (e.g., \"dog\"). In this scenario, we show that leveraging\nword embeddings enables the models to output accurate spatial predictions,\nproving that the models acquire solid common sense spatial knowledge allowing\nfor such generalization.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Acquiring Common Sense Spatial Knowledge through Implicit Spatial\n  Templates",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ethan Perez'}, {'name': 'Florian Strub'}, {'name': 'Harm de Vries'}, {'name': 'Vincent Dumoulin'}, {'name': 'Aaron Courville'}]",
//  "day": 22,
//  "id": "1709.07871v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.07871v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.07871v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We introduce a general-purpose conditioning method for neural networks called\nFiLM: Feature-wise Linear Modulation. FiLM layers influence neural network\ncomputation via a simple, feature-wise affine transformation based on\nconditioning information. We show that FiLM layers are highly effective for\nvisual reasoning - answering image-related questions which require a\nmulti-step, high-level process - a task which has proven difficult for standard\ndeep learning methods that do not explicitly model reasoning. Specifically, we\nshow on visual reasoning tasks that FiLM layers 1) halve state-of-the-art error\nfor the CLEVR benchmark, 2) modulate features in a coherent manner, 3) are\nrobust to ablations and architectural modifications, and 4) generalize well to\nchallenging, new data from few examples or even zero-shot.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ivan Titov'}, {'name': 'Ehsan Khoddam'}]",
//  "day": 8,
//  "id": "1412.2812v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.2812v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.2812v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We introduce a new approach to unsupervised estimation of feature-rich\nsemantic role labeling models. Our model consists of two components: (1) an\nencoding component: a semantic role labeling model which predicts roles given a\nrich set of syntactic and lexical features; (2) a reconstruction component: a\ntensor factorization model which relies on roles to predict argument fillers.\nWhen the components are estimated jointly to minimize errors in argument\nreconstruction, the induced roles largely correspond to roles defined in\nannotated resources. Our method performs on par with most accurate role\ninduction methods on English and German, even though, unlike these previous\napproaches, we do not incorporate any prior linguistic knowledge about the\nlanguages.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Unsupervised Induction of Semantic Roles within a Reconstruction-Error\n  Minimization Framework",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Tolga Bolukbasi'}, {'name': 'Kai-Wei Chang'}, {'name': 'James Zou'}, {'name': 'Venkatesh Saligrama'}, {'name': 'Adam Kalai'}]",
//  "day": 21,
//  "id": "1607.06520v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1607.06520v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1607.06520v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "The blind application of machine learning runs the risk of amplifying biases\npresent in data. Such a danger is facing us with word embedding, a popular\nframework to represent text data as vectors which has been used in many machine\nlearning and natural language processing tasks. We show that even word\nembeddings trained on Google News articles exhibit female/male gender\nstereotypes to a disturbing extent. This raises concerns because their\nwidespread use, as we describe, often tends to amplify these biases.\nGeometrically, gender bias is first shown to be captured by a direction in the\nword embedding. Second, gender neutral words are shown to be linearly separable\nfrom gender definition words in the word embedding. Using these properties, we\nprovide a methodology for modifying an embedding to remove gender stereotypes,\nsuch as the association between between the words receptionist and female,\nwhile maintaining desired associations such as between the words queen and\nfemale. We define metrics to quantify both direct and indirect gender biases in\nembeddings, and develop algorithms to \"debias\" the embedding. Using\ncrowd-worker evaluation as well as standard benchmarks, we empirically\ndemonstrate that our algorithms significantly reduce gender bias in embeddings\nwhile preserving the its useful properties such as the ability to cluster\nrelated concepts and to solve analogy tasks. The resulting embeddings can be\nused in applications without amplifying gender bias.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\n  Embeddings",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Adji B. Dieng'}, {'name': 'Chong Wang'}, {'name': 'Jianfeng Gao'}, {'name': 'John Paisley'}]",
//  "day": 5,
//  "id": "1611.01702v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.01702v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.01702v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "In this paper, we propose TopicRNN, a recurrent neural network (RNN)-based\nlanguage model designed to directly capture the global semantic meaning\nrelating words in a document via latent topics. Because of their sequential\nnature, RNNs are good at capturing the local structure of a word sequence -\nboth semantic and syntactic - but might face difficulty remembering long-range\ndependencies. Intuitively, these long-range dependencies are of semantic\nnature. In contrast, latent topic models are able to capture the global\nunderlying semantic structure of a document but do not account for word\nordering. The proposed TopicRNN model integrates the merits of RNNs and latent\ntopic models: it captures local (syntactic) dependencies using an RNN and\nglobal (semantic) dependencies using latent topics. Unlike previous work on\ncontextual RNN language modeling, our model is learned end-to-end. Empirical\nresults on word prediction show that TopicRNN outperforms existing contextual\nRNN baselines. In addition, TopicRNN can be used as an unsupervised feature\nextractor for documents. We do this for sentiment analysis on the IMDB movie\nreview dataset and report an error rate of $6.28\\%$. This is comparable to the\nstate-of-the-art $5.91\\%$ resulting from a semi-supervised approach. Finally,\nTopicRNN also yields sensible topics, making it a useful alternative to\ndocument models such as latent Dirichlet allocation.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Liwen Zhang'}, {'name': 'John Winn'}, {'name': 'Ryota Tomioka'}]",
//  "day": 7,
//  "id": "1611.02266v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.02266v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.02266v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We propose the Gaussian attention model for content-based neural memory\naccess. With the proposed attention model, a neural network has the additional\ndegree of freedom to control the focus of its attention from a laser sharp\nattention to a broad attention. It is applicable whenever we can assume that\nthe distance in the latent space reflects some notion of semantics. We use the\nproposed attention model as a scoring function for the embedding of a knowledge\nbase into a continuous vector space and then train a model that performs\nquestion answering about the entities in the knowledge base. The proposed\nattention model can handle both the propagation of uncertainty when following a\nseries of relations and also the conjunction of conditions in a natural way. On\na dataset of soccer players who participated in the FIFA World Cup 2014, we\ndemonstrate that our model can handle both path queries and conjunctive queries\nwell.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Gaussian Attention Model and Its Application to Knowledge Base Embedding\n  and Question Answering",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yacine Jernite'}, {'name': 'Edouard Grave'}, {'name': 'Armand Joulin'}, {'name': 'Tomas Mikolov'}]",
//  "day": 18,
//  "id": "1611.06188v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.06188v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.06188v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Recurrent neural networks (RNNs) have been used extensively and with\nincreasing success to model various types of sequential data. Much of this\nprogress has been achieved through devising recurrent units and architectures\nwith the flexibility to capture complex statistics in the data, such as long\nrange dependency or localized attention phenomena. However, while many\nsequential data (such as video, speech or language) can have highly variable\ninformation flow, most recurrent models still consume input features at a\nconstant rate and perform a constant number of computations per time step,\nwhich can be detrimental to both speed and model capacity. In this paper, we\nexplore a modification to existing recurrent units which allows them to learn\nto vary the amount of computation they perform at each step, without prior\nknowledge of the sequence's time structure. We show experimentally that not\nonly do our models require fewer operations, they also lead to better\nperformance overall on evaluation tasks.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Variable Computation in Recurrent Neural Networks",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mostafa Dehghani'}, {'name': 'Aliaksei Severyn'}, {'name': 'Sascha Rothe'}, {'name': 'Jaap Kamps'}]",
//  "day": 30,
//  "id": "1711.11383v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.11383v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.11383v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "In this paper, we propose a method for training neural networks when we have\na large set of data with weak labels and a small amount of data with true\nlabels. In our proposed model, we train two neural networks: a target network,\nthe learner and a confidence network, the meta-learner. The target network is\noptimized to perform a given task and is trained using a large set of unlabeled\ndata that are weakly annotated. We propose to control the magnitude of the\ngradient updates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning to Learn from Weak Supervision by Full Supervision",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Garrett B. Goh'}, {'name': 'Nathan O. Hodas'}, {'name': 'Charles Siegel'}, {'name': 'Abhinav Vishnu'}]",
//  "day": 6,
//  "id": "1712.02034v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.02034v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.02034v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Gell\u00e9rt Weisz'}, {'name': 'Pawe\u0142 Budzianowski'}, {'name': 'Pei-Hao Su'}, {'name': 'Milica Ga\u0161i\u0107'}]",
//  "day": 11,
//  "id": "1802.03753v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.03753v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.03753v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'M. Andrecut'}]",
//  "day": 23,
//  "id": "1802.09914v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1142/S0129183118500158', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.09914v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.09914v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "High-Dimensional Vector Semantics",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Ashutosh Modi'}, {'name': 'Ivan Titov'}]",
//  "day": 18,
//  "id": "1312.5198v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1312.5198v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1312.5198v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Induction of common sense knowledge about prototypical sequences of events\nhas recently received much attention. Instead of inducing this knowledge in the\nform of graphs, as in much of the previous work, in our method, distributed\nrepresentations of event realizations are computed based on distributed\nrepresentations of predicates and their arguments, and then these\nrepresentations are used to predict prototypical event orderings. The\nparameters of the compositional process for computing the event representations\nand the ranking component of the model are jointly estimated from texts. We\nshow that this approach results in a substantial boost in ordering performance\nwith respect to previous methods.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Semantic Script Knowledge with Event Embeddings",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Andrew S. Lan'}, {'name': 'Divyanshu Vats'}, {'name': 'Andrew E. Waters'}, {'name': 'Richard G. Baraniuk'}]",
//  "day": 18,
//  "id": "1501.04346v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1501.04346v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1501.04346v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "While computer and communication technologies have provided effective means\nto scale up many aspects of education, the submission and grading of\nassessments such as homework assignments and tests remains a weak link. In this\npaper, we study the problem of automatically grading the kinds of open response\nmathematical questions that figure prominently in STEM (science, technology,\nengineering, and mathematics) courses. Our data-driven framework for\nmathematical language processing (MLP) leverages solution data from a large\nnumber of learners to evaluate the correctness of their solutions, assign\npartial-credit scores, and provide feedback to each learner on the likely\nlocations of any errors. MLP takes inspiration from the success of natural\nlanguage processing for text data and comprises three main steps. First, we\nconvert each solution to an open response mathematical question into a series\nof numerical features. Second, we cluster the features from several solutions\nto uncover the structures of correct, partially correct, and incorrect\nsolutions. We develop two different clustering approaches, one that leverages\ngeneric clustering algorithms and one based on Bayesian nonparametrics. Third,\nwe automatically grade the remaining (potentially large number of) solutions\nbased on their assigned cluster and one instructor-provided grade per cluster.\nAs a bonus, we can track the cluster assignment of each step of a multistep\nsolution and determine when it departs from a cluster of correct solutions,\nwhich enables us to indicate the likely locations of errors to learners. We\ntest and validate MLP on real-world MOOC data to demonstrate how it can\nsubstantially reduce the human effort required in large-scale educational\nplatforms.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Mathematical Language Processing: Automatic Grading and Feedback for\n  Open Response Mathematical Questions",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Tadahiro Taniguchi'}, {'name': 'Ryo Nakashima'}, {'name': 'Shogo Nagasaka'}]",
//  "day": 22,
//  "id": "1506.06646v2",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/TCDS.2016.2550591', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.06646v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.06646v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Human infants can discover words directly from unsegmented speech signals\nwithout any explicitly labeled data. In this paper, we develop a novel machine\nlearning method called nonparametric Bayesian double articulation analyzer\n(NPB-DAA) that can directly acquire language and acoustic models from observed\ncontinuous speech signals. For this purpose, we propose an integrative\ngenerative model that combines a language model and an acoustic model into a\nsingle generative model called the \"hierarchical Dirichlet process hidden\nlanguage model\" (HDP-HLM). The HDP-HLM is obtained by extending the\nhierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by\nJohnson et al. An inference procedure for the HDP-HLM is derived using the\nblocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure\nenables the simultaneous and direct inference of language and acoustic models\nfrom continuous speech signals. Based on the HDP-HLM and its inference\nprocedure, we developed a novel double articulation analyzer. By assuming\nHDP-HLM as a generative model of observed time series data, and by inferring\nlatent variables of the model, the method can analyze latent double\narticulation structure, i.e., hierarchically organized latent words and\nphonemes, of the data in an unsupervised manner. The novel unsupervised double\narticulation analyzer is called NPB-DAA.\n  The NPB-DAA can automatically estimate double articulation structure embedded\nin speech signals. We also carried out two evaluation experiments using\nsynthetic data and actual human continuous speech signals representing Japanese\nvowel sequences. In the word acquisition and phoneme categorization tasks, the\nNPB-DAA outperformed a conventional double articulation analyzer (DAA) and\nbaseline automatic speech recognition system whose acoustic model was trained\nin a supervised manner.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Nonparametric Bayesian Double Articulation Analyzer for Direct Language\n  Acquisition from Continuous Speech Signals",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Zhiting Hu'}, {'name': 'Xuezhe Ma'}, {'name': 'Zhengzhong Liu'}, {'name': 'Eduard Hovy'}, {'name': 'Eric Xing'}]",
//  "day": 21,
//  "id": "1603.06318v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1603.06318v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1603.06318v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Combining deep neural networks with structured logic rules is desirable to\nharness flexibility and reduce uninterpretability of the neural models. We\npropose a general framework capable of enhancing various types of neural\nnetworks (e.g., CNNs and RNNs) with declarative first-order logic rules.\nSpecifically, we develop an iterative distillation method that transfers the\nstructured information of logic rules into the weights of neural networks. We\ndeploy the framework on a CNN for sentiment analysis, and an RNN for named\nentity recognition. With a few highly intuitive rules, we obtain substantial\nimprovements and achieve state-of-the-art or comparable results to previous\nbest-performing systems.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Harnessing Deep Neural Networks with Logic Rules",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Zhiting Hu'}, {'name': 'Zichao Yang'}, {'name': 'Xiaodan Liang'}, {'name': 'Ruslan Salakhutdinov'}, {'name': 'Eric P. Xing'}]",
//  "day": 2,
//  "id": "1703.00955v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.00955v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.00955v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Toward Controlled Generation of Text",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Lianhui Qin'}, {'name': 'Zhisong Zhang'}, {'name': 'Hai Zhao'}, {'name': 'Zhiting Hu'}, {'name': 'Eric P. Xing'}]",
//  "day": 1,
//  "id": "1704.00217v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.00217v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.00217v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Implicit discourse relation classification is of great challenge due to the\nlack of connectives as strong linguistic cues, which motivates the use of\nannotated implicit connectives to improve the recognition. We propose a feature\nimitation framework in which an implicit relation network is driven to learn\nfrom another neural network with access to connectives, and thus encouraged to\nextract similarly salient features for accurate classification. We develop an\nadversarial model to enable an adaptive imitation scheme through competition\nbetween the implicit network and a rival feature discriminator. Our method\neffectively transfers discriminability of connectives to the implicit features,\nand achieves state-of-the-art performance on the PDTB benchmark.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Adversarial Connective-exploiting Networks for Implicit Discourse\n  Relation Classification",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Maxim Rabinovich'}, {'name': 'Mitchell Stern'}, {'name': 'Dan Klein'}]",
//  "day": 25,
//  "id": "1704.07535v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.07535v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.07535v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Tasks like code generation and semantic parsing require mapping unstructured\n(or partially structured) inputs to well-formed, executable outputs. We\nintroduce abstract syntax networks, a modeling framework for these problems.\nThe outputs are represented as abstract syntax trees (ASTs) and constructed by\na decoder with a dynamically-determined modular structure paralleling the\nstructure of the output tree. On the benchmark Hearthstone dataset for code\ngeneration, our model obtains 79.2 BLEU and 22.7% exact match accuracy,\ncompared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we\nperform competitively on the Atis, Jobs, and Geo semantic parsing datasets with\nno task-specific engineering.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Abstract Syntax Networks for Code Generation and Semantic Parsing",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ben Athiwaratkun'}, {'name': 'Andrew Gordon Wilson'}]",
//  "day": 27,
//  "id": "1704.08424v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08424v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08424v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Word embeddings provide point representations of words containing useful\nsemantic information. We introduce multimodal word distributions formed from\nGaussian mixtures, for multiple word meanings, entailment, and rich uncertainty\ninformation. To learn these distributions, we propose an energy-based\nmax-margin objective. We show that the resulting approach captures uniquely\nexpressive semantic information, and outperforms alternatives, such as word2vec\nskip-grams, and Gaussian embeddings, on benchmark datasets such as word\nsimilarity and entailment.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multimodal Word Distributions",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Brent Harrison'}, {'name': 'Upol Ehsan'}, {'name': 'Mark O. Riedl'}]",
//  "day": 26,
//  "id": "1707.08616v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.08616v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.08616v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "In this work we present a technique to use natural language to help\nreinforcement learning generalize to unseen environments. This technique uses\nneural machine translation, specifically the use of encoder-decoder networks,\nto learn associations between natural language behavior descriptions and\nstate-action information. We then use this learned model to guide agent\nexploration using a modified version of policy shaping to make it more\neffective at learning in unseen environments. We evaluate this technique using\nthe popular arcade game, Frogger, under ideal and non-ideal conditions. This\nevaluation shows that our modified policy shaping algorithm improves over a\nQ-learning agent as well as a baseline version of policy shaping.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Guiding Reinforcement Learning Exploration Using Natural Language",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Mo Yu'}, {'name': 'Xiaoxiao Guo'}, {'name': 'Jinfeng Yi'}, {'name': 'Shiyu Chang'}, {'name': 'Saloni Potdar'}, {'name': 'Gerald Tesauro'}, {'name': 'Haoyu Wang'}, {'name': 'Bowen Zhou'}]",
//  "day": 26,
//  "id": "1708.07918v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.07918v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.07918v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We investigate task clustering for deep-learning based multi-task and\nfew-shot learning in a many-task setting. We propose a new method to measure\ntask similarities with cross-task transfer performance matrix for the deep\nlearning scenario. Although this matrix provides us critical information\nregarding similarity between tasks, its asymmetric property and unreliable\nperformance scores can affect conventional clustering methods adversely.\nAdditionally, the uncertain task-pairs, i.e., the ones with extremely\nasymmetric transfer scores, may collectively mislead clustering algorithms to\noutput an inaccurate task-partition. To overcome these limitations, we propose\na novel task-clustering algorithm by using the matrix completion technique. The\nproposed algorithm constructs a partially-observed similarity matrix based on\nthe certainty of cluster membership of the task-pairs. We then use a matrix\ncompletion algorithm to complete the similarity matrix. Our theoretical\nanalysis shows that under mild constraints, the proposed algorithm will\nperfectly recover the underlying \"true\" similarity matrix with a high\nprobability. Our results show that the new task clustering method can discover\ntask clusters for training flexible and superior neural network models in a\nmulti-task learning setup for sentiment classification and dialog intent\nclassification tasks. Our task clustering approach also extends metric-based\nfew-shot learning methods to adapt multiple metrics, which demonstrates\nempirical advantages when the tasks are diverse.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Robust Task Clustering for Deep Many-Task Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Gino Brunner'}, {'name': 'Yuyi Wang'}, {'name': 'Roger Wattenhofer'}, {'name': 'Michael Weigelt'}]",
//  "day": 18,
//  "id": "1801.06024v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.06024v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.06024v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "We train multi-task autoencoders on linguistic tasks and analyze the learned\nhidden sentence representations. The representations change significantly when\ntranslation and part-of-speech decoders are added. The more decoders a model\nemploys, the better it clusters sentences according to their syntactic\nsimilarity, as the representation space becomes less entangled. We explore the\nstructure of the representation space by interpolating between sentences, which\nyields interesting pseudo-English sentences, many of which have recognizable\nsyntactic structure. Lastly, we point out an interesting property of our\nmodels: The difference-vector between two sentences can be added to change a\nthird sentence with similar features in a meaningful way.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Natural Language Multitasking: Analyzing and Improving Syntactic\n  Saliency of Hidden Representations",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Minghai Chen'}, {'name': 'Sen Wang'}, {'name': 'Paul Pu Liang'}, {'name': 'Tadas Baltru\u0161aitis'}, {'name': 'Amir Zadeh'}, {'name': 'Louis-Philippe Morency'}]",
//  "day": 3,
//  "id": "1802.00924v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.00924v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.00924v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "With the increasing popularity of video sharing websites such as YouTube and\nFacebook, multimodal sentiment analysis has received increasing attention from\nthe scientific community. Contrary to previous works in multimodal sentiment\nanalysis which focus on holistic information in speech segments such as bag of\nwords representations and average facial expression intensity, we develop a\nnovel deep architecture for multimodal sentiment analysis that performs\nmodality fusion at the word level. In this paper, we propose the Gated\nMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\ncomposed of 2 modules. The Gated Multimodal Embedding alleviates the\ndifficulties of fusion when there are noisy modalities. The LSTM with Temporal\nAttention performs word level fusion at a finer fusion resolution between input\nmodalities and attends to the most important time steps. As a result, the\nGME-LSTM(A) is able to better model the multimodal structure of speech through\ntime and perform better sentiment comprehension. We demonstrate the\neffectiveness of this approach on the publicly-available Multimodal Corpus of\nSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\nstate-of-the-art sentiment classification and regression results. Qualitative\nanalysis on our model emphasizes the importance of the Temporal Attention Layer\nin sentiment prediction because the additional acoustic and visual modalities\nare noisy. We also demonstrate the effectiveness of the Gated Multimodal\nEmbedding in selectively filtering these noisy modalities out. Our results and\nanalysis open new areas in the study of sentiment analysis in human\ncommunication and provide new models for multimodal fusion.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n  Learning",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Ed Collins'}, {'name': 'Isabelle Augenstein'}, {'name': 'Sebastian Riedel'}]",
//  "day": 13,
//  "id": "1706.03946v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.03946v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.03946v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Automatic summarisation is a popular approach to reduce a document to its\nmain arguments. Recent research in the area has focused on neural approaches to\nsummarisation, which can be very data-hungry. However, few large datasets exist\nand none for the traditionally popular domain of scientific publications, which\nopens up challenging research avenues centered on encoding large, complex\ndocuments. In this paper, we introduce a new dataset for summarisation of\ncomputer science publications by exploiting a large resource of author provided\nsummaries and show straightforward ways of extending it further. We develop\nmodels on the dataset making use of both neural sentence encoding and\ntraditionally used summarisation features and show that models which encode\nsentences as well as their local and global context perform best, significantly\noutperforming well-established baseline methods.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.AP', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Supervised Approach to Extractive Summarisation of Scientific Papers",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jacob Devlin'}, {'name': 'Hao Cheng'}, {'name': 'Hao Fang'}, {'name': 'Saurabh Gupta'}, {'name': 'Li Deng'}, {'name': 'Xiaodong He'}, {'name': 'Geoffrey Zweig'}, {'name': 'Margaret Mitchell'}]",
//  "day": 7,
//  "id": "1505.01809v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1505.01809v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1505.01809v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Two recent approaches have achieved state-of-the-art results in image\ncaptioning. The first uses a pipelined process where a set of candidate words\nis generated by a convolutional neural network (CNN) trained on images, and\nthen a maximum entropy (ME) language model is used to arrange these words into\na coherent sentence. The second uses the penultimate activation layer of the\nCNN as input to a recurrent neural network (RNN) that then generates the\ncaption sequence. In this paper, we compare the merits of these different\nlanguage modeling approaches for the first time by using the same\nstate-of-the-art CNN as input. We examine issues in the different approaches,\nincluding linguistic irregularities, caption repetition, and data set overlap.\nBy combining key aspects of the ME and RNN methods, we achieve a new record\nperformance over previously published results on the benchmark COCO dataset.\nHowever, the gains we see in BLEU do not translate to human judgments.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Language Models for Image Captioning: The Quirks and What Works",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Mengye Ren'}, {'name': 'Ryan Kiros'}, {'name': 'Richard Zemel'}]",
//  "day": 8,
//  "id": "1505.02074v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1505.02074v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1505.02074v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "This work aims to address the problem of image-based question-answering (QA)\nwith new models and datasets. In our work, we propose to use neural networks\nand visual semantic embeddings, without intermediate stages such as object\ndetection and image segmentation, to predict answers to simple questions about\nimages. Our model performs 1.8 times better than the only published results on\nan existing image QA dataset. We also present a question generation algorithm\nthat converts image descriptions, which are widely available, into QA form. We\nused this algorithm to produce an order-of-magnitude larger dataset, with more\nevenly distributed answers. A suite of baseline results on this new dataset are\nalso presented.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Exploring Models and Data for Image Question Answering",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Yash Goyal'}, {'name': 'Tejas Khot'}, {'name': 'Douglas Summers-Stay'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}]",
//  "day": 2,
//  "id": "1612.00837v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.00837v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.00837v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Problems at the intersection of vision and language are of significant\nimportance both as challenging research questions and for the rich set of\napplications they enable. However, inherent structure in our world and bias in\nour language tend to be a simpler signal for learning than visual modalities,\nresulting in models that ignore visual information, leading to an inflated\nsense of their capability.\n  We propose to counter these language priors for the task of Visual Question\nAnswering (VQA) and make vision (the V in VQA) matter! Specifically, we balance\nthe popular VQA dataset by collecting complementary images such that every\nquestion in our balanced dataset is associated with not just a single image,\nbut rather a pair of similar images that result in two different answers to the\nquestion. Our dataset is by construction more balanced than the original VQA\ndataset and has approximately twice the number of image-question pairs. Our\ncomplete balanced dataset is publicly available at www.visualqa.org as part of\nthe 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA\nv2.0).\n  We further benchmark a number of state-of-art VQA models on our balanced\ndataset. All models perform significantly worse on our balanced dataset,\nsuggesting that these models have indeed learned to exploit language priors.\nThis finding provides the first concrete empirical evidence for what seems to\nbe a qualitative sense among practitioners.\n  Finally, our data collection protocol for identifying complementary images\nenables us to develop a novel interpretable model, which in addition to\nproviding an answer to the given (image, question) pair, also provides a\ncounter-example based explanation. Specifically, it identifies an image that is\nsimilar to the original image, but it believes has a different answer to the\nsame question. This can help in building trust for machines among their users.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in\n  Visual Question Answering",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Mateusz Malinowski'}, {'name': 'Mario Fritz'}]",
//  "day": 1,
//  "id": "1410.0210v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1410.0210v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1410.0210v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "We propose a method for automatically answering questions about images by\nbringing together recent advances from natural language processing and computer\nvision. We combine discrete reasoning with uncertain predictions by a\nmulti-world approach that represents uncertainty about the perceived world in a\nbayesian framework. Our approach can handle human questions of high complexity\nabout realistic scenes and replies with range of answer like counts, object\nclasses, instances and lists of them. The system is directly trained from\nquestion-answer pairs. We establish a first benchmark for this task that can be\nseen as a modern attempt at a visual turing test.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Multi-World Approach to Question Answering about Real-World Scenes\n  based on Uncertain Input",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Mateusz Malinowski'}, {'name': 'Mario Fritz'}]",
//  "day": 14,
//  "id": "1501.03302v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1501.03302v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1501.03302v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Progress in language and image understanding by machines has sparkled the\ninterest of the research community in more open-ended, holistic tasks, and\nrefueled an old AI dream of building intelligent machines. We discuss a few\nprominent challenges that characterize such holistic tasks and argue for\n\"question answering about images\" as a particular appealing instance of such a\nholistic task. In particular, we point out that it is a version of a Turing\nTest that is likely to be more robust to over-interpretations and contrast it\nwith tasks like grounding and generation of descriptions. Finally, we discuss\ntools to measure progress in this field.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hard to Cheat: A Turing Test based on Answering Questions about Images",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Aishwarya Agrawal'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}]",
//  "day": 23,
//  "id": "1606.07356v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.07356v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.07356v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Recently, a number of deep-learning based models have been proposed for the\ntask of Visual Question Answering (VQA). The performance of most models is\nclustered around 60-70%. In this paper we propose systematic methods to analyze\nthe behavior of these models as a first step towards recognizing their\nstrengths and weaknesses, and identifying the most fruitful directions for\nprogress. We analyze two models, one each from two major classes of VQA models\n-- with-attention and without-attention and show the similarities and\ndifferences in the behavior of these models. We also analyze the winning entry\nof the VQA Challenge 2016.\n  Our behavior analysis reveals that despite recent progress, today's VQA\nmodels are \"myopic\" (tend to fail on sufficiently novel instances), often \"jump\nto conclusions\" (converge on a predicted answer after 'listening' to just half\nthe question), and are \"stubborn\" (do not change their answers across images).",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Analyzing the Behavior of Visual Question Answering Models",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Harsh Agrawal'}, {'name': 'Arjun Chandrasekaran'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}, {'name': 'Mohit Bansal'}]",
//  "day": 23,
//  "id": "1606.07493v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.07493v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.07493v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Temporal common sense has applications in AI tasks such as QA, multi-document\nsummarization, and human-AI communication. We propose the task of sequencing --\ngiven a jumbled set of aligned image-caption pairs that belong to a story, the\ntask is to sort them such that the output sequence forms a coherent story. We\npresent multiple approaches, via unary (position) and pairwise (order)\npredictions, and their ensemble-based combinations, achieving strong results on\nthis task. We use both text-based and image-based features, which depict\ncomplementary improvements. Using qualitative examples, we demonstrate that our\nmodels have learnt interesting aspects of temporal common sense.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Sort Story: Sorting Jumbled Images and Captions into Stories",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Ashkan Mokarian'}, {'name': 'Mateusz Malinowski'}, {'name': 'Mario Fritz'}]",
//  "day": 9,
//  "id": "1608.02717v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.02717v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.02717v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We present Mean Box Pooling, a novel visual representation that pools over\nCNN representations of a large number, highly overlapping object proposals. We\nshow that such representation together with nCCA, a successful multimodal\nembedding technique, achieves state-of-the-art performance on the Visual\nMadlibs task. Moreover, inspired by the nCCA's objective function, we extend\nclassical CNN+LSTM approach to train the network by directly maximizing the\nsimilarity between the internal representation of the deep learning\narchitecture and candidate answers. Again, such approach achieves a significant\nimprovement over the prior work that also uses CNN+LSTM approach on Visual\nMadlibs.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Mean Box Pooling: A Rich Image Representation and Output Embedding for\n  the Visual Madlibs Task",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yuval Atzmon'}, {'name': 'Jonathan Berant'}, {'name': 'Vahid Kezami'}, {'name': 'Amir Globerson'}, {'name': 'Gal Chechik'}]",
//  "day": 27,
//  "id": "1608.07639v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.07639v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.07639v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Recurrent neural networks have recently been used for learning to describe\nimages using natural language. However, it has been observed that these models\ngeneralize poorly to scenes that were not observed during training, possibly\ndepending too strongly on the statistics of the text in the training data. Here\nwe propose to describe images using short structured representations, aiming to\ncapture the crux of a description. These structured representations allow us to\ntease-out and evaluate separately two types of generalization: standard\ngeneralization to new images with similar scenes, and generalization to new\ncombinations of known entities. We compare two learning approaches on the\nMS-COCO dataset: a state-of-the-art recurrent network based on an LSTM (Show,\nAttend and Tell), and a simple structured prediction model on top of a deep\nnetwork. We find that the structured model generalizes to new compositions\nsubstantially better than the LSTM, ~7 times the accuracy of predicting\nstructured representations. By providing a concrete method to quantify\ngeneralization for unseen combinations, we argue that structured\nrepresentations and compositional splits are a useful benchmark for image\ncaptioning, and advocate compositional models that capture linguistic and\nvisual structure.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning to generalize to new compositions in image understanding",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'C. Lawrence Zitnick'}, {'name': 'Aishwarya Agrawal'}, {'name': 'Stanislaw Antol'}, {'name': 'Margaret Mitchell'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}]",
//  "day": 31,
//  "id": "1608.08716v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.08716v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.08716v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "As machines have become more intelligent, there has been a renewed interest\nin methods for measuring their intelligence. A common approach is to propose\ntasks for which a human excels, but one which machines find difficult. However,\nan ideal task should also be easy to evaluate and not be easily gameable. We\nbegin with a case study exploring the recently popular task of image captioning\nand its limitations as a task for measuring machine intelligence. An\nalternative and more promising task is Visual Question Answering that tests a\nmachine's ability to reason about language and vision. We describe a dataset\nunprecedented in size created for the task that contains over 760,000 human\ngenerated questions about images. Using around 10 million human generated\nanswers, machines may be easily evaluated.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Measuring Machine Intelligence Through Visual Question Answering",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yash Goyal'}, {'name': 'Akrit Mohapatra'}, {'name': 'Devi Parikh'}, {'name': 'Dhruv Batra'}]",
//  "day": 31,
//  "id": "1608.08974v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.08974v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.08974v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Deep neural networks have shown striking progress and obtained\nstate-of-the-art results in many AI research fields in the recent years.\nHowever, it is often unsatisfying to not know why they predict what they do. In\nthis paper, we address the problem of interpreting Visual Question Answering\n(VQA) models. Specifically, we are interested in finding what part of the input\n(pixels in images or words in questions) the VQA model focuses on while\nanswering the question. To tackle this problem, we use two visualization\ntechniques -- guided backpropagation and occlusion -- to find important words\nin the question and important regions in the image. We then present qualitative\nand quantitative analyses of these importance maps. We found that even without\nexplicit attention mechanisms, VQA models may sometimes be implicitly attending\nto relevant regions in the image, and often to appropriate words in the\nquestion.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards Transparent AI Systems: Interpreting Visual Question Answering\n  Models",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Abhishek Das'}, {'name': 'Satwik Kottur'}, {'name': 'Khushi Gupta'}, {'name': 'Avi Singh'}, {'name': 'Deshraj Yadav'}, {'name': 'Jos\u00e9 M. F. Moura'}, {'name': 'Devi Parikh'}, {'name': 'Dhruv Batra'}]",
//  "day": 26,
//  "id": "1611.08669v5",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1611.08669v5', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1611.08669v5', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We introduce the task of Visual Dialog, which requires an AI agent to hold a\nmeaningful dialog with humans in natural, conversational language about visual\ncontent. Specifically, given an image, a dialog history, and a question about\nthe image, the agent has to ground the question in image, infer context from\nhistory, and answer the question accurately. Visual Dialog is disentangled\nenough from a specific downstream task so as to serve as a general test of\nmachine intelligence, while being grounded in vision enough to allow objective\nevaluation of individual responses and benchmark progress. We develop a novel\ntwo-person chat data-collection protocol to curate a large-scale Visual Dialog\ndataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10\nquestion-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog\nquestion-answer pairs.\n  We introduce a family of neural encoder-decoder models for Visual Dialog with\n3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --\nand 2 decoders (generative and discriminative), which outperform a number of\nsophisticated baselines. We propose a retrieval-based evaluation protocol for\nVisual Dialog where the AI agent is asked to sort a set of candidate answers\nand evaluated on metrics such as mean-reciprocal-rank of human response. We\nquantify gap between machine and human performance on the Visual Dialog task\nvia human studies. Putting it all together, we demonstrate the first 'visual\nchatbot'! Our dataset, code, trained models and visual chatbot are available on\nhttps://visualdialog.org",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Visual Dialog",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Abhinav Thanda'}, {'name': 'Shankar M Venkatesan'}]",
//  "day": 10,
//  "id": "1701.02477v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.02477v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.02477v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Multi-task learning (MTL) involves the simultaneous training of two or more\nrelated tasks over shared representations. In this work, we apply MTL to\naudio-visual automatic speech recognition(AV-ASR). Our primary task is to learn\na mapping between audio-visual fused features and frame labels obtained from\nacoustic GMM/HMM model. This is combined with an auxiliary task which maps\nvisual features to frame labels obtained from a separate visual GMM/HMM model.\nThe MTL model is tested at various levels of babble noise and the results are\ncompared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicate\nthat MTL is especially useful at higher level of noise. Compared to base-line,\nupto 7\\% relative improvement in WER is reported at -3 SNR dB",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic\n  Speech Recognition",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Abhishek Das'}, {'name': 'Satwik Kottur'}, {'name': 'Jos\u00e9 M. F. Moura'}, {'name': 'Stefan Lee'}, {'name': 'Dhruv Batra'}]",
//  "day": 20,
//  "id": "1703.06585v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.06585v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.06585v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Wei-Lun Chao'}, {'name': 'Hexiang Hu'}, {'name': 'Fei Sha'}]",
//  "day": 24,
//  "id": "1704.07121v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.07121v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.07121v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Visual question answering (QA) has attracted a lot of attention lately, seen\nessentially as a form of (visual) Turing test that artificial intelligence\nshould strive to achieve. In this paper, we study a crucial component of this\ntask: how can we design good datasets for the task? We focus on the design of\nmultiple-choice based datasets where the learner has to select the right answer\nfrom a set of candidate ones including the target (i.e. the correct one) and\nthe decoys (i.e. the incorrect ones). Through careful analysis of the results\nattained by state-of-the-art learning models and human annotators on existing\ndatasets, we show the design of the decoy answers has a significant impact on\nhow and what the learning models learn from the datasets. In particular, the\nresulting learner can ignore the visual information, the question, or the both\nwhile still doing well on the task. Inspired by this, we propose automatic\nprocedures to remedy such design deficiencies. We apply the procedures to\nre-construct decoy answers for two popular visual QA datasets as well as to\ncreate a new visual QA dataset from the Visual Genome project, resulting in the\nlargest dataset for this task. Extensive empirical studies show that the design\ndeficiencies have been alleviated in the remedied datasets and the performance\non them is likely a more faithful indicator of the difference among learning\nmodels. The datasets are released and publicly available via\nhttp://www.teds.usc.edu/website_vqa/.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Being Negative but Constructively: Lessons Learnt from Creating Better\n  Visual Question Answering Datasets",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Aishwarya Agrawal'}, {'name': 'Aniruddha Kembhavi'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}]",
//  "day": 26,
//  "id": "1704.08243v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08243v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08243v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Visual Question Answering (VQA) has received a lot of attention over the past\ncouple of years. A number of deep learning models have been proposed for this\ntask. However, it has been shown that these models are heavily driven by\nsuperficial correlations in the training data and lack compositionality -- the\nability to answer questions about unseen compositions of seen concepts. This\ncompositionality is desirable and central to intelligence. In this paper, we\npropose a new setting for Visual Question Answering where the test\nquestion-answer pairs are compositionally novel compared to training\nquestion-answer pairs. To facilitate developing models under this setting, we\npresent a new compositional split of the VQA v1.0 dataset, which we call\nCompositional VQA (C-VQA). We analyze the distribution of questions and answers\nin the C-VQA splits. Finally, we evaluate several existing VQA models under\nthis new setting and show that the performances of these models degrade by a\nsignificant amount compared to the original VQA setting.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0\n  Dataset",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Alexander Kuhnle'}, {'name': 'Ann Copestake'}]",
//  "day": 5,
//  "id": "1706.01322v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.01322v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.01322v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We discuss problems with the standard approaches to evaluation for tasks like\nvisual question answering, and argue that artificial data can be used to\naddress these as a complement to current practice. We demonstrate that with the\nhelp of existing 'deep' linguistic processing technology we are able to create\nchallenging abstract datasets, which enable us to investigate the language\nunderstanding abilities of multimodal deep learning models in detail.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep learning evaluation using deep linguistic processing",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Xu Sun'}, {'name': 'Xuancheng Ren'}, {'name': 'Shuming Ma'}, {'name': 'Houfeng Wang'}]",
//  "day": 19,
//  "id": "1706.06197v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.06197v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.06197v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We propose a simple yet effective technique for neural network learning. The\nforward propagation is computed as usual. In back propagation, only a small\nsubset of the full gradient is computed to update the model parameters. The\ngradient vectors are sparsified in such a way that only the top-$k$ elements\n(in terms of magnitude) are kept. As a result, only $k$ rows or columns\n(depending on the layout) of the weight matrix are modified, leading to a\nlinear reduction ($k$ divided by the vector dimension) in the computational\ncost. Surprisingly, experimental results demonstrate that we can update only\n1--4\\% of the weights at each back propagation pass. This does not result in a\nlarger number of training iterations. More interestingly, the accuracy of the\nresulting models is actually improved rather than degraded, and a detailed\nanalysis is given. The code is available at https://github.com/jklj077/meProp",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "meProp: Sparsified Back Propagation for Accelerated Deep Learning with\n  Reduced Overfitting",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Suranjana Samanta'}, {'name': 'Sameep Mehta'}]",
//  "day": 10,
//  "id": "1707.02812v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.02812v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.02812v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Adversarial samples are strategically modified samples, which are crafted\nwith the purpose of fooling a classifier at hand. An attacker introduces\nspecially crafted adversarial samples to a deployed classifier, which are being\nmis-classified by the classifier. However, the samples are perceived to be\ndrawn from entirely different classes and thus it becomes hard to detect the\nadversarial samples. Most of the prior works have been focused on synthesizing\nadversarial samples in the image domain. In this paper, we propose a new method\nof crafting adversarial text samples by modification of the original samples.\nModifications of the original text samples are done by deleting or replacing\nthe important or salient words in the text or by introducing new words in the\ntext sample. Our algorithm works best for the datasets which have\nsub-categories within each of the classes of examples. While crafting\nadversarial samples, one of the key constraint is to generate meaningful\nsentences which can at pass off as legitimate from language (English)\nviewpoint. Experimental results on IMDB movie review dataset for sentiment\nanalysis and Twitter dataset for gender detection show the efficiency of our\nproposed method.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Towards Crafting Text Adversarial Samples",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ramakanth Pasunuru'}, {'name': 'Mohit Bansal'}]",
//  "day": 7,
//  "id": "1708.02300v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.02300v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.02300v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Sequence-to-sequence models have shown promising improvements on the temporal\ntask of video captioning, but they optimize word-level cross-entropy loss\nduring training. First, using policy gradient and mixed-loss methods for\nreinforcement learning, we directly optimize sentence-level task-based metrics\n(as rewards), achieving significant improvements over the baseline, based on\nboth automatic metrics and human evaluation on multiple datasets. Next, we\npropose a novel entailment-enhanced reward (CIDEnt) that corrects\nphrase-matching based metrics (such as CIDEr) to only allow for\nlogically-implied partial matches and avoid contradictions, achieving further\nsignificant improvements over the CIDEr-reward model. Overall, our\nCIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Reinforced Video Captioning with Entailment Rewards",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Licheng Yu'}, {'name': 'Mohit Bansal'}, {'name': 'Tamara L. Berg'}]",
//  "day": 9,
//  "id": "1708.02977v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.02977v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.02977v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "We address the problem of end-to-end visual storytelling. Given a photo\nalbum, our model first selects the most representative (summary) photos, and\nthen composes a natural language story for the album. For this task, we make\nuse of the Visual Storytelling dataset and a model composed of three\nhierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album\nphotos, select representative (summary) photos, and compose the story.\nAutomatic and human evaluations show our model achieves better performance on\nselection, generation, and retrieval than baselines.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hierarchically-Attentive RNN for Album Summarization and Storytelling",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhengli Zhao'}, {'name': 'Dheeru Dua'}, {'name': 'Sameer Singh'}]",
//  "day": 31,
//  "id": "1710.11342v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.11342v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.11342v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Due to their complex nature, it is hard to characterize the ways in which\nmachine learning models can misbehave or be exploited when deployed. Recent\nwork on adversarial examples, i.e. inputs with minor perturbations that result\nin substantially different model predictions, is helpful in evaluating the\nrobustness of these models by exposing the adversarial scenarios where they\nfail. However, these malicious perturbations are often unnatural, not\nsemantically meaningful, and not applicable to complicated domains such as\nlanguage. In this paper, we propose a framework to generate natural and legible\nadversarial examples that lie on the data manifold, by searching in semantic\nspace of dense and continuous data representation, utilizing the recent\nadvances in generative adversarial networks. We present generated adversaries\nto demonstrate the potential of the proposed approach for black-box classifiers\nfor a wide range of applications such as image classification, textual\nentailment, and machine translation. We include experiments to show that the\ngenerated adversaries are natural, legible to humans, and useful in evaluating\nand analyzing black-box classifiers.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generating Natural Adversarial Examples",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Xu Sun'}, {'name': 'Xuancheng Ren'}, {'name': 'Shuming Ma'}, {'name': 'Bingzhen Wei'}, {'name': 'Wei Li'}, {'name': 'Houfeng Wang'}]",
//  "day": 17,
//  "id": "1711.06528v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.06528v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.06528v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We propose a simple yet effective technique to simplify the training and the\nresulting model of neural networks. In back propagation, only a small subset of\nthe full gradient is computed to update the model parameters. The gradient\nvectors are sparsified in such a way that only the top-$k$ elements (in terms\nof magnitude) are kept. As a result, only $k$ rows or columns (depending on the\nlayout) of the weight matrix are modified, leading to a linear reduction in the\ncomputational cost. Based on the sparsified gradients, we further simplify the\nmodel by eliminating the rows or columns that are seldom updated, which will\nreduce the computational cost both in the training and decoding, and\npotentially accelerate decoding in real-world applications. Surprisingly,\nexperimental results demonstrate that most of time we only need to update fewer\nthan 5% of the weights at each back propagation pass. More interestingly, the\naccuracy of the resulting models is actually improved rather than degraded, and\na detailed analysis is given. The model simplification results show that we\ncould adaptively simplify the model which could often be reduced by around 9x,\nwithout any loss on accuracy or even with improved accuracy.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Training Simplification and Model Simplification for Deep Learning: A\n  Minimal Effort Back Propagation Method",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Abhishek Das'}, {'name': 'Samyak Datta'}, {'name': 'Georgia Gkioxari'}, {'name': 'Stefan Lee'}, {'name': 'Devi Parikh'}, {'name': 'Dhruv Batra'}]",
//  "day": 30,
//  "id": "1711.11543v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.11543v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.11543v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where\nan agent is spawned at a random location in a 3D environment and asked a\nquestion (\"What color is the car?\"). In order to answer, the agent must first\nintelligently navigate to explore the environment, gather information through\nfirst-person (egocentric) vision, and then answer the question (\"orange\").\n  This challenging task requires a range of AI skills -- active perception,\nlanguage understanding, goal-driven navigation, commonsense reasoning, and\ngrounding of language into actions. In this work, we develop the environments,\nend-to-end-trained reinforcement learning agents, and evaluation protocols for\nEmbodiedQA.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Embodied Question Answering",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Aishwarya Agrawal'}, {'name': 'Dhruv Batra'}, {'name': 'Devi Parikh'}, {'name': 'Aniruddha Kembhavi'}]",
//  "day": 1,
//  "id": "1712.00377v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.00377v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.00377v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jin-Hwa Kim'}, {'name': 'Devi Parikh'}, {'name': 'Dhruv Batra'}, {'name': 'Byoung-Tak Zhang'}, {'name': 'Yuandong Tian'}]",
//  "day": 15,
//  "id": "1712.05558v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.05558v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.05558v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "In this work, we propose a goal-driven collaborative task that contains\nvision, language, and action in a virtual environment as its core components.\nSpecifically, we develop a collaborative `Image Drawing' game between two\nagents, called CoDraw. Our game is grounded in a virtual world that contains\nmovable clip art objects. Two players, Teller and Drawer, are involved. The\nTeller sees an abstract scene containing multiple clip arts in a semantically\nmeaningful configuration, while the Drawer tries to reconstruct the scene on an\nempty canvas using available clip arts. The two players communicate via two-way\ncommunication using natural language. We collect the CoDraw dataset of ~10K\ndialogs consisting of 138K messages exchanged between a Teller and a Drawer\nfrom Amazon Mechanical Turk (AMT). We analyze our dataset and present three\nmodels to model the players' behaviors, including an attention model to\ndescribe and draw multiple clip arts at each round. The attention models are\nquantitatively compared to the other models to show how the conventional\napproaches work for this new task. We also present qualitative visualizations.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "CoDraw: Visual Dialog for Collaborative Drawing",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Sang-Woo Lee'}, {'name': 'Yu-Jung Heo'}, {'name': 'Byoung-Tak Zhang'}]",
//  "day": 12,
//  "id": "1802.03881v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.03881v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1802.03881v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Goal-oriented dialogue has been paid attention for its numerous applications\nin artificial intelligence. To solve this task, deep learning and reinforcement\nlearning have recently been applied. However, these approaches struggle to find\na competent recurrent neural questioner, owing to the complexity of learning a\nseries of sentences. Motivated by theory of mind, we propose \"Answerer in\nQuestioner's Mind\" (AQM), a novel algorithm for goal-oriented dialogue. With\nAQM, a questioner asks and infers based on an approximated probabilistic model\nof the answerer. The questioner figures out the answerer's intent via selecting\na plausible question by explicitly calculating the information gain of the\ncandidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialogue tasks: \"MNIST Counting Dialog\"\nand \"GuessWhat?!.\" In our experiments, AQM outperforms comparative algorithms\nand makes human-like dialogue. We further use AQM as a tool for analyzing the\nmechanism of deep reinforcement learning approach and discuss the future\ndirection of practical goal-oriented neural dialogue systems.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue",
//  "year": 2018
//},
//{
//  "author": "[{'name': 'Tolga Bolukbasi'}, {'name': 'Kai-Wei Chang'}, {'name': 'Joseph Wang'}, {'name': 'Venkatesh Saligrama'}]",
//  "day": 28,
//  "id": "1602.08761v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1602.08761v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1602.08761v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "We study the problem of structured prediction under test-time budget\nconstraints. We propose a novel approach applicable to a wide range of\nstructured prediction problems in computer vision and natural language\nprocessing. Our approach seeks to adaptively generate computationally costly\nfeatures during test-time in order to reduce the computational cost of\nprediction while maintaining prediction performance. We show that training the\nadaptive feature generation system can be reduced to a series of structured\nlearning problems, resulting in efficient training using existing structured\nlearning algorithms. This framework provides theoretical justification for\nseveral existing heuristic approaches found in literature. We evaluate our\nproposed adaptive system on two structured prediction tasks, optical character\nrecognition (OCR) and dependency parsing and show strong performance in\nreduction of the feature costs without degrading accuracy.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Resource Constrained Structured Prediction",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Hongyuan Mei'}, {'name': 'Mohit Bansal'}, {'name': 'Matthew R. Walter'}]",
//  "day": 12,
//  "id": "1506.04089v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1506.04089v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1506.04089v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We propose a neural sequence-to-sequence model for direction following, a\ntask that is essential to realizing effective autonomous agents. Our\nalignment-based encoder-decoder model with long short-term memory recurrent\nneural networks (LSTM-RNN) translates natural language instructions to action\nsequences based upon a representation of the observable world state. We\nintroduce a multi-level aligner that empowers our model to focus on sentence\n\"regions\" salient to the current world state by using multiple abstractions of\nthe input sentence. In contrast to existing methods, our model uses no\nspecialized linguistic resources (e.g., parsers) or task-specific annotations\n(e.g., seed lexicons). It is therefore generalizable, yet still achieves the\nbest results reported to-date on a benchmark single-sentence dataset and\ncompetitive results for the limited-training multi-sentence setting. We analyze\nour model through a series of ablations that elucidate the contributions of the\nprimary components of our model.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to\n  Action Sequences",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Lili Mou'}, {'name': 'Zhengdong Lu'}, {'name': 'Hang Li'}, {'name': 'Zhi Jin'}]",
//  "day": 8,
//  "id": "1612.02741v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1612.02741v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1612.02741v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Building neural networks to query a knowledge base (a table) with natural\nlanguage is an emerging research topic in deep learning. An executor for table\nquerying typically requires multiple steps of execution because queries may\nhave complicated structures. In previous studies, researchers have developed\neither fully distributed executors or symbolic executors for table querying. A\ndistributed executor can be trained in an end-to-end fashion, but is weak in\nterms of execution efficiency and explicit interpretability. A symbolic\nexecutor is efficient in execution, but is very difficult to train especially\nat initial stages. In this paper, we propose to couple distributed and symbolic\nexecution for natural language queries, where the symbolic executor is\npretrained with the distributed executor's intermediate execution results in a\nstep-by-step fashion. Experiments show that our approach significantly\noutperforms both distributed and symbolic executors, exhibiting high accuracy,\nhigh learning efficiency, high execution efficiency, and high interpretability.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.SE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Coupling Distributed and Symbolic Execution for Natural Language Queries",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Christian Napoli'}, {'name': 'Giuseppe Pappalardo'}, {'name': 'Emiliano Tramontana'}]",
//  "day": 30,
//  "id": "1409.8484v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.13140/2.1.1446.7843', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.8484v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.8484v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Due to the huge availability of documents in digital form, and the deception\npossibility raise bound to the essence of digital documents and the way they\nare spread, the authorship attribution problem has constantly increased its\nrelevance. Nowadays, authorship attribution,for both information retrieval and\nanalysis, has gained great importance in the context of security, trust and\ncopyright preservation. This work proposes an innovative multi-agent driven\nmachine learning technique that has been developed for authorship attribution.\nBy means of a preprocessing for word-grouping and time-period related analysis\nof the common lexicon, we determine a bias reference level for the recurrence\nfrequency of the words within analysed texts, and then train a Radial Basis\nNeural Networks (RBPNN)-based classifier to identify the correct author. The\nmain advantage of the proposed approach lies in the generality of the semantic\nanalysis, which can be applied to different contexts and lexical domains,\nwithout requiring any modification. Moreover, the proposed system is able to\nincorporate an external input, meant to tune the classifier, and then\nself-adjust by means of continuous learning reinforcement.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.MA', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '68T01, 68T05, 68T10, 68T50, 68U15', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'C.2.1; I.2.6; I.2.7', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "An agent-driven semantical identifier using radial basis neural networks\n  and reinforcement learning",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Karla Stepanova'}, {'name': 'Matej Hoffmann'}, {'name': 'Zdenek Straka'}, {'name': 'Frederico B. Klein'}, {'name': 'Angelo Cangelosi'}, {'name': 'Michal Vavrecka'}]",
//  "day": 8,
//  "id": "1706.02490v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.02490v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.02490v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Humans and animals are constantly exposed to a continuous stream of sensory\ninformation from different modalities. At the same time, they form more\ncompressed representations like concepts or symbols. In species that use\nlanguage, this process is further structured by this interaction, where a\nmapping between the sensorimotor concepts and linguistic elements needs to be\nestablished. There is evidence that children might be learning language by\nsimply disambiguating potential meanings based on multiple exposures to\nutterances in different contexts (cross-situational learning). In existing\nmodels, the mapping between modalities is usually found in a single step by\ndirectly using frequencies of referent and meaning co-occurrences. In this\npaper, we present an extension of this one-step mapping and introduce a newly\nproposed sequential mapping algorithm together with a publicly available Matlab\nimplementation. For demonstration, we have chosen a less typical scenario:\ninstead of learning to associate objects with their names, we focus on body\nrepresentations. A humanoid robot is receiving tactile stimulations on its\nbody, while at the same time listening to utterances of the body part names\n(e.g., hand, forearm and torso). With the goal at arriving at the correct \"body\ncategories\", we demonstrate how a sequential mapping algorithm outperforms\none-step mapping. In addition, the effect of data set size and noise in the\nlinguistic input are studied.",
//  "tag": "[{'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.RO', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Where is my forearm? Clustering of body parts from simultaneous tactile\n  and linguistic input using sequential mapping",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Tara N. Sainath'}, {'name': 'Brian Kingsbury'}, {'name': 'Abdel-rahman Mohamed'}, {'name': 'George E. Dahl'}, {'name': 'George Saon'}, {'name': 'Hagen Soltau'}, {'name': 'Tomas Beran'}, {'name': 'Aleksandr Y. Aravkin'}, {'name': 'Bhuvana Ramabhadran'}]",
//  "day": 5,
//  "id": "1309.1501v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1309.1501v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1309.1501v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Deep Convolutional Neural Networks (CNNs) are more powerful than Deep Neural\nNetworks (DNN), as they are able to better reduce spectral variation in the\ninput signal. This has also been confirmed experimentally, with CNNs showing\nimprovements in word error rate (WER) between 4-12% relative compared to DNNs\nacross a variety of LVCSR tasks. In this paper, we describe different methods\nto further improve CNN performance. First, we conduct a deep analysis comparing\nlimited weight sharing and full weight sharing with state-of-the-art features.\nSecond, we apply various pooling strategies that have shown improvements in\ncomputer vision to an LVCSR speech task. Third, we introduce a method to\neffectively incorporate speaker adaptation, namely fMLLR, into log-mel\nfeatures. Fourth, we introduce an effective strategy to use dropout during\nHessian-free sequence training. We find that with these improvements,\nparticularly with fMLLR and dropout, we are able to achieve an additional 2-3%\nrelative improvement in WER on a 50-hour Broadcast News task over our previous\nbest CNN baseline. On a larger 400-hour BN task, we find an additional 4-5%\nrelative improvement over our previous best CNN baseline.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '65K05, 90C15, 90C90', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Improvements to deep convolutional neural networks for LVCSR",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Hao Wang'}, {'name': 'Naiyan Wang'}, {'name': 'Dit-Yan Yeung'}]",
//  "day": 10,
//  "id": "1409.2944v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.2944v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.2944v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Collaborative filtering (CF) is a successful approach commonly used by many\nrecommender systems. Conventional CF-based methods use the ratings given to\nitems by users as the sole source of information for learning to make\nrecommendation. However, the ratings are often very sparse in many\napplications, causing CF-based methods to degrade significantly in their\nrecommendation performance. To address this sparsity problem, auxiliary\ninformation such as item content information may be utilized. Collaborative\ntopic regression (CTR) is an appealing recent method taking this approach which\ntightly couples the two components that learn from two different sources of\ninformation. Nevertheless, the latent representation learned by CTR may not be\nvery effective when the auxiliary information is very sparse. To address this\nproblem, we generalize recent advances in deep learning from i.i.d. input to\nnon-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian\nmodel called collaborative deep learning (CDL), which jointly performs deep\nrepresentation learning for the content information and collaborative filtering\nfor the ratings (feedback) matrix. Extensive experiments on three real-world\ndatasets from different domains show that CDL can significantly advance the\nstate of the art.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Collaborative Deep Learning for Recommender Systems",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Leila Arras'}, {'name': 'Franziska Horn'}, {'name': 'Gr\u00e9goire Montavon'}, {'name': 'Klaus-Robert M\u00fcller'}, {'name': 'Wojciech Samek'}]",
//  "day": 23,
//  "id": "1606.07298v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.07298v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.07298v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Layer-wise relevance propagation (LRP) is a recently proposed technique for\nexplaining predictions of complex non-linear classifiers in terms of input\nvariables. In this paper, we apply LRP for the first time to natural language\nprocessing (NLP). More precisely, we use it to explain the predictions of a\nconvolutional neural network (CNN) trained on a topic categorization task. Our\nanalysis highlights which words are relevant for a specific prediction of the\nCNN. We compare our technique to standard sensitivity analysis, both\nqualitatively and quantitatively, using a \"word deleting\" perturbation\nexperiment, a PCA analysis, and various visualizations. All experiments\nvalidate the suitability of LRP for explaining the CNN predictions, which is\nalso in line with results reported in recent image classification studies.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Explaining Predictions of Non-Linear Classifiers in NLP",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Vasily Pestun'}, {'name': 'Yiannis Vlassopoulos'}]",
//  "day": 27,
//  "id": "1710.10248v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.10248v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.10248v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "We propose a new statistical model suitable for machine learning of systems\nwith long distance correlations such as natural languages. The model is based\non directed acyclic graph decorated by multi-linear tensor maps in the vertices\nand vector spaces in the edges, called tensor network. Such tensor networks\nhave been previously employed for effective numerical computation of the\nrenormalization group flow on the space of effective quantum field theories and\nlattice models of statistical mechanics. We provide explicit algebro-geometric\nanalysis of the parameter moduli space for tree graphs, discuss model\nproperties and applications such as statistical translation.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.dis-nn', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Tensor network language model",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Vasily Pestun'}, {'name': 'John Terilla'}, {'name': 'Yiannis Vlassopoulos'}]",
//  "day": 4,
//  "id": "1711.01416v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.01416v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.01416v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We propose a statistical model for natural language that begins by\nconsidering language as a monoid, then representing it in complex matrices with\na compatible translation invariant probability measure. We interpret the\nprobability measure as arising via the Born rule from a translation invariant\nmatrix product state.",
//  "tag": "[{'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cond-mat.dis-nn', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Language as a matrix product state",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Tara N. Sainath'}, {'name': 'Lior Horesh'}, {'name': 'Brian Kingsbury'}, {'name': 'Aleksandr Y. Aravkin'}, {'name': 'Bhuvana Ramabhadran'}]",
//  "day": 5,
//  "id": "1309.1508v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1309.1508v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1309.1508v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Hessian-free training has become a popular parallel second or- der\noptimization technique for Deep Neural Network training. This study aims at\nspeeding up Hessian-free training, both by means of decreasing the amount of\ndata used for training, as well as through reduction of the number of Krylov\nsubspace solver iterations used for implicit estimation of the Hessian. In this\npaper, we develop an L-BFGS based preconditioning scheme that avoids the need\nto access the Hessian explicitly. Since L-BFGS cannot be regarded as a\nfixed-point iteration, we further propose the employment of flexible Krylov\nsubspace solvers that retain the desired theoretical convergence guarantees of\ntheir conventional counterparts. Second, we propose a new sampling algorithm,\nwhich geometrically increases the amount of data utilized for gradient and\nKrylov subspace iteration calculations. On a 50-hr English Broadcast News task,\nwe find that these methodologies provide roughly a 1.5x speed-up, whereas, on a\n300-hr Switchboard task, these techniques provide over a 2.3x speedup, with no\nloss in WER. These results suggest that even further speed-up is expected, as\nproblems scale and complexity grows.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'math.OC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '65K05, 90C15, 90C90', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Accelerating Hessian-free optimization for deep neural networks by\n  implicit preconditioning and sampling",
//  "year": 2013
//},
//{
//  "author": "[{'name': 'Roberto Camacho Barranco'}, {'name': 'Laura M. Rodriguez'}, {'name': 'Rebecca Urbina'}, {'name': 'M. Shahriar Hossain'}]",
//  "day": 23,
//  "id": "1606.07496v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1606.07496v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1606.07496v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "While textual reviews have become prominent in many recommendation-based\nsystems, automated frameworks to provide relevant visual cues against text\nreviews where pictures are not available is a new form of task confronted by\ndata mining and machine learning researchers. Suggestions of pictures that are\nrelevant to the content of a review could significantly benefit the users by\nincreasing the effectiveness of a review. We propose a deep learning-based\nframework to automatically: (1) tag the images available in a review dataset,\n(2) generate a caption for each image that does not have one, and (3) enhance\neach review by recommending relevant images that might not be uploaded by the\ncorresponding reviewer. We evaluate the proposed framework using the Yelp\nChallenge Dataset. While a subset of the images in this particular dataset are\ncorrectly captioned, the majority of the pictures do not have any associated\ntext. Moreover, there is no mapping between reviews and images. Each image has\na corresponding business-tag where the picture was taken, though. The overall\ndata setting and unavailability of crucial pieces required for a mapping make\nthe problem of recommending images for reviews a major challenge. Qualitative\nand quantitative evaluations indicate that our proposed framework provides high\nquality enhancements through automatic captioning, tagging, and recommendation\nfor mapping reviews and images.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.IR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.NE', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'H.2.8; H.3.3; I.2.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Is a Picture Worth Ten Thousand Words in a Review Dataset?",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Matthias Scholz'}]",
//  "day": 3,
//  "id": "1204.0684v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1007/s11063-012-9220-6', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1204.0684v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1204.0684v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Linear principal component analysis (PCA) can be extended to a nonlinear PCA\nby using artificial neural networks. But the benefit of curved components\nrequires a careful control of the model complexity. Moreover, standard\ntechniques for model selection, including cross-validation and more generally\nthe use of an independent test set, fail when applied to nonlinear PCA because\nof its inherent unsupervised characteristics. This paper presents a new\napproach for validating the complexity of nonlinear PCA models by using the\nerror in missing data estimation as a criterion for model selection. It is\nmotivated by the idea that only the model of optimal complexity is able to\npredict missing values with the highest accuracy. While standard test set\nvalidation usually favours over-fitted nonlinear PCA models, the proposed model\nvalidation approach correctly selects the optimal model complexity.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Validation of nonlinear PCA",
//  "year": 2012
//},
//{
//  "author": "[{'name': 'Ethan Fetaya'}, {'name': 'Ohad Shamir'}, {'name': 'Shimon Ullman'}]",
//  "day": 10,
//  "id": "1406.2602v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1406.2602v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1406.2602v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "We consider the problem of learning from a similarity matrix (such as\nspectral clustering and lowd imensional embedding), when computing pairwise\nsimilarities are costly, and only a limited number of entries can be observed.\nWe provide a theoretical analysis using standard notions of graph\napproximation, significantly generalizing previous results (which focused on\nspectral clustering with two clusters). We also propose a new algorithmic\napproach based on adaptive sampling, which experimentally matches or improves\non previous methods, while being considerably more general and computationally\ncheaper.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Graph Approximation and Clustering on a Budget",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Shai Shalev-Shwartz'}, {'name': 'Yonatan Wexler'}, {'name': 'Amnon Shashua'}]",
//  "day": 5,
//  "id": "1109.0820v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1109.0820v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1109.0820v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Multiclass prediction is the problem of classifying an object into a relevant\ntarget class. We consider the problem of learning a multiclass predictor that\nuses only few features, and in particular, the number of used features should\nincrease sub-linearly with the number of possible classes. This implies that\nfeatures should be shared by several classes. We describe and analyze the\nShareBoost algorithm for learning a multiclass predictor that uses few shared\nfeatures. We prove that ShareBoost efficiently finds a predictor that uses few\nshared features (if such a predictor exists) and that it has a small\ngeneralization error. We also describe how to use ShareBoost for learning a\nnon-linear predictor that has a fast evaluation time. In a series of\nexperiments with natural data sets we demonstrate the benefits of ShareBoost\nand evaluate its success relatively to other state-of-the-art approaches.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "ShareBoost: Efficient Multiclass Learning with Feature Sharing",
//  "year": 2011
//},
//{
//  "author": "[{'name': 'Nan Lin'}, {'name': 'Junhai Jiang'}, {'name': 'Shicheng Guo'}, {'name': 'Momiao Xiong'}]",
//  "day": 1,
//  "id": "1408.0204v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1371/journal.pone.0132945', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1408.0204v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1408.0204v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Due to advances in sensors, growing large and complex medical image data have\nthe ability to visualize the pathological change in the cellular or even the\nmolecular level or anatomical changes in tissues and organs. As a consequence,\nthe medical images have the potential to enhance diagnosis of disease,\nprediction of clinical outcomes, characterization of disease progression,\nmanagement of health care and development of treatments, but also pose great\nmethodological and computational challenges for representation and selection of\nfeatures in image cluster analysis. To address these challenges, we first\nextend one dimensional functional principal component analysis to the two\ndimensional functional principle component analyses (2DFPCA) to fully capture\nspace variation of image signals. Image signals contain a large number of\nredundant and irrelevant features which provide no additional or no useful\ninformation for cluster analysis. Widely used methods for removing redundant\nand irrelevant features are sparse clustering algorithms using a lasso-type\npenalty to select the features. However, the accuracy of clustering using a\nlasso-type penalty depends on how to select penalty parameters and a threshold\nfor selecting features. In practice, they are difficult to determine. Recently,\nrandomized algorithms have received a great deal of attention in big data\nanalysis. This paper presents a randomized algorithm for accurate feature\nselection in image cluster analysis. The proposed method is applied to ovarian\nand kidney cancer histology image data from the TCGA database. The results\ndemonstrate that the randomized feature selection method coupled with\nfunctional principal component analysis substantially outperforms the current\nsparse clustering algorithms in image cluster analysis.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Functional Principal Component Analysis and Randomized Sparse Clustering\n  Algorithm for Medical Image Analysis",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Liwen Zhang'}, {'name': 'Subhransu Maji'}, {'name': 'Ryota Tomioka'}]",
//  "day": 5,
//  "id": "1503.01521v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1503.01521v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1503.01521v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Similarity between objects is multi-faceted and it can be easier for human\nannotators to measure it when the focus is on a specific aspect. We consider\nthe problem of mapping objects into view-specific embeddings where the distance\nbetween them is consistent with the similarity comparisons of the form \"from\nthe t-th view, object A is more similar to B than to C\". Our framework jointly\nlearns view-specific embeddings exploiting correlations between views.\nExperiments on a number of datasets, including one of multi-view crowdsourced\ncomparison on bird images, show the proposed method achieves lower triplet\ngeneralization error when compared to both learning embeddings independently\nfor each view and all views pooled into one view. Our method can also be used\nto learn multiple measures of similarity over input features taking class\nlabels into account and compares favorably to existing approaches for\nmulti-task metric learning on the ISOLET dataset.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Jointly Learning Multiple Measures of Similarities from Triplet\n  Comparisons",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Andreas C. Damianou'}, {'name': 'Michalis K. Titsias'}, {'name': 'Neil D. Lawrence'}]",
//  "day": 8,
//  "id": "1409.2287v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1409.2287v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1409.2287v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "The Gaussian process latent variable model (GP-LVM) provides a flexible\napproach for non-linear dimensionality reduction that has been widely applied.\nHowever, the current approach for training GP-LVMs is based on maximum\nlikelihood, where the latent projection variables are maximized over rather\nthan integrated out. In this paper we present a Bayesian method for training\nGP-LVMs by introducing a non-standard variational inference framework that\nallows to approximately integrate out the latent variables and subsequently\ntrain a GP-LVM by maximizing an analytic lower bound on the exact marginal\nlikelihood. We apply this method for learning a GP-LVM from iid observations\nand for learning non-linear dynamical systems where the observations are\ntemporally correlated. We show that a benefit of the variational Bayesian\nprocedure is its robustness to overfitting and its ability to automatically\nselect the dimensionality of the nonlinear latent space. The resulting\nframework is generic, flexible and easy to extend for other purposes, such as\nGaussian process regression with uncertain inputs and semi-supervised Gaussian\nprocesses. We demonstrate our method on synthetic data and standard machine\nlearning benchmarks, as well as challenging real world datasets, including high\nresolution video data.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': '60G15 (Primary), 58E30', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'G.3; G.1.2; I.2.6; I.5.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Variational Inference for Uncertainty on the Inputs of Gaussian Process\n  Models",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Mehdi Mirza'}, {'name': 'Simon Osindero'}]",
//  "day": 6,
//  "id": "1411.1784v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1411.1784v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1411.1784v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Generative Adversarial Nets [8] were recently introduced as a novel way to\ntrain generative models. In this work we introduce the conditional version of\ngenerative adversarial nets, which can be constructed by simply feeding the\ndata, y, we wish to condition on to both the generator and discriminator. We\nshow that this model can generate MNIST digits conditioned on class labels. We\nalso illustrate how this model could be used to learn a multi-modal model, and\nprovide preliminary examples of an application to image tagging in which we\ndemonstrate how this approach can generate descriptive tags which are not part\nof training labels.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Conditional Generative Adversarial Nets",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Krzysztof Chalupka'}, {'name': 'Pietro Perona'}, {'name': 'Frederick Eberhardt'}]",
//  "day": 7,
//  "id": "1412.2309v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.2309v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.2309v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We provide a rigorous definition of the visual cause of a behavior that is\nbroadly applicable to the visually driven behavior in humans, animals, neurons,\nrobots and other perceiving systems. Our framework generalizes standard\naccounts of causal learning to settings in which the causal variables need to\nbe constructed from micro-variables. We prove the Causal Coarsening Theorem,\nwhich allows us to gain causal knowledge from observational data with minimal\nexperimental effort. The theorem provides a connection to standard inference\ntechniques in machine learning that identify features of an image that\ncorrelate with, but may not cause, the target behavior. Finally, we propose an\nactive learning scheme to learn a manipulator function that performs optimal\nmanipulations on the image to automatically identify the visual cause of a\ntarget behavior. We illustrate our inference and learning algorithms in\nexperiments based on both synthetic and real data.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Visual Causal Feature Learning",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Behnam Neyshabur'}, {'name': 'Ryota Tomioka'}, {'name': 'Nathan Srebro'}]",
//  "day": 20,
//  "id": "1412.6614v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1412.6614v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1412.6614v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "We present experiments demonstrating that some other form of capacity\ncontrol, different from network size, plays a central role in learning\nmultilayer feed-forward networks. We argue, partially through analogy to matrix\nfactorization, that this is an inductive bias that can help shed light on deep\nlearning.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "In Search of the Real Inductive Bias: On the Role of Implicit\n  Regularization in Deep Learning",
//  "year": 2014
//},
//{
//  "author": "[{'name': 'Muhammad Ghifary'}, {'name': 'W. Bastiaan Kleijn'}, {'name': 'Mengjie Zhang'}, {'name': 'David Balduzzi'}]",
//  "day": 31,
//  "id": "1508.07680v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1508.07680v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1508.07680v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "The problem of domain generalization is to take knowledge acquired from a\nnumber of related domains where training data is available, and to then\nsuccessfully apply it to previously unseen domains. We propose a new feature\nlearning algorithm, Multi-Task Autoencoder (MTAE), that provides good\ngeneralization performance for cross-domain object recognition.\n  Our algorithm extends the standard denoising autoencoder framework by\nsubstituting artificially induced corruption with naturally occurring\ninter-domain variability in the appearance of objects. Instead of\nreconstructing images from noisy versions, MTAE learns to transform the\noriginal image into analogs in multiple related domains. It thereby learns\nfeatures that are robust to variations across domains. The learnt features are\nthen used as inputs to a classifier.\n  We evaluated the performance of the algorithm on benchmark image recognition\ndatasets, where the task is to learn features from multiple datasets and to\nthen predict the image label from unseen datasets. We found that (denoising)\nMTAE outperforms alternative autoencoder-based models as well as the current\nstate-of-the-art algorithms for domain generalization.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Domain Generalization for Object Recognition with Multi-task\n  Autoencoders",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'John-Alexander M. Assael'}, {'name': 'Niklas Wahlstr\u00f6m'}, {'name': 'Thomas B. Sch\u00f6n'}, {'name': 'Marc Peter Deisenroth'}]",
//  "day": 8,
//  "id": "1510.02173v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.02173v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.02173v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Data-efficient reinforcement learning (RL) in continuous state-action spaces\nusing very high-dimensional observations remains a key challenge in developing\nfully autonomous systems. We consider a particularly important instance of this\nchallenge, the pixels-to-torques problem, where an RL agent learns a\nclosed-loop control policy (\"torques\") from pixel information only. We\nintroduce a data-efficient, model-based reinforcement learning algorithm that\nlearns such a closed-loop policy directly from pixel information. The key\ningredient is a deep dynamical model for learning a low-dimensional feature\nembedding of images jointly with a predictive model in this low-dimensional\nfeature space. Joint learning is crucial for long-term predictions, which lie\nat the core of the adaptive nonlinear model predictive control strategy that we\nuse for closed-loop control. Compared to state-of-the-art RL methods for\ncontinuous states and actions, our approach learns quickly, scales to\nhigh-dimensional state spaces, is lightweight and an important step toward\nfully autonomous end-to-end learning from pixels to torques.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Data-Efficient Learning of Feedback Policies from Image Pixels using\n  Deep Dynamical Models",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Muhammad Ghifary'}, {'name': 'David Balduzzi'}, {'name': 'W. Bastiaan Kleijn'}, {'name': 'Mengjie Zhang'}]",
//  "day": 15,
//  "id": "1510.04373v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.04373v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.04373v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "This paper addresses classification tasks on a particular target domain in\nwhich labeled training data are only available from source domains different\nfrom (but related to) the target. Two closely related frameworks, domain\nadaptation and domain generalization, are concerned with such tasks, where the\nonly difference between those frameworks is the availability of the unlabeled\ntarget data: domain adaptation can leverage unlabeled target information, while\ndomain generalization cannot. We propose Scatter Component Analyis (SCA), a\nfast representation learning algorithm that can be applied to both domain\nadaptation and domain generalization. SCA is based on a simple geometrical\nmeasure, i.e., scatter, which operates on reproducing kernel Hilbert space. SCA\nfinds a representation that trades between maximizing the separability of\nclasses, minimizing the mismatch between domains, and maximizing the\nseparability of data; each of which is quantified through scatter. The\noptimization problem of SCA can be reduced to a generalized eigenvalue problem,\nwhich results in a fast and exact solution. Comprehensive experiments on\nbenchmark cross-domain object recognition datasets verify that SCA performs\nmuch faster than several state-of-the-art algorithms and also provides\nstate-of-the-art classification accuracy in both domain adaptation and domain\ngeneralization. We also show that scatter can be used to establish a\ntheoretical generalization bound in the case of domain adaptation.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'I.2.6; I.4', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Scatter Component Analysis: A Unified Framework for Domain Adaptation\n  and Domain Generalization",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Zhao Kang'}, {'name': 'Chong Peng'}, {'name': 'Qiang Cheng'}]",
//  "day": 30,
//  "id": "1510.08971v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1145/2806416.2806506', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1510.08971v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1510.08971v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Matrix rank minimization problem is in general NP-hard. The nuclear norm is\nused to substitute the rank function in many recent studies. Nevertheless, the\nnuclear norm approximation adds all singular values together and the\napproximation error may depend heavily on the magnitudes of singular values.\nThis might restrict its capability in dealing with many practical problems. In\nthis paper, an arctangent function is used as a tighter approximation to the\nrank function. We use it on the challenging subspace clustering problem. For\nthis nonconvex minimization problem, we develop an effective optimization\nprocedure based on a type of augmented Lagrange multipliers (ALM) method.\nExtensive experiments on face clustering and motion segmentation show that the\nproposed method is effective for rank approximation.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Robust Subspace Clustering via Tighter Rank Approximation",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Amogh Gudi'}]",
//  "day": 2,
//  "id": "1512.00743v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1512.00743v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1512.00743v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "The human face constantly conveys information, both consciously and\nsubconsciously. However, as basic as it is for humans to visually interpret\nthis information, it is quite a big challenge for machines. Conventional\nsemantic facial feature recognition and analysis techniques are already in use\nand are based on physiological heuristics, but they suffer from lack of\nrobustness and high computation time. This thesis aims to explore ways for\nmachines to learn to interpret semantic information available in faces in an\nautomated manner without requiring manual design of feature detectors, using\nthe approach of Deep Learning. This thesis provides a study of the effects of\nvarious factors and hyper-parameters of deep neural networks in the process of\ndetermining an optimal network configuration for the task of semantic facial\nfeature recognition. This thesis explores the effectiveness of the system to\nrecognize the various semantic features (like emotions, age, gender, ethnicity\netc.) present in faces. Furthermore, the relation between the effect of\nhigh-level concepts on low level features is explored through an analysis of\nthe similarities in low-level descriptors of different semantic features. This\nthesis also demonstrates a novel idea of using a deep network to generate 3-D\nActive Appearance Models of faces from real-world 2-D images.\n  For a more detailed report on this work, please see [arXiv:1512.00743v1].",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Recognizing Semantic Features in Faces using Deep Learning",
//  "year": 2015
//},
//{
//  "author": "[{'name': 'Muhammad Ghifary'}, {'name': 'W. Bastiaan Kleijn'}, {'name': 'Mengjie Zhang'}, {'name': 'David Balduzzi'}, {'name': 'Wen Li'}]",
//  "day": 12,
//  "id": "1607.03516v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1607.03516v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1607.03516v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "In this paper, we propose a novel unsupervised domain adaptation algorithm\nbased on deep learning for visual object recognition. Specifically, we design a\nnew model called Deep Reconstruction-Classification Network (DRCN), which\njointly learns a shared encoding representation for two tasks: i) supervised\nclassification of labeled source data, and ii) unsupervised reconstruction of\nunlabeled target data.In this way, the learnt representation not only preserves\ndiscriminability, but also encodes useful information from the target domain.\nOur new DRCN model can be optimized by using backpropagation similarly as the\nstandard neural networks.\n  We evaluate the performance of DRCN on a series of cross-domain object\nrecognition tasks, where DRCN provides a considerable improvement (up to ~8% in\naccuracy) over the prior state-of-the-art algorithms. Interestingly, we also\nobserve that the reconstruction pipeline of DRCN transforms images from the\nsource domain into images whose appearance resembles the target dataset. This\nsuggests that DRCN's performance is due to constructing a single composite\nrepresentation that encodes information about both the structure of target\nimages and the classification of source images. Finally, we provide a formal\nanalysis to justify the algorithm's objective in domain adaptation context.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Reconstruction-Classification Networks for Unsupervised Domain\n  Adaptation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Po-Hsuan Chen'}, {'name': 'Xia Zhu'}, {'name': 'Hejia Zhang'}, {'name': 'Javier S. Turek'}, {'name': 'Janice Chen'}, {'name': 'Theodore L. Willke'}, {'name': 'Uri Hasson'}, {'name': 'Peter J. Ramadge'}]",
//  "day": 17,
//  "id": "1608.04846v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.04846v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.04846v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Finding the most effective way to aggregate multi-subject fMRI data is a\nlong-standing and challenging problem. It is of increasing interest in\ncontemporary fMRI studies of human cognition due to the scarcity of data per\nsubject and the variability of brain anatomy and functional response across\nsubjects. Recent work on latent factor models shows promising results in this\ntask but this approach does not preserve spatial locality in the brain. We\nexamine two ways to combine the ideas of a factor model and a searchlight based\nanalysis to aggregate multi-subject fMRI data while preserving spatial\nlocality. We first do this directly by combining a recent factor method known\nas a shared response model with searchlight analysis. Then we design a\nmulti-view convolutional autoencoder for the same task. Both approaches\npreserve spatial locality and have competitive or better performance compared\nwith standard searchlight analysis and the shared response model applied across\nthe whole brain. We also report a system design to handle the computational\nchallenge of training the convolutional autoencoder.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Convolutional Autoencoder for Multi-Subject fMRI Data Aggregation",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yun Wang'}, {'name': 'Xu Chen'}, {'name': 'Peter J. Ramadge'}]",
//  "day": 21,
//  "id": "1608.06010v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.06010v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.06010v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "One way to solve lasso problems when the dictionary does not fit into\navailable memory is to first screen the dictionary to remove unneeded features.\nPrior research has shown that sequential screening methods offer the greatest\npromise in this endeavor. Most existing work on sequential screening targets\nthe context of tuning parameter selection, where one screens and solves a\nsequence of $N$ lasso problems with a fixed grid of geometrically spaced\nregularization parameters. In contrast, we focus on the scenario where a target\nregularization parameter has already been chosen via cross-validated model\nselection, and we then need to solve many lasso instances using this fixed\nvalue. In this context, we propose and explore a feedback controlled sequential\nscreening scheme. Feedback is used at each iteration to select the next problem\nto be solved. This allows the sequence of problems to be adapted to the\ninstance presented and the number of intermediate problems to be automatically\nselected. We demonstrate our feedback scheme using several datasets including a\ndictionary of approximate size 100,000 by 300,000.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Feedback-Controlled Sequential Lasso Screening",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Yun Wang'}, {'name': 'Peter J. Ramadge'}]",
//  "day": 21,
//  "id": "1608.06014v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.06014v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.06014v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Recently dictionary screening has been proposed as an effective way to\nimprove the computational efficiency of solving the lasso problem, which is one\nof the most commonly used method for learning sparse representations. To\naddress today's ever increasing large dataset, effective screening relies on a\ntight region bound on the solution to the dual lasso. Typical region bounds are\nin the form of an intersection of a sphere and multiple half spaces. One way to\ntighten the region bound is using more half spaces, which however, adds to the\noverhead of solving the high dimensional optimization problem in lasso\nscreening. This paper reveals the interesting property that the optimization\nproblem only depends on the projection of features onto the subspace spanned by\nthe normals of the half spaces. This property converts an optimization problem\nin high dimension to much lower dimension, and thus sheds light on reducing the\ncomputation overhead of lasso screening based on tighter region bounds.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "The Symmetry of a Simple Optimization Problem in Lasso Screening",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Maxime Bucher'}, {'name': 'St\u00e9phane Herbin'}, {'name': 'Fr\u00e9d\u00e9ric Jurie'}]",
//  "day": 26,
//  "id": "1608.07441v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1608.07441v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1608.07441v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Zero-Shot learning has been shown to be an efficient strategy for domain\nadaptation. In this context, this paper builds on the recent work of Bucher et\nal. [1], which proposed an approach to solve Zero-Shot classification problems\n(ZSC) by introducing a novel metric learning based objective function. This\nobjective function allows to learn an optimal embedding of the attributes\njointly with a measure of similarity between images and attributes. This paper\nextends their approach by proposing several schemes to control the generation\nof the negative pairs, resulting in a significant improvement of the\nperformance and giving above state-of-the-art results on three challenging ZSC\ndatasets.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Hard Negative Mining for Metric Learning Based Zero-Shot Classification",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Xiang Xiang'}, {'name': 'Trac D. Tran'}]",
//  "day": 22,
//  "id": "1609.07042v4",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1609.07042v4', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1609.07042v4', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "In this paper, we deal with two challenges for measuring the similarity of\nthe subject identities in practical video-based face recognition - the\nvariation of the head pose in uncontrolled environments and the computational\nexpense of processing videos. Since the frame-wise feature mean is unable to\ncharacterize the pose diversity among frames, we define and preserve the\noverall pose diversity and closeness in a video. Then, identity will be the\nonly source of variation across videos since the pose varies even within a\nsingle video. Instead of simply using all the frames, we select those faces\nwhose pose point is closest to the centroid of the K-means cluster containing\nthat pose point. Then, we represent a video as a bag of frame-wise deep face\nfeatures while the number of features has been reduced from hundreds to K.\nSince the video representation can well represent the identity, now we measure\nthe subject similarity between two videos as the max correlation among all\npossible pairs in the two bags of features. On the official 5,000 video-pairs\nof the YouTube Face dataset for face verification, our algorithm achieves a\ncomparable performance with VGG-face that averages over deep features of all\nframes. Other vision tasks can also benefit from the generic idea of employing\ngeometric cues to improve the descriptiveness of deep features.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Pose-Selective Max Pooling for Measuring Similarity",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Shehroz S. Khan'}, {'name': 'Babak Taati'}]",
//  "day": 12,
//  "id": "1610.03761v3",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1016/j.eswa.2017.06.011', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.03761v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.03761v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "A fall is an abnormal activity that occurs rarely, so it is hard to collect\nreal data for falls. It is, therefore, difficult to use supervised learning\nmethods to automatically detect falls. Another challenge in using machine\nlearning methods to automatically detect falls is the choice of engineered\nfeatures. In this paper, we propose to use an ensemble of autoencoders to\nextract features from different channels of wearable sensor data trained only\non normal activities. We show that the traditional approach of choosing a\nthreshold as the maximum of the reconstruction error on the training normal\ndata is not the right way to identify unseen falls. We propose two methods for\nautomatic tightening of reconstruction error from only the normal activities\nfor better identification of unseen falls. We present our results on two\nactivity recognition datasets and show the efficacy of our proposed method\nagainst traditional autoencoder models and two standard one-class\nclassification methods.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Detecting Unseen Falls from Wearable Devices using Channel-wise Ensemble\n  of Autoencoders",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Jure Sokolic'}, {'name': 'Raja Giryes'}, {'name': 'Guillermo Sapiro'}, {'name': 'Miguel R. D. Rodrigues'}]",
//  "day": 14,
//  "id": "1610.04574v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.04574v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.04574v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "This paper studies the generalization error of invariant classifiers. In\nparticular, we consider the common scenario where the classification task is\ninvariant to certain transformations of the input, and that the classifier is\nconstructed (or learned) to be invariant to these transformations. Our approach\nrelies on factoring the input space into a product of a base space and a set of\ntransformations. We show that whereas the generalization error of a\nnon-invariant classifier is proportional to the complexity of the input space,\nthe generalization error of an invariant classifier is proportional to the\ncomplexity of the base space. We also derive a set of sufficient conditions on\nthe geometry of the base space and the set of transformations that ensure that\nthe complexity of the base space is much smaller than the complexity of the\ninput space. Our analysis applies to general classifiers such as convolutional\nneural networks. We demonstrate the implications of the developed theory for\nsuch classifiers with experiments on the MNIST and CIFAR-10 datasets.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Generalization Error of Invariant Classifiers",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Seyed-Mohsen Moosavi-Dezfooli'}, {'name': 'Alhussein Fawzi'}, {'name': 'Omar Fawzi'}, {'name': 'Pascal Frossard'}]",
//  "day": 26,
//  "id": "1610.08401v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1610.08401v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1610.08401v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "Given a state-of-the-art deep neural network classifier, we show the\nexistence of a universal (image-agnostic) and very small perturbation vector\nthat causes natural images to be misclassified with high probability. We\npropose a systematic algorithm for computing universal perturbations, and show\nthat state-of-the-art deep neural networks are highly vulnerable to such\nperturbations, albeit being quasi-imperceptible to the human eye. We further\nempirically analyze these universal perturbations and show, in particular, that\nthey generalize very well across neural networks. The surprising existence of\nuniversal perturbations reveals important geometric correlations among the\nhigh-dimensional decision boundary of classifiers. It further outlines\npotential security breaches with the existence of single directions in the\ninput space that adversaries can possibly exploit to break a classifier on most\nnatural images.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Universal adversarial perturbations",
//  "year": 2016
//},
//{
//  "author": "[{'name': 'Xiang Xiang'}, {'name': 'Trac D. Tran'}]",
//  "day": 11,
//  "id": "1701.03102v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1701.03102v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1701.03102v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 1,
//  "summary": "Limited annotated data available for the recognition of facial expression and\naction units embarrasses the training of deep networks, which can learn\ndisentangled invariant features. However, a linear model with just several\nparameters normally is not demanding in terms of training data. In this paper,\nwe propose an elegant linear model to untangle confounding factors in\nchallenging realistic multichannel signals such as 2D face videos. The simple\nyet powerful model does not rely on huge training data and is natural for\nrecognizing facial actions without explicitly disentangling the identity. Base\non well-understood intuitive linear models such as Sparse Representation based\nClassification (SRC), previous attempts require a prepossessing of explicit\ndecoupling which is practically inexact. Instead, we exploit the low-rank\nproperty across frames to subtract the underlying neutral faces which are\nmodeled jointly with sparse representation on the action components with group\nsparsity enforced. On the extended Cohn-Kanade dataset (CK+), our one-shot\nautomatic method on raw face videos performs as competitive as SRC applied on\nmanually prepared action components and performs even better than SRC in terms\nof true positive rate. We apply the model to the even more challenging task of\nfacial action unit recognition, verified on the MPI Face Video Database\n(MPI-VDB) achieving a decent performance. All the programs and data have been\nmade publicly available.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Linear Disentangled Representation Learning for Facial Actions",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jan Hendrik Metzen'}, {'name': 'Tim Genewein'}, {'name': 'Volker Fischer'}, {'name': 'Bastian Bischoff'}]",
//  "day": 14,
//  "id": "1702.04267v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1702.04267v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1702.04267v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 2,
//  "summary": "Machine learning and deep learning in particular has advanced tremendously on\nperceptual tasks in recent years. However, it remains vulnerable against\nadversarial perturbations of the input that have been crafted specifically to\nfool the system while being quasi-imperceptible to a human. In this work, we\npropose to augment deep neural networks with a small \"detector\" subnetwork\nwhich is trained on the binary classification task of distinguishing genuine\ndata from data containing adversarial perturbations. Our method is orthogonal\nto prior work on addressing adversarial perturbations, which has mostly focused\non making the classification network itself more robust. We show empirically\nthat adversarial perturbations can be detected surprisingly well even though\nthey are quasi-imperceptible to humans. Moreover, while the detectors have been\ntrained to detect only a specific adversary, they generalize to similar and\nweaker adversaries. In addition, we propose an adversarial attack that fools\nboth the classifier and the detector and a novel training procedure for the\ndetector that counteracts this attack.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "On Detecting Adversarial Perturbations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhiming Zhou'}, {'name': 'Han Cai'}, {'name': 'Shu Rong'}, {'name': 'Yuxuan Song'}, {'name': 'Kan Ren'}, {'name': 'Weinan Zhang'}, {'name': 'Yong Yu'}, {'name': 'Jun Wang'}]",
//  "day": 6,
//  "id": "1703.02000v7",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1703.02000v7', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1703.02000v7', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 3,
//  "summary": "Class labels have been empirically shown useful in improving the sample\nquality of generative adversarial nets (GANs). In this paper, we mathematically\nstudy the properties of the current variants of GANs that make use of class\nlabel information. With class aware gradient and cross-entropy decomposition,\nwe reveal how class labels and associated losses influence GAN's training.\nBased on that, we propose Activation Maximization Generative Adversarial\nNetworks (AM-GAN) as an advanced solution. Comprehensive experiments have been\nconducted to validate our analysis and evaluate the effectiveness of our\nsolution, where AM-GAN outperforms other strong baselines and achieves\nstate-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we\ndemonstrate that, with the Inception ImageNet classifier, Inception Score\nmainly tracks the diversity of the generator, and there is, however, no\nreliable evidence that it can reflect the true sample quality. We thus propose\na new metric, called AM Score, to provide more accurate estimation on the\nsample quality. Our proposed model also outperforms the baseline methods in the\nnew metric.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Activation Maximization Generative Adversarial Nets",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Ruth Fong'}, {'name': 'Andrea Vedaldi'}]",
//  "day": 11,
//  "id": "1704.03296v3",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/ICCV.2017.371', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.03296v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.03296v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "As machine learning algorithms are increasingly applied to high impact yet\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\ncritical that researchers can explain how such algorithms arrived at their\npredictions. In recent years, a number of image saliency methods have been\ndeveloped to summarize where highly complex neural networks \"look\" in an image\nfor evidence for their predictions. However, these techniques are limited by\ntheir heuristic nature and architectural constraints. In this paper, we make\ntwo main contributions: First, we propose a general framework for learning\ndifferent kinds of explanations for any black box algorithm. Second, we\nspecialise the framework to find the part of an image most responsible for a\nclassifier decision. Unlike previous works, our method is model-agnostic and\ntestable because it is grounded in explicit and interpretable image\nperturbations.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Hong Zhao'}]",
//  "day": 23,
//  "id": "1704.06885v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.06885v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.06885v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "Though the deep learning is pushing the machine learning to a new stage,\nbasic theories of machine learning are still limited. The principle of\nlearning, the role of the a prior knowledge, the role of neuron bias, and the\nbasis for choosing neural transfer function and cost function, etc., are still\nfar from clear. In this paper, we present a general theoretical framework for\nmachine learning. We classify the prior knowledge into common and\nproblem-dependent parts, and consider that the aim of learning is to maximally\nincorporate them. The principle we suggested for maximizing the former is the\ndesign risk minimization principle, while the neural transfer function, the\ncost function, as well as pretreatment of samples, are endowed with the role\nfor maximizing the latter. The role of the neuron bias is explained from a\ndifferent angle. We develop a Monte Carlo algorithm to establish the\ninput-output responses, and we control the input-output sensitivity of a\nlearning machine by controlling that of individual neurons. Applications of\nfunction approaching and smoothing, pattern recognition and classification, are\nprovided to illustrate how to train general learning machines based on our\ntheory and algorithm. Our method may in addition induce new applications, such\nas the transductive inference.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A General Theory for Training Learning Machine",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yotam Hechtlinger'}, {'name': 'Purvasha Chakravarti'}, {'name': 'Jining Qin'}]",
//  "day": 26,
//  "id": "1704.08165v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1704.08165v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1704.08165v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 4,
//  "summary": "This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) from low-dimensional grid data, such as images, to graph-structured\ndata. We propose a novel spatial convolution utilizing a random walk to uncover\nthe relations within the input, analogous to the way the standard convolution\nuses the spatial neighborhood of a pixel on the grid. The convolution has an\nintuitive interpretation, is efficient and scalable and can also be used on\ndata with varying graph structure. Furthermore, this generalization can be\napplied to many standard regression or classification problems, by learning the\nthe underlying graph. We empirically demonstrate the performance of the\nproposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular\nactivity data set.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Generalization of Convolutional Neural Networks to Graph-Structured\n  Data",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Matthias Hein'}, {'name': 'Maksym Andriushchenko'}]",
//  "day": 23,
//  "id": "1705.08475v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.08475v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.08475v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Recent work has shown that state-of-the-art classifiers are quite brittle, in\nthe sense that a small adversarial change of an originally with high confidence\ncorrectly classified input leads to a wrong classification again with high\nconfidence. This raises concerns that such classifiers are vulnerable to\nattacks and calls into question their usage in safety-critical systems. We show\nin this paper for the first time formal guarantees on the robustness of a\nclassifier by giving instance-specific lower bounds on the norm of the input\nmanipulation required to change the classifier decision. Based on this analysis\nwe propose the Cross-Lipschitz regularization functional. We show that using\nthis form of regularization in kernel methods resp. neural networks improves\nthe robustness of the classifier without any loss in prediction performance.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Formal Guarantees on the Robustness of a Classifier against Adversarial\n  Manipulation",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Alhussein Fawzi'}, {'name': 'Seyed-Mohsen Moosavi-Dezfooli'}, {'name': 'Pascal Frossard'}, {'name': 'Stefano Soatto'}]",
//  "day": 26,
//  "id": "1705.09552v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.09552v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.09552v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "The goal of this paper is to analyze the geometric properties of deep neural\nnetwork classifiers in the input space. We specifically study the topology of\nclassification regions created by deep networks, as well as their associated\ndecision boundary. Through a systematic empirical investigation, we show that\nstate-of-the-art deep nets learn connected classification regions, and that the\ndecision boundary in the vicinity of datapoints is flat along most directions.\nWe further draw an essential connection between two seemingly unrelated\nproperties of deep networks: their sensitivity to additive perturbations in the\ninputs, and the curvature of their decision boundary. The directions where the\ndecision boundary is curved in fact remarkably characterize the directions to\nwhich the classifier is the most vulnerable. We finally leverage a fundamental\nasymmetry in the curvature of the decision boundary of deep nets, and propose a\nmethod to discriminate between original images, and images perturbed with small\nadversarial examples. We show the effectiveness of this purely geometric\napproach for detecting small adversarial perturbations in images, and for\nrecovering the labels of perturbed images.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Classification regions of deep neural networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Seyed-Mohsen Moosavi-Dezfooli'}, {'name': 'Alhussein Fawzi'}, {'name': 'Omar Fawzi'}, {'name': 'Pascal Frossard'}, {'name': 'Stefano Soatto'}]",
//  "day": 26,
//  "id": "1705.09554v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.09554v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.09554v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Deep networks have recently been shown to be vulnerable to universal\nperturbations: there exist very small image-agnostic perturbations that cause\nmost natural images to be misclassified by such classifiers. In this paper, we\npropose the first quantitative analysis of the robustness of classifiers to\nuniversal perturbations, and draw a formal link between the robustness to\nuniversal perturbations, and the geometry of the decision boundary.\nSpecifically, we establish theoretical bounds on the robustness of classifiers\nunder two decision boundary models (flat and curved models). We show in\nparticular that the robustness of deep networks to universal perturbations is\ndriven by a key property of their curvature: there exists shared directions\nalong which the decision boundary of deep networks is systematically positively\ncurved. Under such conditions, we prove the existence of small universal\nperturbations. Our analysis further provides a novel geometric method for\ncomputing universal perturbations, in addition to explaining their properties.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Analysis of universal adversarial perturbations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yunus Saatchi'}, {'name': 'Andrew Gordon Wilson'}]",
//  "day": 26,
//  "id": "1705.09558v3",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.09558v3', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.09558v3', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "Generative adversarial networks (GANs) can implicitly learn rich\ndistributions over images, audio, and data which are hard to model with an\nexplicit likelihood. We present a practical Bayesian formulation for\nunsupervised and semi-supervised learning with GANs. Within this framework, we\nuse stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of\nthe generator and discriminator networks. The resulting approach is\nstraightforward and obtains good performance without any standard interventions\nsuch as feature matching, or mini-batch discrimination. By exploring an\nexpressive posterior over the parameters of the generator, the Bayesian GAN\navoids mode-collapse, produces interpretable and diverse candidate samples, and\nprovides state-of-the-art quantitative results for semi-supervised learning on\nbenchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN,\nWasserstein GANs, and DCGAN ensembles.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Bayesian GAN",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Emily Denton'}, {'name': 'Vighnesh Birodkar'}]",
//  "day": 31,
//  "id": "1705.10915v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1705.10915v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1705.10915v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 5,
//  "summary": "We present a new model DrNET that learns disentangled image representations\nfrom video. Our approach leverages the temporal coherence of video and a novel\nadversarial loss to learn a representation that factorizes each frame into a\nstationary part and a temporally varying component. The disentangled\nrepresentation can be used for a range of tasks. For example, applying a\nstandard LSTM to the time-vary components enables prediction of future frames.\nWe evaluate our approach on a range of synthetic and real videos, demonstrating\nthe ability to coherently generate hundreds of steps into the future.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Unsupervised Learning of Disentangled Representations from Video",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Yujia Li'}, {'name': 'Alexander Schwing'}, {'name': 'Kuan-Chieh Wang'}, {'name': 'Richard Zemel'}]",
//  "day": 19,
//  "id": "1706.06216v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.06216v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.06216v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 6,
//  "summary": "Generative adversarial nets (GANs) are a promising technique for modeling a\ndistribution from samples. It is however well known that GAN training suffers\nfrom instability due to the nature of its maximin formulation. In this paper,\nwe explore ways to tackle the instability problem by dualizing the\ndiscriminator. We start from linear discriminators in which case conjugate\nduality provides a mechanism to reformulate the saddle point objective into a\nmaximization problem, such that both the generator and the discriminator of\nthis 'dualing GAN' act in concert. We then demonstrate how to extend this\nintuition to non-linear formulations. For GANs with linear discriminators our\napproach is able to remove the instability in training, while for GANs with\nnonlinear discriminators our approach provides an alternative to the commonly\nused GAN training algorithm.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Dualing GANs",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Eunhee Kang'}, {'name': 'Jaejun Yoo'}, {'name': 'Jong Chul Ye'}]",
//  "day": 31,
//  "id": "1707.09938v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1707.09938v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1707.09938v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 7,
//  "summary": "Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\nare computationally expensive. To address this problem, we recently proposed\nthe world-first deep convolutional neural network (CNN) for low-dose X-ray CT\nand won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However,\nsome of the texture were not fully recovered. To cope with this problem, here\nwe propose a deep residual learning approach in directional wavelet domain. The\nproposed method is motivated by an observation that a deep convolutional neural\nnetwork can be interpreted as a multilayer convolutional framelets expansion\nusing non-local basis convolved with data-driven local basis. We further extend\nthe idea to derive a deep convolutional framelet expansion by combining global\nredundant transforms and signal boosting from multiple signal representations.\nExtensive experimental results confirm that the proposed network has\nsignificantly improved performance and preserves the detail texture of the\noriginal images",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Wavelet Residual Network for Low-Dose CT via Deep Convolutional\n  Framelets",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Chuhang Zou'}, {'name': 'Ersin Yumer'}, {'name': 'Jimei Yang'}, {'name': 'Duygu Ceylan'}, {'name': 'Derek Hoiem'}]",
//  "day": 4,
//  "id": "1708.01648v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.01648v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.01648v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "The success of various applications including robotics, digital content\ncreation, and visualization demand a structured and abstract representation of\nthe 3D world from limited sensor data. Inspired by the nature of human\nperception of 3D shapes as a collection of simple parts, we explore such an\nabstract shape representation based on primitives. Given a single depth image\nof an object, we present 3D-PRNN, a generative recurrent neural network that\nsynthesizes multiple plausible shapes composed of a set of primitives. Our\ngenerative model encodes symmetry characteristics of common man-made objects,\npreserves long-range structural coherence, and describes objects of varying\ncomplexity with a compact representation. We also propose a method based on\nGaussian Fields to generate a large scale dataset of primitive-based shape\nrepresentations to train our network. We evaluate our approach on a wide range\nof examples and show that it outperforms nearest-neighbor based shape retrieval\nmethods and is on-par with voxel-based generative models while using a\nsignificantly reduced parameter space.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Zhiming Zhou'}, {'name': 'Weinan Zhang'}, {'name': 'Jun Wang'}]",
//  "day": 5,
//  "id": "1708.01729v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.01729v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.01729v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "In this article, we mathematically study several GAN related topics,\nincluding Inception score, label smoothing, gradient vanishing and the\n-log(D(x)) alternative.\n  --- An advanced version is included in arXiv:1703.02000 \"Activation\nMaximization Generative Adversarial Nets\". Please refer Section 6 in 1703.02000\nfor detailed analysis on Inception Score, and refer its appendix for the\ndiscussions on Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative.\n---",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x))\n  Alternative",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kai Arulkumaran'}, {'name': 'Marc Peter Deisenroth'}, {'name': 'Miles Brundage'}, {'name': 'Anil Anthony Bharath'}]",
//  "day": 19,
//  "id": "1708.05866v2",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/MSP.2017.2743240', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.05866v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.05866v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Deep reinforcement learning is poised to revolutionise the field of AI and\nrepresents a step towards building autonomous systems with a higher level\nunderstanding of the visual world. Currently, deep learning is enabling\nreinforcement learning to scale to problems that were previously intractable,\nsuch as learning to play video games directly from pixels. Deep reinforcement\nlearning algorithms are also applied to robotics, allowing control policies for\nrobots to be learned directly from camera inputs in the real world. In this\nsurvey, we begin with an introduction to the general field of reinforcement\nlearning, then progress to the main streams of value-based and policy-based\nmethods. Our survey will cover central algorithms in deep reinforcement\nlearning, including the deep $Q$-network, trust region policy optimisation, and\nasynchronous advantage actor-critic. In parallel, we highlight the unique\nadvantages of deep neural networks, focusing on visual understanding via\nreinforcement learning. To conclude, we describe several current areas of\nresearch within the field.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "A Brief Survey of Deep Reinforcement Learning",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Caiwen Ding'}, {'name': 'Siyu Liao'}, {'name': 'Yanzhi Wang'}, {'name': 'Zhe Li'}, {'name': 'Ning Liu'}, {'name': 'Youwei Zhuo'}, {'name': 'Chao Wang'}, {'name': 'Xuehai Qian'}, {'name': 'Yu Bai'}, {'name': 'Geng Yuan'}, {'name': 'Xiaolong Ma'}, {'name': 'Yipeng Zhang'}, {'name': 'Jian Tang'}, {'name': 'Qinru Qiu'}, {'name': 'Xue Lin'}, {'name': 'Bo Yuan'}]",
//  "day": 29,
//  "id": "1708.08917v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1145/3123939.3124552', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1708.08917v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1708.08917v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 8,
//  "summary": "Large-scale deep neural networks (DNNs) are both compute and memory\nintensive. As the size of DNNs continues to grow, it is critical to improve the\nenergy efficiency and performance while maintaining accuracy. For DNNs, the\nmodel size is an important factor affecting performance, scalability and energy\nefficiency. Weight pruning achieves good compression ratios but suffers from\nthree drawbacks: 1) the irregular network structure after pruning; 2) the\nincreased training complexity; and 3) the lack of rigorous guarantee of\ncompression ratio and inference accuracy. To overcome these limitations, this\npaper proposes CirCNN, a principled approach to represent weights and process\nneural networks using block-circulant matrices. CirCNN utilizes the Fast\nFourier Transform (FFT)-based fast multiplication, simultaneously reducing the\ncomputational complexity (both in inference and training) from O(n2) to\nO(nlogn) and the storage complexity from O(n2) to O(n), with negligible\naccuracy loss. Compared to other approaches, CirCNN is distinct due to its\nmathematical rigor: it can converge to the same effectiveness as DNNs without\ncompression. The CirCNN architecture, a universal DNN inference engine that can\nbe implemented on various hardware/software platforms with configurable network\narchitecture. To demonstrate the performance and energy efficiency, we test\nCirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNN\narchitecture achieves very high energy efficiency and performance with a small\nhardware footprint. Based on the FPGA implementation and ASIC synthesis\nresults, CirCNN achieves 6-102X energy efficiency improvements compared with\nthe best state-of-the-art results.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "CirCNN: Accelerating and Compressing Deep Neural Networks Using\n  Block-CirculantWeight Matrices",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'C\u0103t\u0103lina Cangea'}, {'name': 'Petar Veli\u010dkovi\u0107'}, {'name': 'Pietro Li\u00f2'}]",
//  "day": 2,
//  "id": "1709.00572v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1709.00572v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1709.00572v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "We propose two multimodal deep learning architectures that allow for\ncross-modal dataflow (XFlow) between the feature extractors, thereby extracting\nmore interpretable features and obtaining a better representation than through\nunimodal learning, for the same amount of training data. These models can\nusefully exploit correlations between audio and visual data, which have a\ndifferent dimensionality and are therefore nontrivially exchangeable. Our work\nimproves on existing multimodal deep learning metholodogies in two essential\nways: (1) it presents a novel method for performing cross-modality (before\nfeatures are learned from individual modalities) and (2) extends the previously\nproposed cross-connections, which only transfer information between streams\nthat process compatible data. Both cross-modal architectures outperformed their\nbaselines (by up to 7.5%) when evaluated on the AVletters dataset.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "XFlow: 1D-2D Cross-modal Deep Neural Networks for Audiovisual\n  Classification",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Kun ho Kim'}, {'name': 'Oisin Mac Aodha'}, {'name': 'Pietro Perona'}]",
//  "day": 22,
//  "id": "1710.01691v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.01691v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.01691v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 9,
//  "summary": "Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Context Embedding Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Garrett B. Goh'}, {'name': 'Charles Siegel'}, {'name': 'Abhinav Vishnu'}, {'name': 'Nathan O. Hodas'}, {'name': 'Nathan Baker'}]",
//  "day": 5,
//  "id": "1710.02238v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1710.02238v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1710.02238v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 10,
//  "summary": "The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.",
//  "tag": "[{'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Abhishek Kumar'}, {'name': 'Prasanna Sattigeri'}, {'name': 'Avinash Balakrishnan'}]",
//  "day": 2,
//  "id": "1711.00848v2",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.00848v2', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.00848v2', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Disentangled representations, where the higher level data generative factors\nare reflected in disjoint latent dimensions, offer several benefits such as\nease of deriving invariant representations, transferability to other tasks,\ninterpretability, etc. We consider the problem of unsupervised learning of\ndisentangled representations from large pool of unlabeled observations, and\npropose a variational inference based approach to infer disentangled latent\nfactors. We introduce a regularizer on the expectation of the approximate\nposterior over observed data that encourages the disentanglement. We evaluate\nthe proposed approach using several quantitative metrics and empirically\nobserve significant gains over existing methods in terms of both\ndisentanglement and data likelihood (reconstruction quality).",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Variational Inference of Disentangled Latent Concepts from Unlabeled\n  Observations",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Stanis\u0142aw Jastrz\u0119bski'}, {'name': 'Zachary Kenton'}, {'name': 'Devansh Arpit'}, {'name': 'Nicolas Ballas'}, {'name': 'Asja Fischer'}, {'name': 'Yoshua Bengio'}, {'name': 'Amos Storkey'}]",
//  "day": 13,
//  "id": "1711.04623v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.04623v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.04623v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "We study the properties of the endpoint of stochastic gradient descent (SGD).\nBy approximating SGD as a stochastic differential equation (SDE) we consider\nthe Boltzmann-Gibbs equilibrium distribution of that SDE under the assumption\nof isotropic variance in loss gradients. Through this analysis, we find that\nthree factors - learning rate, batch size and the variance of the loss\ngradients - control the trade-off between the depth and width of the minima\nfound by SGD, with wider minima favoured by a higher ratio of learning rate to\nbatch size. We have direct control over the learning rate and batch size, while\nthe variance is determined by the choice of model architecture, model\nparameterization and dataset. In the equilibrium distribution only the ratio of\nlearning rate to batch size appears, implying that the equilibrium distribution\nis invariant under a simultaneous rescaling of learning rate and batch size by\nthe same amount. We then explore experimentally how learning rate and batch\nsize affect SGD from two perspectives: the endpoint of SGD and the dynamics\nthat lead up to it. For the endpoint, the experiments suggest the endpoint of\nSGD is invariant under simultaneous rescaling of batch size and learning rate,\nand also that a higher ratio leads to flatter minima, both findings are\nconsistent with our theoretical analysis. We note experimentally that the\ndynamics also seem to be invariant under the same rescaling of learning rate\nand batch size, which we explore showing that one can exchange batch size and\nlearning rate for cyclical learning rate schedule. Next, we illustrate how\nnoise affects memorization, showing that high noise levels lead to better\ngeneralization. Finally, we find experimentally that the invariance under\nsimultaneous rescaling of learning rate and batch size breaks down if the\nlearning rate gets too large or the batch size gets too small.",
//  "tag": "[{'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Three Factors Influencing Minima in SGD",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Pawe\u0142 Liskowski'}, {'name': 'Wojciech Ja\u015bkowski'}, {'name': 'Krzysztof Krawiec'}]",
//  "day": 17,
//  "id": "1711.06583v1",
//  "link": "[{'rel': 'related', 'href': 'http://dx.doi.org/10.1109/TG.2018.2799997', 'type': 'text/html', 'title': 'doi'}, {'rel': 'alternate', 'href': 'http://arxiv.org/abs/1711.06583v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1711.06583v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 11,
//  "summary": "Achieving superhuman playing level by AlphaGo corroborated the capabilities\nof convolutional neural architectures (CNNs) for capturing complex spatial\npatterns. This result was to a great extent due to several analogies between Go\nboard states and 2D images CNNs have been designed for, in particular\ntranslational invariance and a relatively large board. In this paper, we verify\nwhether CNN-based move predictors prove effective for Othello, a game with\nsignificantly different characteristics, including a much smaller board size\nand complete lack of translational invariance. We compare several CNN\narchitectures and board encodings, augment them with state-of-the-art\nextensions, train on an extensive database of experts' moves, and examine them\nwith respect to move prediction accuracy and playing strength. The empirical\nevaluation confirms high capabilities of neural move predictors and suggests a\nstrong correlation between prediction accuracy and playing strength. The best\nCNNs not only surpass all other 1-ply Othello players proposed to date but\ndefeat (2-ply) Edax, the best open-source Othello player.",
//  "tag": "[{'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Learning to Play Othello with Deep Neural Networks",
//  "year": 2017
//},
//{
//  "author": "[{'name': 'Jaejun Yoo'}, {'name': 'Sohail Sabir'}, {'name': 'Duchang Heo'}, {'name': 'Kee Hyun Kim'}, {'name': 'Abdul Wahab'}, {'name': 'Yoonseok Choi'}, {'name': 'Seul-I Lee'}, {'name': 'Eun Young Chae'}, {'name': 'Hak Hee Kim'}, {'name': 'Young Min Bae'}, {'name': 'Young-wook Choi'}, {'name': 'Seungryong Cho'}, {'name': 'Jong Chul Ye'}]",
//  "day": 4,
//  "id": "1712.00912v1",
//  "link": "[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1712.00912v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1712.00912v1', 'type': 'application/pdf', 'title': 'pdf'}]",
//  "month": 12,
//  "summary": "Can artificial intelligence (AI) learn complicated non-linear physics? Here\nwe propose a novel deep learning approach that learns non-linear photon\nscattering physics and obtains accurate 3D distribution of optical anomalies.\nIn contrast to the traditional black-box deep learning approaches to inverse\nproblems, our deep network learns to invert the Lippmann-Schwinger integral\nequation which describes the essential physics of photon migration of diffuse\nnear-infrared (NIR) photons in turbid media. As an example for clinical\nrelevance, we applied the method to our prototype diffuse optical tomography\n(DOT). We show that our deep neural network, trained with only simulation data,\ncan accurately recover the location of anomalies within biomimetic phantoms and\nlive animals without the use of an exogenous contrast agent.",
//  "tag": "[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]",
//  "title": "Deep Learning Can Reverse Photon Migration for Diffuse Optical\n  Tomography",
//  "year": 2017
//}
